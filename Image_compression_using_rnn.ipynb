{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_compression_using_rnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunalrdeshmukh/RNN_for_Imagecompression/blob/master/Image_compression_using_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cdHKSuKpqc9G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "77d87440-a318-4dbb-9107-f8e39f4c58a3"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn , optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable, Function\n",
        "from torch.nn.modules.utils import _pair\n",
        "\n",
        "!pip install Pillow==4.0.0\n",
        "!pip install PIL\n",
        "!pip install image\n",
        "!pip install lmdb\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n",
            "Collecting PIL\n",
            "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for PIL\u001b[0m\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.7)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (0.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KWR0dPzU5N1m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Sign(Function):\n",
        "    \"\"\"\n",
        "    Variable Rate Image Compression with Recurrent Neural Networks\n",
        "    https://arxiv.org/abs/1511.06085\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Sign, self).__init__()\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, is_training=True):\n",
        "        # Apply quantization noise while only training\n",
        "        if is_training:\n",
        "            prob = input.new(input.size()).uniform_()\n",
        "            x = input.clone()\n",
        "            x[(1 - input) / 2 <= prob] = 1\n",
        "            x[(1 - input) / 2 > prob] = -1\n",
        "            return x\n",
        "        else:\n",
        "            return input.sign()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "      return grad_output, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ul0hADEE5tI2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvRNNCellBase(nn.Module):\n",
        "    def __repr__(self):\n",
        "        s = (\n",
        "            '{name}({input_channels}, {hidden_channels}, kernel_size={kernel_size}'\n",
        "            ', stride={stride}')\n",
        "        if self.padding != (0, ) * len(self.padding):\n",
        "            s += ', padding={padding}'\n",
        "        if self.dilation != (1, ) * len(self.dilation):\n",
        "            s += ', dilation={dilation}'\n",
        "        s += ', hidden_kernel_size={hidden_kernel_size}'\n",
        "        s += ')'\n",
        "        return s.format(name=self.__class__.__name__, **self.__dict__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtS-eLbf7SPW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvLSTMCell(ConvRNNCellBase):\n",
        "    def __init__(self,\n",
        "                 input_channels,\n",
        "                 hidden_channels,\n",
        "                 kernel_size=3,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 dilation=1,\n",
        "                 hidden_kernel_size=1,\n",
        "                 bias=True):\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        self.kernel_size = _pair(kernel_size)\n",
        "        self.stride = _pair(stride)\n",
        "        self.padding = _pair(padding)\n",
        "        self.dilation = _pair(dilation)\n",
        "\n",
        "        self.hidden_kernel_size = _pair(hidden_kernel_size)\n",
        "\n",
        "        hidden_padding = _pair(hidden_kernel_size // 2)\n",
        "\n",
        "        gate_channels = 4 * self.hidden_channels\n",
        "        self.conv_ih = nn.Conv2d(\n",
        "            in_channels=self.input_channels,\n",
        "            out_channels=gate_channels,\n",
        "            kernel_size=self.kernel_size,\n",
        "            stride=self.stride,\n",
        "            padding=self.padding,\n",
        "            dilation=self.dilation,\n",
        "            bias=bias)\n",
        "\n",
        "        self.conv_hh = nn.Conv2d(\n",
        "            in_channels=self.hidden_channels,\n",
        "            out_channels=gate_channels,\n",
        "            kernel_size=hidden_kernel_size,\n",
        "            stride=1,\n",
        "            padding=hidden_padding,\n",
        "            dilation=1,\n",
        "            bias=bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv_ih.reset_parameters()\n",
        "        self.conv_hh.reset_parameters()\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        hx, cx = hidden\n",
        "        gates = self.conv_ih(input) + self.conv_hh(hx)\n",
        "\n",
        "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
        "\n",
        "        ingate = F.sigmoid(ingate)\n",
        "        forgetgate = F.sigmoid(forgetgate)\n",
        "        cellgate = F.tanh(cellgate)\n",
        "        outgate = F.sigmoid(outgate)\n",
        "\n",
        "        cy = (forgetgate * cx) + (ingate * cellgate)\n",
        "        hy = outgate * F.tanh(cy)\n",
        "\n",
        "        return hy, cy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GltCQ3gs7VC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "525a14da-f65c-405d-b377-394dd074335a"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/1zb/pytorch-image-comp-rnn.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-image-comp-rnn'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Total 114 (delta 0), reused 0 (delta 0), pack-reused 114\u001b[K\n",
            "Receiving objects: 100% (114/114), 2.36 MiB | 30.19 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "76xs3rF9Baa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa98b2e4-86a6-487d-b7bf-a9b395546457"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  gdrive  pytorch-image-comp-rnn  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ui3XrtfoBeJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f5ef6f4-1e3d-4fd0-9a81-0aefaadfcde9"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4_0PWQ_dBum9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d56bbe0-aa1c-4923-f15a-14d204fc8b18"
      },
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  gdrive  pytorch-image-comp-rnn  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lfWpL0GoCI6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5d48e87d-0dc6-4b9d-b1cb-e632e2f46c71"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: inter-device move failed: 'pytorch-image-comp-rnn' to 'gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn'; unable to remove target: Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t0vQfBtmDwTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62104
        },
        "outputId": "4e7698cc-3759-4813-cc16-de7ce9e4561d"
      },
      "cell_type": "code",
      "source": [
        "!python 'gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/train.py' -f 'gdrive/My Drive/Fall 18/297/datasets/Imagenet/train/train/' -N 32 -e 1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total images: 38839; total batches: 1214\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/train.py:170: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  len(train_loader), loss.data[0], bp_t1 - bp_t0, batch_t1 -\n",
            "[TRAIN] Epoch[1](1/1214); Loss: 0.238569; Backpropagation: 0.7787 sec; Batch: 4.6591 sec\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/train.py:173: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  '\\n').format(* [l.data[0] for l in losses]))\n",
            "0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 0.2386 \n",
            "\n",
            "[TRAIN] Epoch[1](2/1214); Loss: 0.268786; Backpropagation: 0.6305 sec; Batch: 4.4868 sec\n",
            "0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 0.2688 \n",
            "\n",
            "[TRAIN] Epoch[1](3/1214); Loss: 0.252696; Backpropagation: 0.6130 sec; Batch: 4.4739 sec\n",
            "0.2526 0.2526 0.2526 0.2527 0.2527 0.2527 0.2527 0.2527 0.2527 0.2527 0.2527 0.2527 0.2527 0.2527 0.2527 0.2527 \n",
            "\n",
            "[TRAIN] Epoch[1](4/1214); Loss: 0.256200; Backpropagation: 0.6115 sec; Batch: 4.4777 sec\n",
            "0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 0.2562 \n",
            "\n",
            "[TRAIN] Epoch[1](5/1214); Loss: 0.270160; Backpropagation: 0.6144 sec; Batch: 4.4720 sec\n",
            "0.2702 0.2702 0.2702 0.2702 0.2702 0.2702 0.2702 0.2702 0.2702 0.2702 0.2702 0.2702 0.2701 0.2701 0.2701 0.2701 \n",
            "\n",
            "[TRAIN] Epoch[1](6/1214); Loss: 0.224046; Backpropagation: 0.6124 sec; Batch: 4.4826 sec\n",
            "0.2240 0.2240 0.2240 0.2241 0.2241 0.2241 0.2241 0.2241 0.2241 0.2241 0.2241 0.2241 0.2240 0.2240 0.2239 0.2239 \n",
            "\n",
            "[TRAIN] Epoch[1](7/1214); Loss: 0.226439; Backpropagation: 0.6046 sec; Batch: 4.4677 sec\n",
            "0.2266 0.2266 0.2266 0.2266 0.2266 0.2266 0.2266 0.2265 0.2265 0.2265 0.2264 0.2263 0.2263 0.2262 0.2262 0.2261 \n",
            "\n",
            "[TRAIN] Epoch[1](8/1214); Loss: 0.233314; Backpropagation: 0.6137 sec; Batch: 4.4827 sec\n",
            "0.2353 0.2353 0.2352 0.2351 0.2349 0.2347 0.2344 0.2341 0.2337 0.2332 0.2327 0.2322 0.2316 0.2309 0.2303 0.2296 \n",
            "\n",
            "[TRAIN] Epoch[1](9/1214); Loss: 0.221739; Backpropagation: 0.6100 sec; Batch: 4.4751 sec\n",
            "0.2293 0.2293 0.2292 0.2289 0.2284 0.2277 0.2266 0.2253 0.2236 0.2217 0.2194 0.2170 0.2144 0.2117 0.2090 0.2063 \n",
            "\n",
            "[TRAIN] Epoch[1](10/1214); Loss: 0.207083; Backpropagation: 0.6138 sec; Batch: 4.4812 sec\n",
            "0.2349 0.2345 0.2336 0.2316 0.2282 0.2231 0.2160 0.2072 0.1975 0.1880 0.1804 0.1765 0.1775 0.1833 0.1935 0.2075 \n",
            "\n",
            "[TRAIN] Epoch[1](11/1214); Loss: 0.200283; Backpropagation: 0.6127 sec; Batch: 4.4770 sec\n",
            "0.2323 0.2316 0.2298 0.2262 0.2205 0.2123 0.2020 0.1902 0.1786 0.1691 0.1634 0.1630 0.1700 0.1843 0.2040 0.2272 \n",
            "\n",
            "[TRAIN] Epoch[1](12/1214); Loss: 0.201891; Backpropagation: 0.6125 sec; Batch: 4.4853 sec\n",
            "0.2340 0.2335 0.2323 0.2302 0.2268 0.2220 0.2160 0.2089 0.2011 0.1929 0.1849 0.1778 0.1720 0.1677 0.1653 0.1650 \n",
            "\n",
            "[TRAIN] Epoch[1](13/1214); Loss: 0.205235; Backpropagation: 0.6126 sec; Batch: 4.4780 sec\n",
            "0.2384 0.2378 0.2366 0.2343 0.2308 0.2260 0.2199 0.2129 0.2052 0.1972 0.1893 0.1819 0.1753 0.1697 0.1655 0.1628 \n",
            "\n",
            "[TRAIN] Epoch[1](14/1214); Loss: 0.202484; Backpropagation: 0.6101 sec; Batch: 4.4800 sec\n",
            "0.2447 0.2436 0.2410 0.2364 0.2297 0.2209 0.2105 0.1991 0.1878 0.1781 0.1713 0.1680 0.1686 0.1727 0.1795 0.1879 \n",
            "\n",
            "[TRAIN] Epoch[1](15/1214); Loss: 0.205510; Backpropagation: 0.6124 sec; Batch: 4.4847 sec\n",
            "0.2431 0.2413 0.2371 0.2298 0.2198 0.2079 0.1953 0.1837 0.1748 0.1704 0.1721 0.1793 0.1904 0.2031 0.2152 0.2248 \n",
            "\n",
            "[TRAIN] Epoch[1](16/1214); Loss: 0.191365; Backpropagation: 0.6154 sec; Batch: 4.4824 sec\n",
            "0.2406 0.2384 0.2336 0.2259 0.2156 0.2036 0.1911 0.1793 0.1693 0.1622 0.1588 0.1595 0.1633 0.1687 0.1739 0.1779 \n",
            "\n",
            "[TRAIN] Epoch[1](17/1214); Loss: 0.185954; Backpropagation: 0.6177 sec; Batch: 4.4871 sec\n",
            "0.2433 0.2406 0.2348 0.2261 0.2148 0.2024 0.1901 0.1789 0.1695 0.1621 0.1566 0.1531 0.1513 0.1506 0.1506 0.1505 \n",
            "\n",
            "[TRAIN] Epoch[1](18/1214); Loss: 0.170494; Backpropagation: 0.6124 sec; Batch: 4.4794 sec\n",
            "0.2170 0.2143 0.2090 0.2015 0.1925 0.1830 0.1735 0.1650 0.1579 0.1527 0.1489 0.1463 0.1443 0.1425 0.1407 0.1388 \n",
            "\n",
            "[TRAIN] Epoch[1](19/1214); Loss: 0.171423; Backpropagation: 0.6129 sec; Batch: 4.4839 sec\n",
            "0.2365 0.2322 0.2245 0.2139 0.2016 0.1891 0.1773 0.1667 0.1577 0.1502 0.1439 0.1384 0.1333 0.1289 0.1254 0.1231 \n",
            "\n",
            "[TRAIN] Epoch[1](20/1214); Loss: 0.164391; Backpropagation: 0.6140 sec; Batch: 4.4859 sec\n",
            "0.2277 0.2218 0.2114 0.1976 0.1831 0.1700 0.1594 0.1516 0.1465 0.1427 0.1395 0.1369 0.1353 0.1349 0.1354 0.1366 \n",
            "\n",
            "[TRAIN] Epoch[1](21/1214); Loss: 0.159059; Backpropagation: 0.6235 sec; Batch: 4.4939 sec\n",
            "0.2534 0.2399 0.2190 0.1954 0.1736 0.1555 0.1430 0.1357 0.1320 0.1303 0.1288 0.1270 0.1248 0.1248 0.1282 0.1335 \n",
            "\n",
            "[TRAIN] Epoch[1](22/1214); Loss: 0.177440; Backpropagation: 0.6142 sec; Batch: 4.4841 sec\n",
            "0.2631 0.2477 0.2255 0.2016 0.1812 0.1672 0.1586 0.1531 0.1496 0.1484 0.1500 0.1541 0.1592 0.1622 0.1609 0.1566 \n",
            "\n",
            "[TRAIN] Epoch[1](23/1214); Loss: 0.145466; Backpropagation: 0.6134 sec; Batch: 4.4909 sec\n",
            "0.2200 0.2035 0.1822 0.1621 0.1475 0.1382 0.1322 0.1278 0.1252 0.1261 0.1291 0.1301 0.1270 0.1230 0.1239 0.1294 \n",
            "\n",
            "[TRAIN] Epoch[1](24/1214); Loss: 0.166630; Backpropagation: 0.6105 sec; Batch: 4.4847 sec\n",
            "0.2277 0.2132 0.1955 0.1794 0.1680 0.1608 0.1567 0.1551 0.1558 0.1559 0.1533 0.1499 0.1481 0.1484 0.1492 0.1493 \n",
            "\n",
            "[TRAIN] Epoch[1](25/1214); Loss: 0.133244; Backpropagation: 0.6260 sec; Batch: 4.4962 sec\n",
            "0.1938 0.1728 0.1507 0.1353 0.1270 0.1236 0.1237 0.1274 0.1305 0.1272 0.1211 0.1180 0.1187 0.1201 0.1207 0.1214 \n",
            "\n",
            "[TRAIN] Epoch[1](26/1214); Loss: 0.150090; Backpropagation: 0.6151 sec; Batch: 4.4916 sec\n",
            "0.2399 0.2146 0.1888 0.1671 0.1504 0.1394 0.1350 0.1348 0.1343 0.1321 0.1285 0.1262 0.1268 0.1278 0.1278 0.1279 \n",
            "\n",
            "[TRAIN] Epoch[1](27/1214); Loss: 0.142472; Backpropagation: 0.6192 sec; Batch: 4.4946 sec\n",
            "0.2086 0.1861 0.1640 0.1483 0.1380 0.1322 0.1312 0.1327 0.1333 0.1324 0.1301 0.1284 0.1271 0.1271 0.1295 0.1305 \n",
            "\n",
            "[TRAIN] Epoch[1](28/1214); Loss: 0.139354; Backpropagation: 0.6249 sec; Batch: 4.4971 sec\n",
            "0.1973 0.1696 0.1493 0.1404 0.1359 0.1308 0.1297 0.1333 0.1331 0.1295 0.1283 0.1293 0.1296 0.1296 0.1316 0.1325 \n",
            "\n",
            "[TRAIN] Epoch[1](29/1214); Loss: 0.141920; Backpropagation: 0.6126 sec; Batch: 4.4813 sec\n",
            "0.2132 0.1878 0.1647 0.1475 0.1378 0.1325 0.1307 0.1305 0.1300 0.1286 0.1287 0.1293 0.1285 0.1270 0.1269 0.1270 \n",
            "\n",
            "[TRAIN] Epoch[1](30/1214); Loss: 0.153777; Backpropagation: 0.6164 sec; Batch: 4.4944 sec\n",
            "0.2307 0.2001 0.1749 0.1569 0.1463 0.1429 0.1410 0.1405 0.1405 0.1406 0.1409 0.1411 0.1407 0.1413 0.1413 0.1408 \n",
            "\n",
            "[TRAIN] Epoch[1](31/1214); Loss: 0.138160; Backpropagation: 0.6103 sec; Batch: 4.4883 sec\n",
            "0.2404 0.1996 0.1673 0.1451 0.1306 0.1225 0.1198 0.1192 0.1208 0.1225 0.1226 0.1210 0.1203 0.1196 0.1196 0.1198 \n",
            "\n",
            "[TRAIN] Epoch[1](32/1214); Loss: 0.139094; Backpropagation: 0.6147 sec; Batch: 4.4878 sec\n",
            "0.2204 0.1902 0.1657 0.1473 0.1345 0.1277 0.1235 0.1240 0.1254 0.1260 0.1255 0.1239 0.1233 0.1233 0.1223 0.1225 \n",
            "\n",
            "[TRAIN] Epoch[1](33/1214); Loss: 0.140926; Backpropagation: 0.6115 sec; Batch: 4.4846 sec\n",
            "0.2194 0.1853 0.1629 0.1490 0.1386 0.1308 0.1288 0.1293 0.1284 0.1258 0.1256 0.1262 0.1254 0.1258 0.1268 0.1267 \n",
            "\n",
            "[TRAIN] Epoch[1](34/1214); Loss: 0.126584; Backpropagation: 0.6180 sec; Batch: 4.5011 sec\n",
            "0.2028 0.1674 0.1427 0.1284 0.1202 0.1170 0.1157 0.1146 0.1150 0.1156 0.1151 0.1140 0.1142 0.1140 0.1138 0.1148 \n",
            "\n",
            "[TRAIN] Epoch[1](35/1214); Loss: 0.124472; Backpropagation: 0.6093 sec; Batch: 4.4835 sec\n",
            "0.1888 0.1496 0.1304 0.1208 0.1179 0.1184 0.1180 0.1183 0.1190 0.1186 0.1174 0.1157 0.1153 0.1144 0.1145 0.1145 \n",
            "\n",
            "[TRAIN] Epoch[1](36/1214); Loss: 0.120178; Backpropagation: 0.6124 sec; Batch: 4.4877 sec\n",
            "0.2057 0.1581 0.1283 0.1188 0.1148 0.1135 0.1131 0.1097 0.1087 0.1073 0.1081 0.1072 0.1082 0.1084 0.1063 0.1066 \n",
            "\n",
            "[TRAIN] Epoch[1](37/1214); Loss: 0.125130; Backpropagation: 0.6197 sec; Batch: 4.4918 sec\n",
            "0.2061 0.1707 0.1426 0.1260 0.1194 0.1169 0.1149 0.1127 0.1113 0.1130 0.1142 0.1110 0.1109 0.1110 0.1113 0.1102 \n",
            "\n",
            "[TRAIN] Epoch[1](38/1214); Loss: 0.116659; Backpropagation: 0.6155 sec; Batch: 4.4955 sec\n",
            "0.1966 0.1508 0.1245 0.1142 0.1112 0.1092 0.1082 0.1064 0.1068 0.1064 0.1061 0.1062 0.1056 0.1047 0.1047 0.1050 \n",
            "\n",
            "[TRAIN] Epoch[1](39/1214); Loss: 0.110841; Backpropagation: 0.6167 sec; Batch: 4.4915 sec\n",
            "0.1861 0.1456 0.1175 0.1048 0.1027 0.1017 0.1014 0.1017 0.1015 0.1005 0.1007 0.1015 0.1024 0.1020 0.1024 0.1007 \n",
            "\n",
            "[TRAIN] Epoch[1](40/1214); Loss: 0.112600; Backpropagation: 0.6182 sec; Batch: 4.4926 sec\n",
            "0.1703 0.1345 0.1184 0.1111 0.1079 0.1073 0.1061 0.1066 0.1070 0.1051 0.1037 0.1058 0.1038 0.1036 0.1060 0.1044 \n",
            "\n",
            "[TRAIN] Epoch[1](41/1214); Loss: 0.118830; Backpropagation: 0.6148 sec; Batch: 4.4884 sec\n",
            "0.2040 0.1589 0.1245 0.1173 0.1130 0.1092 0.1093 0.1083 0.1062 0.1074 0.1067 0.1081 0.1075 0.1071 0.1076 0.1061 \n",
            "\n",
            "[TRAIN] Epoch[1](42/1214); Loss: 0.121319; Backpropagation: 0.6142 sec; Batch: 4.4886 sec\n",
            "0.1907 0.1483 0.1254 0.1196 0.1174 0.1145 0.1131 0.1137 0.1136 0.1120 0.1117 0.1117 0.1130 0.1122 0.1111 0.1132 \n",
            "\n",
            "[TRAIN] Epoch[1](43/1214); Loss: 0.118901; Backpropagation: 0.6109 sec; Batch: 4.4776 sec\n",
            "0.1903 0.1479 0.1252 0.1172 0.1131 0.1108 0.1110 0.1100 0.1100 0.1101 0.1094 0.1104 0.1111 0.1090 0.1075 0.1093 \n",
            "\n",
            "[TRAIN] Epoch[1](44/1214); Loss: 0.114825; Backpropagation: 0.6122 sec; Batch: 4.4841 sec\n",
            "0.1798 0.1393 0.1190 0.1115 0.1100 0.1082 0.1082 0.1060 0.1076 0.1070 0.1055 0.1066 0.1071 0.1081 0.1065 0.1068 \n",
            "\n",
            "[TRAIN] Epoch[1](45/1214); Loss: 0.134553; Backpropagation: 0.6100 sec; Batch: 4.4777 sec\n",
            "0.1851 0.1499 0.1403 0.1337 0.1308 0.1293 0.1290 0.1272 0.1291 0.1281 0.1297 0.1284 0.1278 0.1285 0.1270 0.1290 \n",
            "\n",
            "[TRAIN] Epoch[1](46/1214); Loss: 0.121702; Backpropagation: 0.6161 sec; Batch: 4.4855 sec\n",
            "0.1855 0.1440 0.1276 0.1183 0.1152 0.1158 0.1140 0.1150 0.1148 0.1138 0.1141 0.1141 0.1136 0.1135 0.1135 0.1145 \n",
            "\n",
            "[TRAIN] Epoch[1](47/1214); Loss: 0.126164; Backpropagation: 0.6097 sec; Batch: 4.4782 sec\n",
            "0.2182 0.1667 0.1393 0.1245 0.1165 0.1152 0.1140 0.1142 0.1140 0.1139 0.1149 0.1144 0.1138 0.1136 0.1129 0.1125 \n",
            "\n",
            "[TRAIN] Epoch[1](48/1214); Loss: 0.119565; Backpropagation: 0.6131 sec; Batch: 4.4914 sec\n",
            "0.2157 0.1545 0.1296 0.1160 0.1109 0.1090 0.1081 0.1086 0.1083 0.1087 0.1072 0.1083 0.1066 0.1079 0.1068 0.1069 \n",
            "\n",
            "[TRAIN] Epoch[1](49/1214); Loss: 0.115348; Backpropagation: 0.6088 sec; Batch: 4.4903 sec\n",
            "0.1808 0.1375 0.1210 0.1135 0.1090 0.1090 0.1091 0.1081 0.1079 0.1083 0.1068 0.1077 0.1065 0.1068 0.1064 0.1073 \n",
            "\n",
            "[TRAIN] Epoch[1](50/1214); Loss: 0.115188; Backpropagation: 0.6122 sec; Batch: 4.4863 sec\n",
            "0.1835 0.1391 0.1212 0.1121 0.1104 0.1093 0.1072 0.1075 0.1074 0.1082 0.1061 0.1061 0.1069 0.1063 0.1057 0.1059 \n",
            "\n",
            "[TRAIN] Epoch[1](51/1214); Loss: 0.114604; Backpropagation: 0.6178 sec; Batch: 4.4965 sec\n",
            "0.1854 0.1393 0.1191 0.1116 0.1081 0.1066 0.1071 0.1067 0.1066 0.1061 0.1073 0.1056 0.1071 0.1053 0.1063 0.1055 \n",
            "\n",
            "[TRAIN] Epoch[1](52/1214); Loss: 0.117295; Backpropagation: 0.6062 sec; Batch: 4.4819 sec\n",
            "0.1946 0.1458 0.1247 0.1107 0.1089 0.1084 0.1075 0.1093 0.1088 0.1089 0.1086 0.1074 0.1089 0.1076 0.1084 0.1082 \n",
            "\n",
            "[TRAIN] Epoch[1](53/1214); Loss: 0.114793; Backpropagation: 0.6126 sec; Batch: 4.4856 sec\n",
            "0.1737 0.1375 0.1196 0.1125 0.1098 0.1079 0.1076 0.1083 0.1079 0.1085 0.1077 0.1074 0.1075 0.1074 0.1063 0.1072 \n",
            "\n",
            "[TRAIN] Epoch[1](54/1214); Loss: 0.109855; Backpropagation: 0.6258 sec; Batch: 4.5048 sec\n",
            "0.1779 0.1313 0.1155 0.1085 0.1068 0.1043 0.1018 0.1025 0.1018 0.1008 0.1010 0.1009 0.1016 0.1016 0.1007 0.1006 \n",
            "\n",
            "[TRAIN] Epoch[1](55/1214); Loss: 0.108812; Backpropagation: 0.6067 sec; Batch: 4.4765 sec\n",
            "0.1578 0.1242 0.1133 0.1064 0.1044 0.1052 0.1033 0.1036 0.1032 0.1038 0.1026 0.1033 0.1021 0.1028 0.1018 0.1032 \n",
            "\n",
            "[TRAIN] Epoch[1](56/1214); Loss: 0.125641; Backpropagation: 0.6219 sec; Batch: 4.4969 sec\n",
            "0.1911 0.1505 0.1333 0.1237 0.1206 0.1181 0.1178 0.1174 0.1174 0.1166 0.1165 0.1164 0.1173 0.1179 0.1172 0.1186 \n",
            "\n",
            "[TRAIN] Epoch[1](57/1214); Loss: 0.101750; Backpropagation: 0.6116 sec; Batch: 4.4896 sec\n",
            "0.1700 0.1202 0.1025 0.0973 0.0952 0.0946 0.0950 0.0952 0.0933 0.0954 0.0941 0.0947 0.0938 0.0951 0.0964 0.0951 \n",
            "\n",
            "[TRAIN] Epoch[1](58/1214); Loss: 0.104333; Backpropagation: 0.6206 sec; Batch: 4.4955 sec\n",
            "0.1743 0.1248 0.1056 0.1007 0.0982 0.0984 0.0960 0.0971 0.0960 0.0962 0.0968 0.0970 0.0969 0.0968 0.0977 0.0968 \n",
            "\n",
            "[TRAIN] Epoch[1](59/1214); Loss: 0.114290; Backpropagation: 0.6128 sec; Batch: 4.4831 sec\n",
            "0.1789 0.1343 0.1168 0.1117 0.1091 0.1079 0.1074 0.1072 0.1069 0.1074 0.1066 0.1064 0.1064 0.1068 0.1067 0.1080 \n",
            "\n",
            "[TRAIN] Epoch[1](60/1214); Loss: 0.123901; Backpropagation: 0.6194 sec; Batch: 4.4914 sec\n",
            "0.1935 0.1428 0.1255 0.1219 0.1188 0.1184 0.1172 0.1172 0.1158 0.1161 0.1164 0.1165 0.1158 0.1158 0.1157 0.1152 \n",
            "\n",
            "[TRAIN] Epoch[1](61/1214); Loss: 0.118307; Backpropagation: 0.6074 sec; Batch: 4.4869 sec\n",
            "0.1909 0.1424 0.1221 0.1160 0.1128 0.1116 0.1105 0.1102 0.1099 0.1098 0.1090 0.1093 0.1094 0.1095 0.1093 0.1104 \n",
            "\n",
            "[TRAIN] Epoch[1](62/1214); Loss: 0.105042; Backpropagation: 0.6114 sec; Batch: 4.4810 sec\n",
            "0.1886 0.1292 0.1079 0.1023 0.0981 0.0966 0.0959 0.0951 0.0960 0.0956 0.0958 0.0956 0.0957 0.0961 0.0955 0.0966 \n",
            "\n",
            "[TRAIN] Epoch[1](63/1214); Loss: 0.126608; Backpropagation: 0.6116 sec; Batch: 4.4900 sec\n",
            "0.1962 0.1514 0.1346 0.1250 0.1216 0.1186 0.1181 0.1176 0.1182 0.1176 0.1180 0.1177 0.1170 0.1184 0.1178 0.1177 \n",
            "\n",
            "[TRAIN] Epoch[1](64/1214); Loss: 0.136163; Backpropagation: 0.6115 sec; Batch: 4.4878 sec\n",
            "0.1756 0.1509 0.1418 0.1372 0.1345 0.1333 0.1316 0.1303 0.1312 0.1302 0.1299 0.1302 0.1304 0.1304 0.1308 0.1302 \n",
            "\n",
            "[TRAIN] Epoch[1](65/1214); Loss: 0.108786; Backpropagation: 0.6190 sec; Batch: 4.4982 sec\n",
            "0.1499 0.1212 0.1120 0.1080 0.1057 0.1044 0.1048 0.1042 0.1034 0.1041 0.1034 0.1043 0.1038 0.1035 0.1039 0.1040 \n",
            "\n",
            "[TRAIN] Epoch[1](66/1214); Loss: 0.108577; Backpropagation: 0.6171 sec; Batch: 4.4931 sec\n",
            "0.1762 0.1292 0.1118 0.1057 0.1031 0.1020 0.1013 0.1011 0.1012 0.1002 0.1001 0.1008 0.1007 0.1018 0.1014 0.1007 \n",
            "\n",
            "[TRAIN] Epoch[1](67/1214); Loss: 0.103950; Backpropagation: 0.6204 sec; Batch: 4.4941 sec\n",
            "0.1607 0.1136 0.1054 0.1017 0.0995 0.0986 0.0978 0.0976 0.0984 0.0978 0.0980 0.0977 0.0979 0.0993 0.1001 0.0991 \n",
            "\n",
            "[TRAIN] Epoch[1](68/1214); Loss: 0.113614; Backpropagation: 0.6132 sec; Batch: 4.4858 sec\n",
            "0.1748 0.1362 0.1186 0.1111 0.1090 0.1073 0.1064 0.1063 0.1067 0.1062 0.1064 0.1056 0.1059 0.1058 0.1056 0.1060 \n",
            "\n",
            "[TRAIN] Epoch[1](69/1214); Loss: 0.101185; Backpropagation: 0.6077 sec; Batch: 4.4788 sec\n",
            "0.1810 0.1269 0.1078 0.0979 0.0946 0.0933 0.0924 0.0915 0.0911 0.0915 0.0921 0.0916 0.0917 0.0927 0.0910 0.0918 \n",
            "\n",
            "[TRAIN] Epoch[1](70/1214); Loss: 0.119897; Backpropagation: 0.6197 sec; Batch: 4.4923 sec\n",
            "0.1861 0.1342 0.1218 0.1198 0.1164 0.1141 0.1132 0.1129 0.1124 0.1119 0.1132 0.1130 0.1119 0.1125 0.1124 0.1125 \n",
            "\n",
            "[TRAIN] Epoch[1](71/1214); Loss: 0.104861; Backpropagation: 0.6155 sec; Batch: 4.4874 sec\n",
            "0.1656 0.1218 0.1080 0.1022 0.0999 0.0990 0.0984 0.0983 0.0983 0.0980 0.0974 0.0982 0.0980 0.0982 0.0986 0.0979 \n",
            "\n",
            "[TRAIN] Epoch[1](72/1214); Loss: 0.113849; Backpropagation: 0.6203 sec; Batch: 4.4923 sec\n",
            "0.1605 0.1240 0.1185 0.1130 0.1105 0.1094 0.1088 0.1084 0.1084 0.1080 0.1082 0.1080 0.1088 0.1089 0.1092 0.1091 \n",
            "\n",
            "[TRAIN] Epoch[1](73/1214); Loss: 0.113875; Backpropagation: 0.6167 sec; Batch: 4.4916 sec\n",
            "0.1825 0.1306 0.1152 0.1108 0.1086 0.1072 0.1070 0.1071 0.1063 0.1067 0.1071 0.1066 0.1062 0.1064 0.1070 0.1068 \n",
            "\n",
            "[TRAIN] Epoch[1](74/1214); Loss: 0.100339; Backpropagation: 0.6098 sec; Batch: 4.4808 sec\n",
            "0.1736 0.1185 0.1038 0.0983 0.0960 0.0940 0.0929 0.0924 0.0922 0.0920 0.0918 0.0919 0.0921 0.0920 0.0919 0.0921 \n",
            "\n",
            "[TRAIN] Epoch[1](75/1214); Loss: 0.101572; Backpropagation: 0.6227 sec; Batch: 4.5047 sec\n",
            "0.1699 0.1212 0.1037 0.0993 0.0968 0.0955 0.0949 0.0944 0.0940 0.0938 0.0935 0.0935 0.0932 0.0940 0.0938 0.0938 \n",
            "\n",
            "[TRAIN] Epoch[1](76/1214); Loss: 0.114775; Backpropagation: 0.6097 sec; Batch: 4.4847 sec\n",
            "0.1466 0.1245 0.1165 0.1156 0.1135 0.1122 0.1114 0.1110 0.1108 0.1107 0.1104 0.1106 0.1106 0.1103 0.1108 0.1109 \n",
            "\n",
            "[TRAIN] Epoch[1](77/1214); Loss: 0.101605; Backpropagation: 0.6112 sec; Batch: 4.4874 sec\n",
            "0.1684 0.1219 0.1043 0.0993 0.0970 0.0955 0.0945 0.0945 0.0941 0.0941 0.0939 0.0938 0.0936 0.0939 0.0935 0.0935 \n",
            "\n",
            "[TRAIN] Epoch[1](78/1214); Loss: 0.125063; Backpropagation: 0.6098 sec; Batch: 4.4785 sec\n",
            "0.1875 0.1455 0.1286 0.1240 0.1214 0.1197 0.1188 0.1181 0.1180 0.1176 0.1172 0.1176 0.1171 0.1169 0.1167 0.1164 \n",
            "\n",
            "[TRAIN] Epoch[1](79/1214); Loss: 0.124403; Backpropagation: 0.6059 sec; Batch: 4.4809 sec\n",
            "0.1760 0.1427 0.1302 0.1245 0.1215 0.1199 0.1190 0.1181 0.1181 0.1179 0.1175 0.1173 0.1170 0.1171 0.1168 0.1170 \n",
            "\n",
            "[TRAIN] Epoch[1](80/1214); Loss: 0.124640; Backpropagation: 0.6061 sec; Batch: 4.4728 sec\n",
            "0.1683 0.1381 0.1263 0.1225 0.1212 0.1207 0.1201 0.1199 0.1195 0.1196 0.1194 0.1195 0.1196 0.1198 0.1193 0.1204 \n",
            "\n",
            "[TRAIN] Epoch[1](81/1214); Loss: 0.108063; Backpropagation: 0.6107 sec; Batch: 4.4806 sec\n",
            "0.1661 0.1211 0.1100 0.1060 0.1042 0.1034 0.1025 0.1019 0.1020 0.1019 0.1016 0.1021 0.1018 0.1015 0.1017 0.1013 \n",
            "\n",
            "[TRAIN] Epoch[1](82/1214); Loss: 0.120052; Backpropagation: 0.6186 sec; Batch: 4.4941 sec\n",
            "0.2096 0.1490 0.1230 0.1149 0.1123 0.1119 0.1108 0.1105 0.1100 0.1099 0.1097 0.1097 0.1097 0.1098 0.1099 0.1102 \n",
            "\n",
            "[TRAIN] Epoch[1](83/1214); Loss: 0.101570; Backpropagation: 0.6076 sec; Batch: 4.4818 sec\n",
            "0.1590 0.1199 0.1054 0.0996 0.0978 0.0967 0.0961 0.0956 0.0960 0.0947 0.0945 0.0942 0.0941 0.0938 0.0939 0.0937 \n",
            "\n",
            "[TRAIN] Epoch[1](84/1214); Loss: 0.135402; Backpropagation: 0.6184 sec; Batch: 4.4924 sec\n",
            "0.1997 0.1499 0.1383 0.1340 0.1323 0.1308 0.1299 0.1291 0.1288 0.1281 0.1281 0.1279 0.1277 0.1275 0.1271 0.1272 \n",
            "\n",
            "[TRAIN] Epoch[1](85/1214); Loss: 0.106455; Backpropagation: 0.6072 sec; Batch: 4.4817 sec\n",
            "0.1534 0.1221 0.1105 0.1051 0.1037 0.1031 0.1021 0.1016 0.1011 0.1008 0.1002 0.1002 0.1000 0.0999 0.0996 0.0998 \n",
            "\n",
            "[TRAIN] Epoch[1](86/1214); Loss: 0.100545; Backpropagation: 0.6126 sec; Batch: 4.4857 sec\n",
            "0.1570 0.1215 0.1067 0.1021 0.0989 0.0972 0.0958 0.0954 0.0937 0.0928 0.0926 0.0919 0.0915 0.0910 0.0905 0.0901 \n",
            "\n",
            "[TRAIN] Epoch[1](87/1214); Loss: 0.110615; Backpropagation: 0.6100 sec; Batch: 4.4846 sec\n",
            "0.1672 0.1258 0.1137 0.1104 0.1082 0.1065 0.1059 0.1042 0.1044 0.1036 0.1040 0.1034 0.1035 0.1029 0.1030 0.1031 \n",
            "\n",
            "[TRAIN] Epoch[1](88/1214); Loss: 0.101069; Backpropagation: 0.6094 sec; Batch: 4.4822 sec\n",
            "0.1714 0.1135 0.1040 0.1018 0.0972 0.0949 0.0950 0.0937 0.0941 0.0936 0.0932 0.0933 0.0928 0.0928 0.0925 0.0932 \n",
            "\n",
            "[TRAIN] Epoch[1](89/1214); Loss: 0.089404; Backpropagation: 0.6145 sec; Batch: 4.4904 sec\n",
            "0.1523 0.1035 0.0907 0.0871 0.0843 0.0834 0.0831 0.0831 0.0832 0.0829 0.0827 0.0828 0.0830 0.0831 0.0827 0.0826 \n",
            "\n",
            "[TRAIN] Epoch[1](90/1214); Loss: 0.100038; Backpropagation: 0.6106 sec; Batch: 4.4829 sec\n",
            "0.1706 0.1182 0.1039 0.0990 0.0962 0.0948 0.0930 0.0928 0.0919 0.0918 0.0921 0.0916 0.0922 0.0913 0.0909 0.0902 \n",
            "\n",
            "[TRAIN] Epoch[1](91/1214); Loss: 0.099108; Backpropagation: 0.6150 sec; Batch: 4.4881 sec\n",
            "0.1646 0.1122 0.1017 0.0978 0.0950 0.0943 0.0932 0.0931 0.0928 0.0925 0.0920 0.0917 0.0911 0.0911 0.0914 0.0912 \n",
            "\n",
            "[TRAIN] Epoch[1](92/1214); Loss: 0.108748; Backpropagation: 0.6269 sec; Batch: 4.5047 sec\n",
            "0.1570 0.1223 0.1140 0.1110 0.1072 0.1061 0.1037 0.1038 0.1023 0.1029 0.1024 0.1018 0.1013 0.1009 0.1014 0.1017 \n",
            "\n",
            "[TRAIN] Epoch[1](93/1214); Loss: 0.086802; Backpropagation: 0.6098 sec; Batch: 4.4820 sec\n",
            "0.1472 0.0997 0.0884 0.0858 0.0828 0.0829 0.0808 0.0809 0.0817 0.0811 0.0801 0.0797 0.0795 0.0791 0.0793 0.0800 \n",
            "\n",
            "[TRAIN] Epoch[1](94/1214); Loss: 0.107427; Backpropagation: 0.6106 sec; Batch: 4.4844 sec\n",
            "0.1499 0.1223 0.1136 0.1091 0.1073 0.1053 0.1045 0.1025 0.1024 0.1012 0.1010 0.0998 0.1008 0.0999 0.0999 0.0992 \n",
            "\n",
            "[TRAIN] Epoch[1](95/1214); Loss: 0.100625; Backpropagation: 0.6134 sec; Batch: 4.4847 sec\n",
            "0.1436 0.1125 0.1042 0.1028 0.0997 0.0982 0.0968 0.0970 0.0956 0.0954 0.0950 0.0944 0.0939 0.0936 0.0940 0.0935 \n",
            "\n",
            "[TRAIN] Epoch[1](96/1214); Loss: 0.102058; Backpropagation: 0.6155 sec; Batch: 4.4880 sec\n",
            "0.1453 0.1171 0.1074 0.1031 0.1017 0.0993 0.0977 0.0968 0.0968 0.0962 0.0958 0.0955 0.0950 0.0953 0.0949 0.0951 \n",
            "\n",
            "[TRAIN] Epoch[1](97/1214); Loss: 0.099958; Backpropagation: 0.6206 sec; Batch: 4.4916 sec\n",
            "0.1609 0.1194 0.1089 0.1024 0.0982 0.0970 0.0945 0.0939 0.0919 0.0909 0.0906 0.0906 0.0903 0.0898 0.0900 0.0900 \n",
            "\n",
            "[TRAIN] Epoch[1](98/1214); Loss: 0.105595; Backpropagation: 0.6160 sec; Batch: 4.4907 sec\n",
            "0.1624 0.1216 0.1133 0.1068 0.1050 0.1030 0.1008 0.0996 0.0985 0.0982 0.0973 0.0970 0.0964 0.0965 0.0965 0.0967 \n",
            "\n",
            "[TRAIN] Epoch[1](99/1214); Loss: 0.116515; Backpropagation: 0.6117 sec; Batch: 4.4789 sec\n",
            "0.1670 0.1419 0.1376 0.1205 0.1128 0.1103 0.1094 0.1092 0.1068 0.1079 0.1075 0.1067 0.1065 0.1068 0.1063 0.1069 \n",
            "\n",
            "[TRAIN] Epoch[1](100/1214); Loss: 0.125172; Backpropagation: 0.6098 sec; Batch: 4.4818 sec\n",
            "0.1740 0.1414 0.1729 0.1478 0.1224 0.1111 0.1099 0.1160 0.1139 0.1156 0.1148 0.1160 0.1145 0.1130 0.1099 0.1096 \n",
            "\n",
            "[TRAIN] Epoch[1](101/1214); Loss: 0.114134; Backpropagation: 0.6184 sec; Batch: 4.4909 sec\n",
            "0.1551 0.1388 0.1555 0.1332 0.1133 0.1080 0.1065 0.1067 0.1032 0.1013 0.1010 0.1011 0.1013 0.1000 0.1014 0.1000 \n",
            "\n",
            "[TRAIN] Epoch[1](102/1214); Loss: 0.103517; Backpropagation: 0.6094 sec; Batch: 4.4849 sec\n",
            "0.1526 0.1311 0.1275 0.1089 0.1033 0.1011 0.0965 0.0957 0.0956 0.0929 0.0928 0.0922 0.0917 0.0914 0.0917 0.0915 \n",
            "\n",
            "[TRAIN] Epoch[1](103/1214); Loss: 0.111906; Backpropagation: 0.6101 sec; Batch: 4.4826 sec\n",
            "0.1772 0.1498 0.1279 0.1191 0.1091 0.1063 0.1030 0.1029 0.1020 0.1002 0.0999 0.0990 0.0984 0.0997 0.0978 0.0982 \n",
            "\n",
            "[TRAIN] Epoch[1](104/1214); Loss: 0.122530; Backpropagation: 0.6147 sec; Batch: 4.4936 sec\n",
            "0.1749 0.1535 0.1399 0.1290 0.1205 0.1173 0.1157 0.1140 0.1141 0.1126 0.1117 0.1118 0.1124 0.1117 0.1104 0.1111 \n",
            "\n",
            "[TRAIN] Epoch[1](105/1214); Loss: 0.121836; Backpropagation: 0.6136 sec; Batch: 4.4871 sec\n",
            "0.1774 0.1571 0.1390 0.1339 0.1230 0.1188 0.1144 0.1133 0.1115 0.1105 0.1098 0.1088 0.1082 0.1079 0.1081 0.1076 \n",
            "\n",
            "[TRAIN] Epoch[1](106/1214); Loss: 0.112254; Backpropagation: 0.6106 sec; Batch: 4.4900 sec\n",
            "0.1509 0.1550 0.1289 0.1285 0.1171 0.1126 0.1067 0.1042 0.1023 0.1004 0.0998 0.0989 0.0982 0.0980 0.0974 0.0971 \n",
            "\n",
            "[TRAIN] Epoch[1](107/1214); Loss: 0.107445; Backpropagation: 0.6206 sec; Batch: 4.4905 sec\n",
            "0.1411 0.1359 0.1208 0.1162 0.1106 0.1061 0.1026 0.1014 0.0993 0.0985 0.0983 0.0977 0.0976 0.0976 0.0974 0.0979 \n",
            "\n",
            "[TRAIN] Epoch[1](108/1214); Loss: 0.108120; Backpropagation: 0.6233 sec; Batch: 4.4927 sec\n",
            "0.1623 0.1366 0.1177 0.1143 0.1070 0.1033 0.1013 0.1002 0.0988 0.0973 0.1000 0.0975 0.0984 0.0984 0.0978 0.0990 \n",
            "\n",
            "[TRAIN] Epoch[1](109/1214); Loss: 0.098265; Backpropagation: 0.6110 sec; Batch: 4.4717 sec\n",
            "0.1597 0.1293 0.1143 0.1050 0.0987 0.0956 0.0910 0.0894 0.0878 0.0865 0.0860 0.0861 0.0861 0.0852 0.0858 0.0858 \n",
            "\n",
            "[TRAIN] Epoch[1](110/1214); Loss: 0.101132; Backpropagation: 0.6251 sec; Batch: 4.4987 sec\n",
            "0.1617 0.1385 0.1164 0.1085 0.0987 0.0960 0.0934 0.0906 0.0899 0.0891 0.0888 0.0890 0.0889 0.0894 0.0892 0.0899 \n",
            "\n",
            "[TRAIN] Epoch[1](111/1214); Loss: 0.100973; Backpropagation: 0.6111 sec; Batch: 4.4865 sec\n",
            "0.1565 0.1403 0.1158 0.1054 0.1000 0.0955 0.0931 0.0909 0.0896 0.0895 0.0898 0.0895 0.0898 0.0904 0.0899 0.0896 \n",
            "\n",
            "[TRAIN] Epoch[1](112/1214); Loss: 0.111000; Backpropagation: 0.6105 sec; Batch: 4.4835 sec\n",
            "0.1852 0.1438 0.1258 0.1150 0.1101 0.1057 0.1058 0.1038 0.1006 0.0996 0.0993 0.0974 0.0969 0.0961 0.0959 0.0951 \n",
            "\n",
            "[TRAIN] Epoch[1](113/1214); Loss: 0.099832; Backpropagation: 0.6084 sec; Batch: 4.4812 sec\n",
            "0.1651 0.1408 0.1148 0.1048 0.0978 0.0960 0.0925 0.0903 0.0887 0.0869 0.0861 0.0857 0.0862 0.0863 0.0874 0.0878 \n",
            "\n",
            "[TRAIN] Epoch[1](114/1214); Loss: 0.092389; Backpropagation: 0.6171 sec; Batch: 4.4871 sec\n",
            "0.1609 0.1336 0.1064 0.0955 0.0915 0.0872 0.0841 0.0828 0.0808 0.0807 0.0795 0.0785 0.0787 0.0789 0.0793 0.0797 \n",
            "\n",
            "[TRAIN] Epoch[1](115/1214); Loss: 0.097785; Backpropagation: 0.6131 sec; Batch: 4.4863 sec\n",
            "0.1431 0.1254 0.1092 0.1009 0.0991 0.0949 0.0926 0.0901 0.0898 0.0900 0.0893 0.0878 0.0876 0.0880 0.0883 0.0884 \n",
            "\n",
            "[TRAIN] Epoch[1](116/1214); Loss: 0.089202; Backpropagation: 0.6213 sec; Batch: 4.4992 sec\n",
            "0.1805 0.1275 0.1010 0.0898 0.0863 0.0815 0.0790 0.0764 0.0750 0.0743 0.0752 0.0751 0.0760 0.0754 0.0770 0.0771 \n",
            "\n",
            "[TRAIN] Epoch[1](117/1214); Loss: 0.085975; Backpropagation: 0.6105 sec; Batch: 4.4804 sec\n",
            "0.1480 0.1142 0.0999 0.0902 0.0862 0.0825 0.0793 0.0769 0.0756 0.0753 0.0747 0.0745 0.0744 0.0750 0.0743 0.0746 \n",
            "\n",
            "[TRAIN] Epoch[1](118/1214); Loss: 0.103990; Backpropagation: 0.6134 sec; Batch: 4.4894 sec\n",
            "0.1747 0.1414 0.1165 0.1058 0.1027 0.0994 0.0987 0.0962 0.0951 0.0931 0.0918 0.0903 0.0898 0.0900 0.0890 0.0895 \n",
            "\n",
            "[TRAIN] Epoch[1](119/1214); Loss: 0.097062; Backpropagation: 0.6070 sec; Batch: 4.4794 sec\n",
            "0.1745 0.1357 0.1115 0.1016 0.0968 0.0924 0.0901 0.0870 0.0859 0.0853 0.0840 0.0831 0.0819 0.0813 0.0804 0.0815 \n",
            "\n",
            "[TRAIN] Epoch[1](120/1214); Loss: 0.092505; Backpropagation: 0.6198 sec; Batch: 4.4940 sec\n",
            "0.1557 0.1306 0.1071 0.0948 0.0912 0.0892 0.0869 0.0849 0.0827 0.0821 0.0805 0.0805 0.0798 0.0783 0.0779 0.0779 \n",
            "\n",
            "[TRAIN] Epoch[1](121/1214); Loss: 0.101186; Backpropagation: 0.6096 sec; Batch: 4.4837 sec\n",
            "0.1622 0.1352 0.1179 0.1055 0.1017 0.0965 0.0939 0.0915 0.0909 0.0903 0.0898 0.0891 0.0891 0.0887 0.0886 0.0883 \n",
            "\n",
            "[TRAIN] Epoch[1](122/1214); Loss: 0.100630; Backpropagation: 0.6189 sec; Batch: 4.4988 sec\n",
            "0.1630 0.1320 0.1118 0.1057 0.0992 0.0964 0.0938 0.0922 0.0907 0.0904 0.0892 0.0894 0.0890 0.0894 0.0890 0.0888 \n",
            "\n",
            "[TRAIN] Epoch[1](123/1214); Loss: 0.118038; Backpropagation: 0.6180 sec; Batch: 4.4932 sec\n",
            "0.1864 0.1600 0.1343 0.1241 0.1158 0.1123 0.1092 0.1073 0.1078 0.1071 0.1055 0.1041 0.1047 0.1033 0.1036 0.1030 \n",
            "\n",
            "[TRAIN] Epoch[1](124/1214); Loss: 0.099485; Backpropagation: 0.6101 sec; Batch: 4.4923 sec\n",
            "0.1577 0.1308 0.1112 0.1043 0.0975 0.0954 0.0935 0.0928 0.0910 0.0895 0.0895 0.0884 0.0880 0.0875 0.0872 0.0874 \n",
            "\n",
            "[TRAIN] Epoch[1](125/1214); Loss: 0.098160; Backpropagation: 0.6159 sec; Batch: 4.4904 sec\n",
            "0.1749 0.1362 0.1105 0.1021 0.0952 0.0927 0.0894 0.0871 0.0863 0.0853 0.0846 0.0840 0.0850 0.0851 0.0858 0.0864 \n",
            "\n",
            "[TRAIN] Epoch[1](126/1214); Loss: 0.100628; Backpropagation: 0.6124 sec; Batch: 4.4836 sec\n",
            "0.1606 0.1346 0.1189 0.1108 0.1025 0.0983 0.0938 0.0908 0.0891 0.0876 0.0871 0.0865 0.0864 0.0874 0.0881 0.0876 \n",
            "\n",
            "[TRAIN] Epoch[1](127/1214); Loss: 0.095332; Backpropagation: 0.6242 sec; Batch: 4.4989 sec\n",
            "0.1569 0.1195 0.1030 0.0991 0.0961 0.0923 0.0903 0.0890 0.0877 0.0864 0.0855 0.0844 0.0844 0.0838 0.0833 0.0835 \n",
            "\n",
            "[TRAIN] Epoch[1](128/1214); Loss: 0.087082; Backpropagation: 0.6107 sec; Batch: 4.4837 sec\n",
            "0.1501 0.1134 0.0985 0.0908 0.0853 0.0814 0.0794 0.0784 0.0770 0.0773 0.0770 0.0762 0.0767 0.0764 0.0772 0.0782 \n",
            "\n",
            "[TRAIN] Epoch[1](129/1214); Loss: 0.096966; Backpropagation: 0.6159 sec; Batch: 4.4898 sec\n",
            "0.1521 0.1237 0.1135 0.1080 0.0997 0.0936 0.0921 0.0876 0.0869 0.0858 0.0850 0.0842 0.0842 0.0859 0.0848 0.0842 \n",
            "\n",
            "[TRAIN] Epoch[1](130/1214); Loss: 0.095627; Backpropagation: 0.6108 sec; Batch: 4.4831 sec\n",
            "0.1667 0.1256 0.1096 0.1026 0.0951 0.0921 0.0878 0.0855 0.0838 0.0840 0.0836 0.0832 0.0835 0.0827 0.0824 0.0820 \n",
            "\n",
            "[TRAIN] Epoch[1](131/1214); Loss: 0.087185; Backpropagation: 0.6065 sec; Batch: 4.4759 sec\n",
            "0.1589 0.1185 0.1039 0.0951 0.0860 0.0823 0.0793 0.0770 0.0772 0.0745 0.0739 0.0737 0.0738 0.0735 0.0736 0.0737 \n",
            "\n",
            "[TRAIN] Epoch[1](132/1214); Loss: 0.087881; Backpropagation: 0.6123 sec; Batch: 4.4910 sec\n",
            "0.1366 0.1194 0.1055 0.0975 0.0886 0.0839 0.0807 0.0782 0.0776 0.0767 0.0778 0.0772 0.0770 0.0765 0.0770 0.0759 \n",
            "\n",
            "[TRAIN] Epoch[1](133/1214); Loss: 0.103233; Backpropagation: 0.6089 sec; Batch: 4.4819 sec\n",
            "0.1567 0.1348 0.1190 0.1110 0.1055 0.1011 0.0989 0.0958 0.0936 0.0929 0.0914 0.0915 0.0898 0.0903 0.0898 0.0898 \n",
            "\n",
            "[TRAIN] Epoch[1](134/1214); Loss: 0.096847; Backpropagation: 0.6186 sec; Batch: 4.4896 sec\n",
            "0.1612 0.1325 0.1080 0.1000 0.0936 0.0906 0.0882 0.0875 0.0864 0.0869 0.0868 0.0866 0.0854 0.0847 0.0848 0.0862 \n",
            "\n",
            "[TRAIN] Epoch[1](135/1214); Loss: 0.104413; Backpropagation: 0.6183 sec; Batch: 4.4901 sec\n",
            "0.1817 0.1486 0.1224 0.1138 0.1061 0.1028 0.0994 0.0940 0.0925 0.0904 0.0889 0.0876 0.0868 0.0858 0.0850 0.0847 \n",
            "\n",
            "[TRAIN] Epoch[1](136/1214); Loss: 0.085408; Backpropagation: 0.6202 sec; Batch: 4.4921 sec\n",
            "0.1497 0.1147 0.0979 0.0892 0.0829 0.0783 0.0787 0.0762 0.0758 0.0753 0.0752 0.0745 0.0746 0.0745 0.0745 0.0744 \n",
            "\n",
            "[TRAIN] Epoch[1](137/1214); Loss: 0.081724; Backpropagation: 0.6128 sec; Batch: 4.4855 sec\n",
            "0.1390 0.1134 0.0989 0.0908 0.0857 0.0787 0.0745 0.0722 0.0713 0.0696 0.0691 0.0689 0.0684 0.0689 0.0691 0.0691 \n",
            "\n",
            "[TRAIN] Epoch[1](138/1214); Loss: 0.087922; Backpropagation: 0.6107 sec; Batch: 4.4846 sec\n",
            "0.1481 0.1192 0.1032 0.0941 0.0871 0.0830 0.0808 0.0791 0.0779 0.0768 0.0767 0.0765 0.0758 0.0761 0.0768 0.0756 \n",
            "\n",
            "[TRAIN] Epoch[1](139/1214); Loss: 0.101496; Backpropagation: 0.6115 sec; Batch: 4.4858 sec\n",
            "0.1489 0.1269 0.1138 0.1067 0.1023 0.0995 0.0982 0.0955 0.0943 0.0925 0.0913 0.0915 0.0905 0.0904 0.0909 0.0907 \n",
            "\n",
            "[TRAIN] Epoch[1](140/1214); Loss: 0.085998; Backpropagation: 0.6120 sec; Batch: 4.4910 sec\n",
            "0.1461 0.1151 0.1000 0.0920 0.0845 0.0793 0.0774 0.0767 0.0761 0.0762 0.0757 0.0756 0.0753 0.0751 0.0754 0.0754 \n",
            "\n",
            "[TRAIN] Epoch[1](141/1214); Loss: 0.086541; Backpropagation: 0.6166 sec; Batch: 4.4907 sec\n",
            "0.1624 0.1226 0.1028 0.0921 0.0841 0.0796 0.0779 0.0759 0.0753 0.0740 0.0738 0.0733 0.0729 0.0722 0.0726 0.0731 \n",
            "\n",
            "[TRAIN] Epoch[1](142/1214); Loss: 0.092450; Backpropagation: 0.6107 sec; Batch: 4.4892 sec\n",
            "0.1385 0.1091 0.1035 0.0932 0.0924 0.0877 0.0874 0.0870 0.0836 0.0843 0.0850 0.0850 0.0846 0.0852 0.0856 0.0868 \n",
            "\n",
            "[TRAIN] Epoch[1](143/1214); Loss: 0.104505; Backpropagation: 0.6224 sec; Batch: 4.5018 sec\n",
            "0.1432 0.1223 0.1148 0.1125 0.1055 0.1081 0.1022 0.0997 0.0979 0.0966 0.0959 0.0951 0.0944 0.0953 0.0935 0.0951 \n",
            "\n",
            "[TRAIN] Epoch[1](144/1214); Loss: 0.102518; Backpropagation: 0.6161 sec; Batch: 4.4928 sec\n",
            "0.1578 0.1188 0.1183 0.1153 0.1120 0.1017 0.1013 0.0934 0.0939 0.0921 0.0904 0.0903 0.0870 0.0913 0.0880 0.0887 \n",
            "\n",
            "[TRAIN] Epoch[1](145/1214); Loss: 0.120715; Backpropagation: 0.6156 sec; Batch: 4.4872 sec\n",
            "0.1394 0.1319 0.1330 0.1411 0.1242 0.1241 0.1204 0.1179 0.1133 0.1135 0.1105 0.1151 0.1113 0.1116 0.1101 0.1140 \n",
            "\n",
            "[TRAIN] Epoch[1](146/1214); Loss: 0.140092; Backpropagation: 0.6185 sec; Batch: 4.4938 sec\n",
            "0.1565 0.1633 0.1624 0.1741 0.1494 0.1466 0.1361 0.1380 0.1325 0.1302 0.1282 0.1253 0.1262 0.1282 0.1247 0.1197 \n",
            "\n",
            "[TRAIN] Epoch[1](147/1214); Loss: 0.113848; Backpropagation: 0.6132 sec; Batch: 4.4864 sec\n",
            "0.1461 0.1313 0.1294 0.1283 0.1181 0.1150 0.1101 0.1102 0.1061 0.1050 0.1048 0.1025 0.1026 0.1034 0.1040 0.1046 \n",
            "\n",
            "[TRAIN] Epoch[1](148/1214); Loss: 0.111815; Backpropagation: 0.6198 sec; Batch: 4.4910 sec\n",
            "0.1623 0.1279 0.1236 0.1181 0.1108 0.1093 0.1045 0.1047 0.1030 0.1017 0.1014 0.1050 0.1014 0.1039 0.1034 0.1081 \n",
            "\n",
            "[TRAIN] Epoch[1](149/1214); Loss: 0.124898; Backpropagation: 0.6113 sec; Batch: 4.4840 sec\n",
            "0.1797 0.1500 0.1397 0.1371 0.1278 0.1290 0.1179 0.1190 0.1131 0.1143 0.1098 0.1125 0.1086 0.1140 0.1103 0.1154 \n",
            "\n",
            "[TRAIN] Epoch[1](150/1214); Loss: 0.105254; Backpropagation: 0.6143 sec; Batch: 4.4914 sec\n",
            "0.1498 0.1194 0.1125 0.1097 0.1043 0.1018 0.0967 0.0987 0.0974 0.0981 0.0964 0.0990 0.0972 0.1003 0.1000 0.1027 \n",
            "\n",
            "[TRAIN] Epoch[1](151/1214); Loss: 0.110054; Backpropagation: 0.6175 sec; Batch: 4.4930 sec\n",
            "0.1681 0.1392 0.1233 0.1159 0.1088 0.1094 0.1033 0.1050 0.0980 0.1000 0.0964 0.0993 0.0971 0.0990 0.0981 0.0999 \n",
            "\n",
            "[TRAIN] Epoch[1](152/1214); Loss: 0.101943; Backpropagation: 0.6215 sec; Batch: 4.5037 sec\n",
            "0.1485 0.1295 0.1112 0.1084 0.1014 0.1021 0.0972 0.0970 0.0920 0.0926 0.0912 0.0907 0.0919 0.0912 0.0935 0.0928 \n",
            "\n",
            "[TRAIN] Epoch[1](153/1214); Loss: 0.108444; Backpropagation: 0.6132 sec; Batch: 4.4892 sec\n",
            "0.1626 0.1365 0.1219 0.1177 0.1089 0.1069 0.1018 0.1016 0.0989 0.0995 0.0964 0.0968 0.0960 0.0966 0.0961 0.0970 \n",
            "\n",
            "[TRAIN] Epoch[1](154/1214); Loss: 0.109288; Backpropagation: 0.6120 sec; Batch: 4.4911 sec\n",
            "0.1725 0.1414 0.1246 0.1175 0.1089 0.1085 0.1065 0.1042 0.0981 0.0979 0.0950 0.0963 0.0935 0.0956 0.0936 0.0944 \n",
            "\n",
            "[TRAIN] Epoch[1](155/1214); Loss: 0.093263; Backpropagation: 0.6076 sec; Batch: 4.4799 sec\n",
            "0.1495 0.1265 0.1070 0.1003 0.0929 0.0924 0.0848 0.0852 0.0812 0.0826 0.0813 0.0811 0.0807 0.0821 0.0814 0.0831 \n",
            "\n",
            "[TRAIN] Epoch[1](156/1214); Loss: 0.124739; Backpropagation: 0.6165 sec; Batch: 4.4839 sec\n",
            "0.1867 0.1562 0.1396 0.1328 0.1238 0.1216 0.1182 0.1172 0.1138 0.1150 0.1129 0.1120 0.1121 0.1110 0.1118 0.1108 \n",
            "\n",
            "[TRAIN] Epoch[1](157/1214); Loss: 0.100441; Backpropagation: 0.6108 sec; Batch: 4.4846 sec\n",
            "0.1564 0.1307 0.1122 0.1067 0.1022 0.0968 0.0960 0.0923 0.0912 0.0892 0.0887 0.0894 0.0886 0.0892 0.0886 0.0888 \n",
            "\n",
            "[TRAIN] Epoch[1](158/1214); Loss: 0.102064; Backpropagation: 0.6145 sec; Batch: 4.4908 sec\n",
            "0.1425 0.1266 0.1155 0.1072 0.1055 0.1029 0.0990 0.0990 0.0958 0.0939 0.0917 0.0908 0.0905 0.0904 0.0912 0.0908 \n",
            "\n",
            "[TRAIN] Epoch[1](159/1214); Loss: 0.106917; Backpropagation: 0.6101 sec; Batch: 4.4861 sec\n",
            "0.1736 0.1390 0.1212 0.1135 0.1098 0.1066 0.1012 0.0982 0.0961 0.0950 0.0940 0.0935 0.0933 0.0927 0.0917 0.0914 \n",
            "\n",
            "[TRAIN] Epoch[1](160/1214); Loss: 0.099960; Backpropagation: 0.6183 sec; Batch: 4.4973 sec\n",
            "0.1457 0.1340 0.1158 0.1072 0.1022 0.0997 0.0963 0.0932 0.0908 0.0896 0.0890 0.0881 0.0872 0.0872 0.0866 0.0869 \n",
            "\n",
            "[TRAIN] Epoch[1](161/1214); Loss: 0.101589; Backpropagation: 0.6238 sec; Batch: 4.4969 sec\n",
            "0.1567 0.1322 0.1155 0.1084 0.1039 0.0992 0.0969 0.0937 0.0911 0.0899 0.0898 0.0898 0.0895 0.0892 0.0899 0.0899 \n",
            "\n",
            "[TRAIN] Epoch[1](162/1214); Loss: 0.106971; Backpropagation: 0.6083 sec; Batch: 4.4863 sec\n",
            "0.1831 0.1496 0.1288 0.1157 0.1057 0.1032 0.0984 0.0972 0.0941 0.0928 0.0923 0.0908 0.0904 0.0908 0.0890 0.0896 \n",
            "\n",
            "[TRAIN] Epoch[1](163/1214); Loss: 0.103793; Backpropagation: 0.6234 sec; Batch: 4.4932 sec\n",
            "0.1823 0.1505 0.1240 0.1107 0.1014 0.0998 0.0956 0.0934 0.0922 0.0902 0.0889 0.0882 0.0873 0.0865 0.0850 0.0847 \n",
            "\n",
            "[TRAIN] Epoch[1](164/1214); Loss: 0.114684; Backpropagation: 0.6196 sec; Batch: 4.4952 sec\n",
            "0.1919 0.1532 0.1314 0.1229 0.1159 0.1131 0.1074 0.1065 0.1041 0.1021 0.1013 0.0999 0.0974 0.0962 0.0964 0.0955 \n",
            "\n",
            "[TRAIN] Epoch[1](165/1214); Loss: 0.096432; Backpropagation: 0.6223 sec; Batch: 4.4951 sec\n",
            "0.1763 0.1474 0.1203 0.1016 0.0937 0.0899 0.0870 0.0847 0.0823 0.0818 0.0805 0.0808 0.0793 0.0786 0.0788 0.0799 \n",
            "\n",
            "[TRAIN] Epoch[1](166/1214); Loss: 0.101430; Backpropagation: 0.6095 sec; Batch: 4.4813 sec\n",
            "0.1726 0.1385 0.1232 0.1068 0.0998 0.0968 0.0949 0.0915 0.0906 0.0889 0.0879 0.0870 0.0859 0.0862 0.0859 0.0865 \n",
            "\n",
            "[TRAIN] Epoch[1](167/1214); Loss: 0.094721; Backpropagation: 0.6073 sec; Batch: 4.4797 sec\n",
            "0.1495 0.1278 0.1092 0.0981 0.0933 0.0913 0.0892 0.0865 0.0843 0.0856 0.0837 0.0836 0.0835 0.0829 0.0828 0.0842 \n",
            "\n",
            "[TRAIN] Epoch[1](168/1214); Loss: 0.090601; Backpropagation: 0.6244 sec; Batch: 4.4982 sec\n",
            "0.1557 0.1265 0.1124 0.0961 0.0887 0.0836 0.0823 0.0810 0.0795 0.0785 0.0786 0.0774 0.0776 0.0775 0.0773 0.0771 \n",
            "\n",
            "[TRAIN] Epoch[1](169/1214); Loss: 0.089625; Backpropagation: 0.6176 sec; Batch: 4.4971 sec\n",
            "0.1749 0.1230 0.1048 0.0898 0.0860 0.0821 0.0800 0.0793 0.0784 0.0767 0.0759 0.0756 0.0764 0.0776 0.0771 0.0765 \n",
            "\n",
            "[TRAIN] Epoch[1](170/1214); Loss: 0.099273; Backpropagation: 0.6124 sec; Batch: 4.4853 sec\n",
            "0.1667 0.1280 0.1133 0.1028 0.0964 0.0934 0.0915 0.0899 0.0890 0.0886 0.0878 0.0881 0.0879 0.0883 0.0887 0.0880 \n",
            "\n",
            "[TRAIN] Epoch[1](171/1214); Loss: 0.097259; Backpropagation: 0.6145 sec; Batch: 4.4845 sec\n",
            "0.1607 0.1300 0.1121 0.1035 0.0975 0.0932 0.0893 0.0870 0.0860 0.0848 0.0852 0.0841 0.0841 0.0853 0.0858 0.0874 \n",
            "\n",
            "[TRAIN] Epoch[1](172/1214); Loss: 0.099877; Backpropagation: 0.6203 sec; Batch: 4.4972 sec\n",
            "0.1781 0.1423 0.1155 0.1038 0.0962 0.0911 0.0881 0.0883 0.0872 0.0868 0.0870 0.0864 0.0861 0.0875 0.0867 0.0872 \n",
            "\n",
            "[TRAIN] Epoch[1](173/1214); Loss: 0.093005; Backpropagation: 0.6220 sec; Batch: 4.4929 sec\n",
            "0.1901 0.1278 0.1108 0.0999 0.0908 0.0874 0.0838 0.0801 0.0784 0.0781 0.0778 0.0775 0.0767 0.0759 0.0766 0.0763 \n",
            "\n",
            "[TRAIN] Epoch[1](174/1214); Loss: 0.088029; Backpropagation: 0.6126 sec; Batch: 4.4873 sec\n",
            "0.1496 0.1136 0.1033 0.0931 0.0861 0.0827 0.0796 0.0790 0.0777 0.0783 0.0780 0.0773 0.0775 0.0773 0.0777 0.0776 \n",
            "\n",
            "[TRAIN] Epoch[1](175/1214); Loss: 0.087652; Backpropagation: 0.6187 sec; Batch: 4.4878 sec\n",
            "0.1614 0.1154 0.1015 0.0919 0.0864 0.0823 0.0782 0.0771 0.0769 0.0758 0.0758 0.0756 0.0754 0.0760 0.0764 0.0763 \n",
            "\n",
            "[TRAIN] Epoch[1](176/1214); Loss: 0.083586; Backpropagation: 0.6138 sec; Batch: 4.4882 sec\n",
            "0.1560 0.1184 0.1032 0.0931 0.0869 0.0802 0.0751 0.0738 0.0699 0.0697 0.0691 0.0682 0.0684 0.0695 0.0686 0.0673 \n",
            "\n",
            "[TRAIN] Epoch[1](177/1214); Loss: 0.095802; Backpropagation: 0.6192 sec; Batch: 4.4906 sec\n",
            "0.1612 0.1310 0.1135 0.1016 0.0950 0.0932 0.0879 0.0863 0.0849 0.0837 0.0831 0.0825 0.0822 0.0821 0.0830 0.0817 \n",
            "\n",
            "[TRAIN] Epoch[1](178/1214); Loss: 0.093718; Backpropagation: 0.6117 sec; Batch: 4.4850 sec\n",
            "0.1580 0.1181 0.1121 0.0996 0.0942 0.0911 0.0859 0.0847 0.0831 0.0825 0.0820 0.0822 0.0814 0.0815 0.0811 0.0820 \n",
            "\n",
            "[TRAIN] Epoch[1](179/1214); Loss: 0.100579; Backpropagation: 0.6125 sec; Batch: 4.4950 sec\n",
            "0.1579 0.1271 0.1175 0.1109 0.1017 0.0971 0.0935 0.0921 0.0908 0.0893 0.0884 0.0881 0.0890 0.0882 0.0888 0.0889 \n",
            "\n",
            "[TRAIN] Epoch[1](180/1214); Loss: 0.099594; Backpropagation: 0.6120 sec; Batch: 4.4870 sec\n",
            "0.1515 0.1268 0.1175 0.1130 0.1063 0.1003 0.0963 0.0919 0.0891 0.0878 0.0874 0.0851 0.0847 0.0849 0.0852 0.0858 \n",
            "\n",
            "[TRAIN] Epoch[1](181/1214); Loss: 0.088969; Backpropagation: 0.6079 sec; Batch: 4.4799 sec\n",
            "0.1688 0.1239 0.1102 0.0988 0.0911 0.0866 0.0810 0.0785 0.0756 0.0738 0.0732 0.0731 0.0727 0.0719 0.0720 0.0723 \n",
            "\n",
            "[TRAIN] Epoch[1](182/1214); Loss: 0.093005; Backpropagation: 0.6182 sec; Batch: 4.4865 sec\n",
            "0.1695 0.1215 0.1130 0.1006 0.0936 0.0873 0.0832 0.0821 0.0806 0.0793 0.0795 0.0787 0.0795 0.0799 0.0799 0.0799 \n",
            "\n",
            "[TRAIN] Epoch[1](183/1214); Loss: 0.089872; Backpropagation: 0.6098 sec; Batch: 4.4818 sec\n",
            "0.1614 0.1202 0.1114 0.1006 0.0954 0.0873 0.0867 0.0819 0.0776 0.0754 0.0743 0.0733 0.0732 0.0728 0.0728 0.0737 \n",
            "\n",
            "[TRAIN] Epoch[1](184/1214); Loss: 0.095965; Backpropagation: 0.6157 sec; Batch: 4.4929 sec\n",
            "0.1718 0.1339 0.1208 0.1138 0.1033 0.0916 0.0860 0.0834 0.0823 0.0813 0.0780 0.0776 0.0778 0.0777 0.0781 0.0779 \n",
            "\n",
            "[TRAIN] Epoch[1](185/1214); Loss: 0.091868; Backpropagation: 0.6128 sec; Batch: 4.4809 sec\n",
            "0.1662 0.1228 0.1183 0.1033 0.0966 0.0891 0.0870 0.0798 0.0778 0.0759 0.0759 0.0753 0.0753 0.0751 0.0759 0.0757 \n",
            "\n",
            "[TRAIN] Epoch[1](186/1214); Loss: 0.093691; Backpropagation: 0.6167 sec; Batch: 4.4902 sec\n",
            "0.1618 0.1264 0.1108 0.1026 0.0963 0.0910 0.0864 0.0838 0.0809 0.0799 0.0801 0.0795 0.0793 0.0799 0.0802 0.0801 \n",
            "\n",
            "[TRAIN] Epoch[1](187/1214); Loss: 0.098657; Backpropagation: 0.6158 sec; Batch: 4.4947 sec\n",
            "0.1711 0.1336 0.1197 0.1065 0.0984 0.0915 0.0891 0.0870 0.0862 0.0853 0.0841 0.0847 0.0846 0.0858 0.0852 0.0856 \n",
            "\n",
            "[TRAIN] Epoch[1](188/1214); Loss: 0.103316; Backpropagation: 0.6060 sec; Batch: 4.4790 sec\n",
            "0.1880 0.1459 0.1269 0.1204 0.1083 0.0985 0.0931 0.0889 0.0874 0.0855 0.0853 0.0848 0.0851 0.0857 0.0851 0.0844 \n",
            "\n",
            "[TRAIN] Epoch[1](189/1214); Loss: 0.084450; Backpropagation: 0.6107 sec; Batch: 4.4795 sec\n",
            "0.1559 0.1184 0.1002 0.0954 0.0856 0.0801 0.0754 0.0739 0.0721 0.0719 0.0705 0.0700 0.0701 0.0703 0.0707 0.0707 \n",
            "\n",
            "[TRAIN] Epoch[1](190/1214); Loss: 0.090993; Backpropagation: 0.6127 sec; Batch: 4.4873 sec\n",
            "0.1704 0.1261 0.1094 0.0972 0.0882 0.0826 0.0791 0.0788 0.0790 0.0789 0.0780 0.0782 0.0783 0.0781 0.0765 0.0772 \n",
            "\n",
            "[TRAIN] Epoch[1](191/1214); Loss: 0.096401; Backpropagation: 0.6178 sec; Batch: 4.4870 sec\n",
            "0.1785 0.1272 0.1107 0.1035 0.0933 0.0898 0.0863 0.0845 0.0838 0.0833 0.0835 0.0834 0.0844 0.0839 0.0831 0.0832 \n",
            "\n",
            "[TRAIN] Epoch[1](192/1214); Loss: 0.094890; Backpropagation: 0.6080 sec; Batch: 4.4771 sec\n",
            "0.1781 0.1338 0.1174 0.1031 0.0936 0.0873 0.0841 0.0813 0.0802 0.0799 0.0805 0.0802 0.0800 0.0792 0.0800 0.0795 \n",
            "\n",
            "[TRAIN] Epoch[1](193/1214); Loss: 0.083459; Backpropagation: 0.6107 sec; Batch: 4.4854 sec\n",
            "0.1669 0.1275 0.1049 0.0941 0.0827 0.0769 0.0720 0.0700 0.0686 0.0686 0.0679 0.0675 0.0672 0.0667 0.0671 0.0668 \n",
            "\n",
            "[TRAIN] Epoch[1](194/1214); Loss: 0.093785; Backpropagation: 0.6108 sec; Batch: 4.4836 sec\n",
            "0.1853 0.1392 0.1141 0.1036 0.0945 0.0888 0.0829 0.0798 0.0785 0.0773 0.0769 0.0761 0.0757 0.0763 0.0758 0.0758 \n",
            "\n",
            "[TRAIN] Epoch[1](195/1214); Loss: 0.086091; Backpropagation: 0.6088 sec; Batch: 4.4792 sec\n",
            "0.1542 0.1221 0.1012 0.0910 0.0845 0.0798 0.0769 0.0751 0.0740 0.0739 0.0740 0.0738 0.0737 0.0742 0.0744 0.0746 \n",
            "\n",
            "[TRAIN] Epoch[1](196/1214); Loss: 0.092837; Backpropagation: 0.6134 sec; Batch: 4.4871 sec\n",
            "0.1817 0.1493 0.1235 0.1049 0.0891 0.0836 0.0810 0.0812 0.0785 0.0757 0.0740 0.0736 0.0730 0.0728 0.0717 0.0718 \n",
            "\n",
            "[TRAIN] Epoch[1](197/1214); Loss: 0.089797; Backpropagation: 0.6095 sec; Batch: 4.4832 sec\n",
            "0.1731 0.1395 0.1116 0.0992 0.0888 0.0830 0.0799 0.0768 0.0739 0.0740 0.0732 0.0732 0.0736 0.0722 0.0723 0.0725 \n",
            "\n",
            "[TRAIN] Epoch[1](198/1214); Loss: 0.095466; Backpropagation: 0.6113 sec; Batch: 4.4840 sec\n",
            "0.1855 0.1528 0.1263 0.1081 0.0950 0.0883 0.0833 0.0804 0.0789 0.0775 0.0759 0.0751 0.0749 0.0750 0.0752 0.0751 \n",
            "\n",
            "[TRAIN] Epoch[1](199/1214); Loss: 0.105953; Backpropagation: 0.6177 sec; Batch: 4.4957 sec\n",
            "0.2020 0.1568 0.1330 0.1122 0.1057 0.0979 0.0945 0.0920 0.0904 0.0886 0.0877 0.0879 0.0868 0.0863 0.0866 0.0871 \n",
            "\n",
            "[TRAIN] Epoch[1](200/1214); Loss: 0.096841; Backpropagation: 0.6137 sec; Batch: 4.4864 sec\n",
            "0.1677 0.1350 0.1119 0.1069 0.0958 0.0928 0.0890 0.0873 0.0848 0.0830 0.0829 0.0822 0.0823 0.0825 0.0825 0.0828 \n",
            "\n",
            "[TRAIN] Epoch[1](201/1214); Loss: 0.105045; Backpropagation: 0.6095 sec; Batch: 4.4851 sec\n",
            "0.1760 0.1460 0.1279 0.1114 0.1090 0.1011 0.0990 0.0961 0.0947 0.0913 0.0897 0.0881 0.0882 0.0871 0.0879 0.0871 \n",
            "\n",
            "[TRAIN] Epoch[1](202/1214); Loss: 0.103839; Backpropagation: 0.6137 sec; Batch: 4.4861 sec\n",
            "0.1773 0.1561 0.1293 0.1213 0.1115 0.1049 0.0986 0.0929 0.0915 0.0879 0.0868 0.0837 0.0818 0.0792 0.0800 0.0787 \n",
            "\n",
            "[TRAIN] Epoch[1](203/1214); Loss: 0.108641; Backpropagation: 0.6218 sec; Batch: 4.4959 sec\n",
            "0.1516 0.1402 0.1297 0.1223 0.1159 0.1091 0.1049 0.1004 0.0986 0.0969 0.0956 0.0952 0.0946 0.0948 0.0946 0.0939 \n",
            "\n",
            "[TRAIN] Epoch[1](204/1214); Loss: 0.100246; Backpropagation: 0.6124 sec; Batch: 4.4902 sec\n",
            "0.1754 0.1474 0.1170 0.1163 0.1098 0.1051 0.0981 0.0923 0.0897 0.0842 0.0811 0.0784 0.0777 0.0783 0.0770 0.0762 \n",
            "\n",
            "[TRAIN] Epoch[1](205/1214); Loss: 0.097339; Backpropagation: 0.6123 sec; Batch: 4.4902 sec\n",
            "0.1678 0.1395 0.1144 0.1089 0.1085 0.0998 0.0949 0.0882 0.0863 0.0830 0.0802 0.0791 0.0781 0.0767 0.0760 0.0760 \n",
            "\n",
            "[TRAIN] Epoch[1](206/1214); Loss: 0.103059; Backpropagation: 0.6199 sec; Batch: 4.5020 sec\n",
            "0.1718 0.1539 0.1268 0.1208 0.1111 0.1042 0.0968 0.0906 0.0876 0.0878 0.0870 0.0841 0.0828 0.0811 0.0808 0.0818 \n",
            "\n",
            "[TRAIN] Epoch[1](207/1214); Loss: 0.097976; Backpropagation: 0.6136 sec; Batch: 4.4898 sec\n",
            "0.1641 0.1366 0.1259 0.1111 0.1048 0.0967 0.0935 0.0905 0.0843 0.0817 0.0821 0.0800 0.0800 0.0787 0.0783 0.0793 \n",
            "\n",
            "[TRAIN] Epoch[1](208/1214); Loss: 0.096578; Backpropagation: 0.6185 sec; Batch: 4.4954 sec\n",
            "0.1616 0.1339 0.1091 0.1042 0.0997 0.0930 0.0886 0.0885 0.0857 0.0861 0.0841 0.0828 0.0818 0.0816 0.0822 0.0822 \n",
            "\n",
            "[TRAIN] Epoch[1](209/1214); Loss: 0.099427; Backpropagation: 0.6178 sec; Batch: 4.4935 sec\n",
            "0.1649 0.1286 0.1154 0.1130 0.1036 0.0952 0.0937 0.0914 0.0897 0.0872 0.0872 0.0856 0.0843 0.0829 0.0843 0.0840 \n",
            "\n",
            "[TRAIN] Epoch[1](210/1214); Loss: 0.097824; Backpropagation: 0.6161 sec; Batch: 4.4949 sec\n",
            "0.1801 0.1429 0.1133 0.1077 0.0987 0.0928 0.0903 0.0876 0.0830 0.0819 0.0821 0.0801 0.0797 0.0820 0.0815 0.0812 \n",
            "\n",
            "[TRAIN] Epoch[1](211/1214); Loss: 0.091151; Backpropagation: 0.6090 sec; Batch: 4.4818 sec\n",
            "0.1673 0.1324 0.1075 0.1025 0.0903 0.0862 0.0838 0.0811 0.0783 0.0763 0.0758 0.0760 0.0754 0.0754 0.0745 0.0756 \n",
            "\n",
            "[TRAIN] Epoch[1](212/1214); Loss: 0.097835; Backpropagation: 0.6211 sec; Batch: 4.4951 sec\n",
            "0.1572 0.1263 0.1172 0.1065 0.1008 0.0957 0.0935 0.0911 0.0876 0.0862 0.0844 0.0843 0.0835 0.0836 0.0841 0.0833 \n",
            "\n",
            "[TRAIN] Epoch[1](213/1214); Loss: 0.101552; Backpropagation: 0.6197 sec; Batch: 4.4906 sec\n",
            "0.1780 0.1341 0.1194 0.1083 0.1005 0.0963 0.0939 0.0919 0.0891 0.0875 0.0872 0.0875 0.0876 0.0869 0.0880 0.0885 \n",
            "\n",
            "[TRAIN] Epoch[1](214/1214); Loss: 0.080291; Backpropagation: 0.6163 sec; Batch: 4.4965 sec\n",
            "0.1470 0.1100 0.0990 0.0856 0.0803 0.0749 0.0706 0.0680 0.0673 0.0670 0.0674 0.0678 0.0686 0.0697 0.0705 0.0708 \n",
            "\n",
            "[TRAIN] Epoch[1](215/1214); Loss: 0.094110; Backpropagation: 0.6232 sec; Batch: 4.4958 sec\n",
            "0.1685 0.1291 0.1116 0.1007 0.0939 0.0894 0.0873 0.0837 0.0818 0.0806 0.0798 0.0794 0.0793 0.0797 0.0800 0.0811 \n",
            "\n",
            "[TRAIN] Epoch[1](216/1214); Loss: 0.105681; Backpropagation: 0.6131 sec; Batch: 4.4895 sec\n",
            "0.1721 0.1347 0.1247 0.1111 0.1058 0.1031 0.1001 0.0970 0.0949 0.0934 0.0927 0.0920 0.0921 0.0923 0.0926 0.0923 \n",
            "\n",
            "[TRAIN] Epoch[1](217/1214); Loss: 0.107905; Backpropagation: 0.6108 sec; Batch: 4.4913 sec\n",
            "0.1673 0.1414 0.1277 0.1148 0.1058 0.1018 0.0993 0.0977 0.0971 0.0959 0.0956 0.0959 0.0959 0.0961 0.0969 0.0971 \n",
            "\n",
            "[TRAIN] Epoch[1](218/1214); Loss: 0.091491; Backpropagation: 0.6165 sec; Batch: 4.4909 sec\n",
            "0.1660 0.1306 0.1113 0.0996 0.0920 0.0857 0.0830 0.0796 0.0786 0.0776 0.0776 0.0766 0.0766 0.0762 0.0767 0.0764 \n",
            "\n",
            "[TRAIN] Epoch[1](219/1214); Loss: 0.099678; Backpropagation: 0.6128 sec; Batch: 4.4895 sec\n",
            "0.1582 0.1226 0.1175 0.1028 0.0981 0.0945 0.0917 0.0907 0.0900 0.0895 0.0892 0.0893 0.0899 0.0899 0.0903 0.0905 \n",
            "\n",
            "[TRAIN] Epoch[1](220/1214); Loss: 0.087986; Backpropagation: 0.6200 sec; Batch: 4.4955 sec\n",
            "0.1629 0.1190 0.1015 0.0879 0.0837 0.0810 0.0784 0.0775 0.0771 0.0768 0.0768 0.0770 0.0766 0.0769 0.0770 0.0775 \n",
            "\n",
            "[TRAIN] Epoch[1](221/1214); Loss: 0.095844; Backpropagation: 0.6160 sec; Batch: 4.4898 sec\n",
            "0.1674 0.1280 0.1158 0.1029 0.0967 0.0912 0.0882 0.0857 0.0837 0.0832 0.0827 0.0825 0.0820 0.0813 0.0809 0.0813 \n",
            "\n",
            "[TRAIN] Epoch[1](222/1214); Loss: 0.090049; Backpropagation: 0.6112 sec; Batch: 4.4873 sec\n",
            "0.1533 0.1220 0.1038 0.0951 0.0884 0.0856 0.0827 0.0817 0.0799 0.0793 0.0785 0.0780 0.0773 0.0784 0.0783 0.0783 \n",
            "\n",
            "[TRAIN] Epoch[1](223/1214); Loss: 0.094418; Backpropagation: 0.6133 sec; Batch: 4.4911 sec\n",
            "0.1775 0.1351 0.1145 0.1007 0.0938 0.0881 0.0853 0.0833 0.0817 0.0808 0.0793 0.0792 0.0781 0.0783 0.0771 0.0778 \n",
            "\n",
            "[TRAIN] Epoch[1](224/1214); Loss: 0.096890; Backpropagation: 0.6113 sec; Batch: 4.4819 sec\n",
            "0.1671 0.1327 0.1112 0.1010 0.0949 0.0915 0.0888 0.0872 0.0856 0.0848 0.0841 0.0847 0.0840 0.0837 0.0846 0.0844 \n",
            "\n",
            "[TRAIN] Epoch[1](225/1214); Loss: 0.096190; Backpropagation: 0.6115 sec; Batch: 4.4847 sec\n",
            "0.1652 0.1257 0.1115 0.1001 0.0936 0.0898 0.0873 0.0870 0.0856 0.0853 0.0846 0.0849 0.0842 0.0846 0.0847 0.0849 \n",
            "\n",
            "[TRAIN] Epoch[1](226/1214); Loss: 0.081579; Backpropagation: 0.6155 sec; Batch: 4.4901 sec\n",
            "0.1404 0.1111 0.0949 0.0845 0.0793 0.0757 0.0744 0.0731 0.0725 0.0719 0.0713 0.0711 0.0711 0.0710 0.0715 0.0716 \n",
            "\n",
            "[TRAIN] Epoch[1](227/1214); Loss: 0.081214; Backpropagation: 0.6153 sec; Batch: 4.4890 sec\n",
            "0.1340 0.1039 0.0923 0.0846 0.0805 0.0763 0.0742 0.0736 0.0731 0.0726 0.0718 0.0719 0.0721 0.0724 0.0727 0.0733 \n",
            "\n",
            "[TRAIN] Epoch[1](228/1214); Loss: 0.096364; Backpropagation: 0.6104 sec; Batch: 4.4814 sec\n",
            "0.1740 0.1259 0.1133 0.0989 0.0935 0.0904 0.0882 0.0857 0.0845 0.0838 0.0840 0.0838 0.0838 0.0837 0.0839 0.0844 \n",
            "\n",
            "[TRAIN] Epoch[1](229/1214); Loss: 0.088360; Backpropagation: 0.6191 sec; Batch: 4.4978 sec\n",
            "0.1545 0.1195 0.0988 0.0921 0.0871 0.0850 0.0818 0.0793 0.0776 0.0772 0.0769 0.0770 0.0766 0.0766 0.0768 0.0770 \n",
            "\n",
            "[TRAIN] Epoch[1](230/1214); Loss: 0.089339; Backpropagation: 0.6208 sec; Batch: 4.4990 sec\n",
            "0.1723 0.1267 0.1051 0.0915 0.0871 0.0834 0.0799 0.0775 0.0773 0.0763 0.0756 0.0754 0.0750 0.0752 0.0755 0.0756 \n",
            "\n",
            "[TRAIN] Epoch[1](231/1214); Loss: 0.086475; Backpropagation: 0.6150 sec; Batch: 4.4875 sec\n",
            "0.1494 0.1186 0.1036 0.0907 0.0835 0.0804 0.0793 0.0780 0.0762 0.0752 0.0752 0.0748 0.0747 0.0745 0.0747 0.0749 \n",
            "\n",
            "[TRAIN] Epoch[1](232/1214); Loss: 0.087182; Backpropagation: 0.6132 sec; Batch: 4.4858 sec\n",
            "0.1562 0.1144 0.0985 0.0884 0.0829 0.0816 0.0786 0.0780 0.0775 0.0771 0.0767 0.0766 0.0768 0.0768 0.0769 0.0777 \n",
            "\n",
            "[TRAIN] Epoch[1](233/1214); Loss: 0.089328; Backpropagation: 0.6214 sec; Batch: 4.4902 sec\n",
            "0.1536 0.1140 0.1040 0.0921 0.0872 0.0829 0.0813 0.0799 0.0795 0.0786 0.0790 0.0790 0.0791 0.0792 0.0797 0.0800 \n",
            "\n",
            "[TRAIN] Epoch[1](234/1214); Loss: 0.083908; Backpropagation: 0.6165 sec; Batch: 4.4922 sec\n",
            "0.1594 0.1182 0.0973 0.0877 0.0810 0.0777 0.0754 0.0736 0.0723 0.0716 0.0715 0.0711 0.0713 0.0712 0.0714 0.0717 \n",
            "\n",
            "[TRAIN] Epoch[1](235/1214); Loss: 0.086631; Backpropagation: 0.6212 sec; Batch: 4.4960 sec\n",
            "0.1706 0.1166 0.1020 0.0878 0.0820 0.0781 0.0761 0.0751 0.0747 0.0744 0.0744 0.0745 0.0747 0.0749 0.0749 0.0753 \n",
            "\n",
            "[TRAIN] Epoch[1](236/1214); Loss: 0.084932; Backpropagation: 0.6095 sec; Batch: 4.4872 sec\n",
            "0.1650 0.1123 0.1015 0.0843 0.0802 0.0764 0.0756 0.0745 0.0743 0.0739 0.0737 0.0732 0.0733 0.0732 0.0736 0.0739 \n",
            "\n",
            "[TRAIN] Epoch[1](237/1214); Loss: 0.087391; Backpropagation: 0.6156 sec; Batch: 4.4892 sec\n",
            "0.1653 0.1265 0.1049 0.0927 0.0848 0.0811 0.0781 0.0763 0.0750 0.0743 0.0738 0.0732 0.0729 0.0730 0.0731 0.0733 \n",
            "\n",
            "[TRAIN] Epoch[1](238/1214); Loss: 0.080669; Backpropagation: 0.6171 sec; Batch: 4.4935 sec\n",
            "0.1461 0.1066 0.0931 0.0820 0.0768 0.0743 0.0725 0.0719 0.0712 0.0713 0.0707 0.0708 0.0708 0.0708 0.0708 0.0710 \n",
            "\n",
            "[TRAIN] Epoch[1](239/1214); Loss: 0.080497; Backpropagation: 0.6120 sec; Batch: 4.4884 sec\n",
            "0.1728 0.1154 0.0927 0.0806 0.0759 0.0728 0.0708 0.0693 0.0685 0.0676 0.0673 0.0669 0.0669 0.0667 0.0668 0.0670 \n",
            "\n",
            "[TRAIN] Epoch[1](240/1214); Loss: 0.093993; Backpropagation: 0.6078 sec; Batch: 4.4777 sec\n",
            "0.1591 0.1248 0.1103 0.0992 0.0938 0.0892 0.0868 0.0842 0.0836 0.0825 0.0822 0.0817 0.0818 0.0814 0.0816 0.0816 \n",
            "\n",
            "[TRAIN] Epoch[1](241/1214); Loss: 0.083490; Backpropagation: 0.6101 sec; Batch: 4.4808 sec\n",
            "0.1457 0.1113 0.0950 0.0852 0.0807 0.0779 0.0760 0.0747 0.0741 0.0739 0.0734 0.0734 0.0736 0.0736 0.0737 0.0737 \n",
            "\n",
            "[TRAIN] Epoch[1](242/1214); Loss: 0.086380; Backpropagation: 0.6073 sec; Batch: 4.4820 sec\n",
            "0.1528 0.1080 0.0934 0.0869 0.0828 0.0807 0.0796 0.0789 0.0782 0.0778 0.0775 0.0772 0.0771 0.0771 0.0770 0.0774 \n",
            "\n",
            "[TRAIN] Epoch[1](243/1214); Loss: 0.072258; Backpropagation: 0.6133 sec; Batch: 4.4835 sec\n",
            "0.1662 0.1090 0.0814 0.0723 0.0663 0.0630 0.0613 0.0599 0.0597 0.0592 0.0591 0.0593 0.0593 0.0596 0.0601 0.0606 \n",
            "\n",
            "[TRAIN] Epoch[1](244/1214); Loss: 0.090265; Backpropagation: 0.6127 sec; Batch: 4.4830 sec\n",
            "0.1534 0.1151 0.1001 0.0910 0.0873 0.0842 0.0831 0.0821 0.0813 0.0813 0.0811 0.0810 0.0809 0.0809 0.0807 0.0807 \n",
            "\n",
            "[TRAIN] Epoch[1](245/1214); Loss: 0.072677; Backpropagation: 0.6278 sec; Batch: 4.5053 sec\n",
            "0.1440 0.1043 0.0877 0.0764 0.0692 0.0654 0.0635 0.0624 0.0619 0.0613 0.0611 0.0609 0.0608 0.0610 0.0614 0.0616 \n",
            "\n",
            "[TRAIN] Epoch[1](246/1214); Loss: 0.076843; Backpropagation: 0.6273 sec; Batch: 4.5008 sec\n",
            "0.1715 0.1108 0.0869 0.0763 0.0697 0.0690 0.0665 0.0657 0.0645 0.0645 0.0638 0.0637 0.0640 0.0642 0.0641 0.0643 \n",
            "\n",
            "[TRAIN] Epoch[1](247/1214); Loss: 0.078270; Backpropagation: 0.6167 sec; Batch: 4.4903 sec\n",
            "0.1430 0.1077 0.0905 0.0803 0.0750 0.0727 0.0701 0.0695 0.0684 0.0684 0.0678 0.0678 0.0678 0.0679 0.0676 0.0678 \n",
            "\n",
            "[TRAIN] Epoch[1](248/1214); Loss: 0.089315; Backpropagation: 0.6153 sec; Batch: 4.4842 sec\n",
            "0.1667 0.1314 0.1061 0.0942 0.0859 0.0821 0.0795 0.0776 0.0769 0.0761 0.0758 0.0754 0.0754 0.0753 0.0753 0.0753 \n",
            "\n",
            "[TRAIN] Epoch[1](249/1214); Loss: 0.075328; Backpropagation: 0.6169 sec; Batch: 4.4959 sec\n",
            "0.1519 0.1079 0.0815 0.0737 0.0699 0.0678 0.0665 0.0654 0.0652 0.0648 0.0648 0.0649 0.0651 0.0651 0.0652 0.0656 \n",
            "\n",
            "[TRAIN] Epoch[1](250/1214); Loss: 0.090082; Backpropagation: 0.6086 sec; Batch: 4.4841 sec\n",
            "0.1872 0.1366 0.1035 0.0911 0.0840 0.0803 0.0780 0.0768 0.0758 0.0751 0.0753 0.0755 0.0754 0.0755 0.0755 0.0757 \n",
            "\n",
            "[TRAIN] Epoch[1](251/1214); Loss: 0.086233; Backpropagation: 0.6158 sec; Batch: 4.4953 sec\n",
            "0.1649 0.1183 0.0953 0.0863 0.0824 0.0795 0.0779 0.0762 0.0756 0.0748 0.0747 0.0747 0.0747 0.0748 0.0749 0.0749 \n",
            "\n",
            "[TRAIN] Epoch[1](252/1214); Loss: 0.087501; Backpropagation: 0.6198 sec; Batch: 4.4920 sec\n",
            "0.1727 0.1236 0.0992 0.0879 0.0818 0.0788 0.0767 0.0762 0.0757 0.0756 0.0753 0.0754 0.0752 0.0754 0.0752 0.0753 \n",
            "\n",
            "[TRAIN] Epoch[1](253/1214); Loss: 0.069545; Backpropagation: 0.6139 sec; Batch: 4.4880 sec\n",
            "0.1391 0.1049 0.0792 0.0701 0.0650 0.0626 0.0610 0.0601 0.0596 0.0591 0.0589 0.0587 0.0587 0.0586 0.0586 0.0587 \n",
            "\n",
            "[TRAIN] Epoch[1](254/1214); Loss: 0.081979; Backpropagation: 0.6109 sec; Batch: 4.4844 sec\n",
            "0.1536 0.1117 0.0924 0.0836 0.0794 0.0759 0.0739 0.0725 0.0717 0.0710 0.0712 0.0711 0.0708 0.0707 0.0710 0.0709 \n",
            "\n",
            "[TRAIN] Epoch[1](255/1214); Loss: 0.080281; Backpropagation: 0.6096 sec; Batch: 4.4849 sec\n",
            "0.1516 0.1099 0.0883 0.0803 0.0749 0.0735 0.0721 0.0713 0.0706 0.0705 0.0704 0.0702 0.0703 0.0704 0.0701 0.0703 \n",
            "\n",
            "[TRAIN] Epoch[1](256/1214); Loss: 0.083105; Backpropagation: 0.6155 sec; Batch: 4.4901 sec\n",
            "0.1492 0.1097 0.0921 0.0872 0.0799 0.0775 0.0753 0.0740 0.0734 0.0730 0.0731 0.0729 0.0730 0.0731 0.0733 0.0731 \n",
            "\n",
            "[TRAIN] Epoch[1](257/1214); Loss: 0.084122; Backpropagation: 0.6113 sec; Batch: 4.4879 sec\n",
            "0.1400 0.1096 0.0943 0.0863 0.0810 0.0787 0.0771 0.0766 0.0760 0.0756 0.0753 0.0751 0.0750 0.0751 0.0750 0.0751 \n",
            "\n",
            "[TRAIN] Epoch[1](258/1214); Loss: 0.084316; Backpropagation: 0.6151 sec; Batch: 4.4842 sec\n",
            "0.1743 0.1245 0.0945 0.0847 0.0789 0.0750 0.0736 0.0725 0.0719 0.0714 0.0714 0.0712 0.0713 0.0711 0.0715 0.0713 \n",
            "\n",
            "[TRAIN] Epoch[1](259/1214); Loss: 0.089148; Backpropagation: 0.6204 sec; Batch: 4.4958 sec\n",
            "0.1510 0.1163 0.0963 0.0907 0.0851 0.0830 0.0814 0.0806 0.0801 0.0801 0.0802 0.0801 0.0801 0.0801 0.0803 0.0807 \n",
            "\n",
            "[TRAIN] Epoch[1](260/1214); Loss: 0.080348; Backpropagation: 0.6106 sec; Batch: 4.4831 sec\n",
            "0.1610 0.1198 0.0905 0.0824 0.0753 0.0720 0.0703 0.0692 0.0683 0.0681 0.0680 0.0681 0.0680 0.0682 0.0682 0.0682 \n",
            "\n",
            "[TRAIN] Epoch[1](261/1214); Loss: 0.093521; Backpropagation: 0.6148 sec; Batch: 4.4965 sec\n",
            "0.1870 0.1401 0.1116 0.0979 0.0896 0.0849 0.0820 0.0797 0.0788 0.0784 0.0781 0.0780 0.0776 0.0776 0.0776 0.0775 \n",
            "\n",
            "[TRAIN] Epoch[1](262/1214); Loss: 0.082235; Backpropagation: 0.6102 sec; Batch: 4.4872 sec\n",
            "0.1385 0.1067 0.0888 0.0846 0.0795 0.0774 0.0759 0.0748 0.0744 0.0740 0.0737 0.0736 0.0736 0.0735 0.0735 0.0734 \n",
            "\n",
            "[TRAIN] Epoch[1](263/1214); Loss: 0.084604; Backpropagation: 0.6126 sec; Batch: 4.4859 sec\n",
            "0.1554 0.1149 0.0909 0.0837 0.0804 0.0775 0.0760 0.0757 0.0752 0.0751 0.0748 0.0746 0.0746 0.0747 0.0751 0.0749 \n",
            "\n",
            "[TRAIN] Epoch[1](264/1214); Loss: 0.075577; Backpropagation: 0.6142 sec; Batch: 4.4857 sec\n",
            "0.1689 0.1127 0.0810 0.0741 0.0702 0.0660 0.0647 0.0641 0.0638 0.0635 0.0635 0.0634 0.0631 0.0633 0.0634 0.0635 \n",
            "\n",
            "[TRAIN] Epoch[1](265/1214); Loss: 0.089317; Backpropagation: 0.6275 sec; Batch: 4.4998 sec\n",
            "0.1684 0.1152 0.0952 0.0895 0.0848 0.0826 0.0809 0.0799 0.0795 0.0791 0.0792 0.0790 0.0791 0.0789 0.0789 0.0788 \n",
            "\n",
            "[TRAIN] Epoch[1](266/1214); Loss: 0.085005; Backpropagation: 0.6243 sec; Batch: 4.5013 sec\n",
            "0.1696 0.1218 0.0973 0.0856 0.0793 0.0765 0.0748 0.0739 0.0732 0.0728 0.0726 0.0725 0.0725 0.0726 0.0726 0.0726 \n",
            "\n",
            "[TRAIN] Epoch[1](267/1214); Loss: 0.086375; Backpropagation: 0.6182 sec; Batch: 4.4949 sec\n",
            "0.1392 0.1048 0.0899 0.0855 0.0825 0.0809 0.0800 0.0798 0.0796 0.0797 0.0795 0.0796 0.0799 0.0802 0.0804 0.0806 \n",
            "\n",
            "[TRAIN] Epoch[1](268/1214); Loss: 0.087439; Backpropagation: 0.6176 sec; Batch: 4.4945 sec\n",
            "0.1599 0.1224 0.0983 0.0887 0.0826 0.0796 0.0780 0.0772 0.0767 0.0766 0.0765 0.0766 0.0764 0.0765 0.0765 0.0767 \n",
            "\n",
            "[TRAIN] Epoch[1](269/1214); Loss: 0.078208; Backpropagation: 0.6132 sec; Batch: 4.4862 sec\n",
            "0.1515 0.1088 0.0860 0.0764 0.0721 0.0710 0.0696 0.0690 0.0686 0.0685 0.0683 0.0681 0.0683 0.0682 0.0686 0.0685 \n",
            "\n",
            "[TRAIN] Epoch[1](270/1214); Loss: 0.086141; Backpropagation: 0.6147 sec; Batch: 4.4863 sec\n",
            "0.1646 0.1201 0.0953 0.0857 0.0803 0.0784 0.0769 0.0763 0.0757 0.0754 0.0751 0.0749 0.0748 0.0749 0.0748 0.0750 \n",
            "\n",
            "[TRAIN] Epoch[1](271/1214); Loss: 0.082141; Backpropagation: 0.6158 sec; Batch: 4.4889 sec\n",
            "0.1387 0.1042 0.0872 0.0814 0.0780 0.0765 0.0757 0.0750 0.0750 0.0746 0.0747 0.0747 0.0748 0.0745 0.0746 0.0747 \n",
            "\n",
            "[TRAIN] Epoch[1](272/1214); Loss: 0.091541; Backpropagation: 0.6181 sec; Batch: 4.5008 sec\n",
            "0.1570 0.1172 0.0958 0.0890 0.0868 0.0851 0.0843 0.0837 0.0834 0.0831 0.0832 0.0831 0.0831 0.0832 0.0833 0.0833 \n",
            "\n",
            "[TRAIN] Epoch[1](273/1214); Loss: 0.075490; Backpropagation: 0.6125 sec; Batch: 4.4973 sec\n",
            "0.1528 0.1050 0.0837 0.0741 0.0699 0.0681 0.0661 0.0659 0.0654 0.0653 0.0648 0.0650 0.0651 0.0653 0.0657 0.0657 \n",
            "\n",
            "[TRAIN] Epoch[1](274/1214); Loss: 0.089370; Backpropagation: 0.6122 sec; Batch: 4.4892 sec\n",
            "0.1617 0.1174 0.0964 0.0893 0.0842 0.0821 0.0810 0.0803 0.0800 0.0797 0.0796 0.0795 0.0795 0.0795 0.0798 0.0798 \n",
            "\n",
            "[TRAIN] Epoch[1](275/1214); Loss: 0.073591; Backpropagation: 0.6073 sec; Batch: 4.4837 sec\n",
            "0.1419 0.0957 0.0803 0.0732 0.0693 0.0670 0.0662 0.0655 0.0650 0.0648 0.0647 0.0647 0.0647 0.0647 0.0649 0.0649 \n",
            "\n",
            "[TRAIN] Epoch[1](276/1214); Loss: 0.079738; Backpropagation: 0.6087 sec; Batch: 4.4812 sec\n",
            "0.1593 0.1118 0.0862 0.0791 0.0746 0.0723 0.0703 0.0696 0.0693 0.0690 0.0689 0.0690 0.0689 0.0690 0.0692 0.0692 \n",
            "\n",
            "[TRAIN] Epoch[1](277/1214); Loss: 0.084574; Backpropagation: 0.6146 sec; Batch: 4.4896 sec\n",
            "0.1542 0.1107 0.0931 0.0850 0.0802 0.0782 0.0763 0.0757 0.0752 0.0752 0.0750 0.0750 0.0748 0.0747 0.0748 0.0750 \n",
            "\n",
            "[TRAIN] Epoch[1](278/1214); Loss: 0.069528; Backpropagation: 0.6153 sec; Batch: 4.4934 sec\n",
            "0.1325 0.0887 0.0746 0.0697 0.0655 0.0634 0.0623 0.0619 0.0616 0.0615 0.0613 0.0613 0.0616 0.0619 0.0621 0.0623 \n",
            "\n",
            "[TRAIN] Epoch[1](279/1214); Loss: 0.077645; Backpropagation: 0.6174 sec; Batch: 4.4916 sec\n",
            "0.1515 0.1082 0.0854 0.0782 0.0729 0.0702 0.0692 0.0682 0.0677 0.0674 0.0672 0.0672 0.0672 0.0671 0.0674 0.0674 \n",
            "\n",
            "[TRAIN] Epoch[1](280/1214); Loss: 0.080018; Backpropagation: 0.6230 sec; Batch: 4.4966 sec\n",
            "0.1489 0.1056 0.0874 0.0801 0.0751 0.0732 0.0721 0.0713 0.0710 0.0707 0.0706 0.0706 0.0706 0.0709 0.0710 0.0711 \n",
            "\n",
            "[TRAIN] Epoch[1](281/1214); Loss: 0.090919; Backpropagation: 0.6179 sec; Batch: 4.4902 sec\n",
            "0.1664 0.1255 0.0991 0.0914 0.0865 0.0841 0.0820 0.0812 0.0803 0.0800 0.0796 0.0796 0.0796 0.0798 0.0797 0.0798 \n",
            "\n",
            "[TRAIN] Epoch[1](282/1214); Loss: 0.076677; Backpropagation: 0.6187 sec; Batch: 4.4922 sec\n",
            "0.1423 0.0998 0.0791 0.0745 0.0718 0.0707 0.0695 0.0694 0.0689 0.0689 0.0687 0.0687 0.0685 0.0686 0.0686 0.0688 \n",
            "\n",
            "[TRAIN] Epoch[1](283/1214); Loss: 0.074960; Backpropagation: 0.6146 sec; Batch: 4.4929 sec\n",
            "0.1340 0.0936 0.0789 0.0763 0.0710 0.0695 0.0683 0.0680 0.0678 0.0677 0.0674 0.0674 0.0672 0.0672 0.0675 0.0675 \n",
            "\n",
            "[TRAIN] Epoch[1](284/1214); Loss: 0.076055; Backpropagation: 0.6236 sec; Batch: 4.4958 sec\n",
            "0.1301 0.0947 0.0792 0.0756 0.0726 0.0714 0.0701 0.0698 0.0693 0.0693 0.0690 0.0691 0.0691 0.0692 0.0691 0.0692 \n",
            "\n",
            "[TRAIN] Epoch[1](285/1214); Loss: 0.087038; Backpropagation: 0.6166 sec; Batch: 4.4946 sec\n",
            "0.1587 0.1121 0.0908 0.0851 0.0811 0.0803 0.0792 0.0786 0.0782 0.0783 0.0782 0.0782 0.0783 0.0784 0.0784 0.0787 \n",
            "\n",
            "[TRAIN] Epoch[1](286/1214); Loss: 0.074132; Backpropagation: 0.6102 sec; Batch: 4.4838 sec\n",
            "0.1545 0.1021 0.0814 0.0728 0.0682 0.0658 0.0647 0.0642 0.0642 0.0639 0.0639 0.0638 0.0640 0.0639 0.0643 0.0643 \n",
            "\n",
            "[TRAIN] Epoch[1](287/1214); Loss: 0.082468; Backpropagation: 0.6156 sec; Batch: 4.4914 sec\n",
            "0.1719 0.1166 0.0884 0.0804 0.0756 0.0734 0.0719 0.0716 0.0713 0.0711 0.0709 0.0709 0.0711 0.0712 0.0714 0.0716 \n",
            "\n",
            "[TRAIN] Epoch[1](288/1214); Loss: 0.080662; Backpropagation: 0.6088 sec; Batch: 4.4831 sec\n",
            "0.1483 0.1026 0.0855 0.0795 0.0758 0.0740 0.0733 0.0727 0.0724 0.0724 0.0724 0.0723 0.0723 0.0721 0.0723 0.0724 \n",
            "\n",
            "[TRAIN] Epoch[1](289/1214); Loss: 0.081955; Backpropagation: 0.6138 sec; Batch: 4.4903 sec\n",
            "0.1413 0.1053 0.0881 0.0823 0.0785 0.0766 0.0751 0.0745 0.0741 0.0739 0.0737 0.0736 0.0736 0.0735 0.0735 0.0737 \n",
            "\n",
            "[TRAIN] Epoch[1](290/1214); Loss: 0.076270; Backpropagation: 0.6145 sec; Batch: 4.4902 sec\n",
            "0.1390 0.0954 0.0808 0.0747 0.0718 0.0706 0.0698 0.0694 0.0690 0.0687 0.0686 0.0684 0.0685 0.0687 0.0685 0.0685 \n",
            "\n",
            "[TRAIN] Epoch[1](291/1214); Loss: 0.074919; Backpropagation: 0.6168 sec; Batch: 4.4896 sec\n",
            "0.1445 0.0926 0.0767 0.0725 0.0698 0.0687 0.0683 0.0677 0.0673 0.0672 0.0672 0.0671 0.0672 0.0673 0.0672 0.0673 \n",
            "\n",
            "[TRAIN] Epoch[1](292/1214); Loss: 0.081007; Backpropagation: 0.6210 sec; Batch: 4.4989 sec\n",
            "0.1372 0.1031 0.0873 0.0809 0.0770 0.0758 0.0745 0.0740 0.0736 0.0734 0.0732 0.0733 0.0732 0.0732 0.0732 0.0733 \n",
            "\n",
            "[TRAIN] Epoch[1](293/1214); Loss: 0.085948; Backpropagation: 0.6104 sec; Batch: 4.4871 sec\n",
            "0.1455 0.0987 0.0905 0.0842 0.0814 0.0803 0.0796 0.0793 0.0794 0.0793 0.0792 0.0792 0.0794 0.0794 0.0796 0.0800 \n",
            "\n",
            "[TRAIN] Epoch[1](294/1214); Loss: 0.069940; Backpropagation: 0.6240 sec; Batch: 4.5015 sec\n",
            "0.1499 0.0969 0.0740 0.0669 0.0640 0.0618 0.0612 0.0606 0.0606 0.0603 0.0605 0.0603 0.0603 0.0603 0.0607 0.0608 \n",
            "\n",
            "[TRAIN] Epoch[1](295/1214); Loss: 0.083705; Backpropagation: 0.6144 sec; Batch: 4.4870 sec\n",
            "0.1496 0.1087 0.0868 0.0812 0.0787 0.0767 0.0761 0.0756 0.0757 0.0755 0.0756 0.0756 0.0758 0.0758 0.0760 0.0761 \n",
            "\n",
            "[TRAIN] Epoch[1](296/1214); Loss: 0.085418; Backpropagation: 0.6099 sec; Batch: 4.4877 sec\n",
            "0.1375 0.1067 0.0905 0.0859 0.0826 0.0803 0.0793 0.0790 0.0786 0.0782 0.0780 0.0780 0.0780 0.0780 0.0779 0.0780 \n",
            "\n",
            "[TRAIN] Epoch[1](297/1214); Loss: 0.080124; Backpropagation: 0.6173 sec; Batch: 4.4900 sec\n",
            "0.1402 0.1073 0.0907 0.0811 0.0760 0.0736 0.0728 0.0720 0.0717 0.0714 0.0711 0.0710 0.0710 0.0706 0.0707 0.0707 \n",
            "\n",
            "[TRAIN] Epoch[1](298/1214); Loss: 0.079095; Backpropagation: 0.6111 sec; Batch: 4.4934 sec\n",
            "0.1540 0.1038 0.0838 0.0776 0.0729 0.0717 0.0707 0.0703 0.0700 0.0700 0.0699 0.0700 0.0699 0.0702 0.0701 0.0706 \n",
            "\n",
            "[TRAIN] Epoch[1](299/1214); Loss: 0.073871; Backpropagation: 0.6171 sec; Batch: 4.4896 sec\n",
            "0.1354 0.0940 0.0779 0.0718 0.0689 0.0681 0.0672 0.0670 0.0667 0.0665 0.0663 0.0663 0.0664 0.0664 0.0664 0.0666 \n",
            "\n",
            "[TRAIN] Epoch[1](300/1214); Loss: 0.077324; Backpropagation: 0.6110 sec; Batch: 4.4841 sec\n",
            "0.1425 0.1011 0.0833 0.0761 0.0727 0.0714 0.0700 0.0694 0.0688 0.0687 0.0686 0.0687 0.0687 0.0690 0.0690 0.0693 \n",
            "\n",
            "[TRAIN] Epoch[1](301/1214); Loss: 0.077812; Backpropagation: 0.6204 sec; Batch: 4.4997 sec\n",
            "0.1508 0.1012 0.0827 0.0761 0.0723 0.0703 0.0694 0.0690 0.0688 0.0687 0.0689 0.0689 0.0690 0.0694 0.0697 0.0699 \n",
            "\n",
            "[TRAIN] Epoch[1](302/1214); Loss: 0.078200; Backpropagation: 0.6144 sec; Batch: 4.4847 sec\n",
            "0.1598 0.1050 0.0832 0.0762 0.0727 0.0701 0.0692 0.0686 0.0683 0.0680 0.0679 0.0680 0.0682 0.0685 0.0686 0.0688 \n",
            "\n",
            "[TRAIN] Epoch[1](303/1214); Loss: 0.077759; Backpropagation: 0.6101 sec; Batch: 4.4814 sec\n",
            "0.1457 0.1032 0.0840 0.0783 0.0732 0.0711 0.0697 0.0692 0.0690 0.0687 0.0687 0.0685 0.0687 0.0685 0.0687 0.0689 \n",
            "\n",
            "[TRAIN] Epoch[1](304/1214); Loss: 0.078728; Backpropagation: 0.6185 sec; Batch: 4.4915 sec\n",
            "0.1410 0.0990 0.0840 0.0781 0.0742 0.0726 0.0719 0.0714 0.0711 0.0710 0.0710 0.0709 0.0710 0.0707 0.0708 0.0709 \n",
            "\n",
            "[TRAIN] Epoch[1](305/1214); Loss: 0.075565; Backpropagation: 0.6162 sec; Batch: 4.4845 sec\n",
            "0.1330 0.0919 0.0804 0.0745 0.0715 0.0701 0.0691 0.0689 0.0687 0.0687 0.0686 0.0685 0.0686 0.0687 0.0688 0.0689 \n",
            "\n",
            "[TRAIN] Epoch[1](306/1214); Loss: 0.088807; Backpropagation: 0.6105 sec; Batch: 4.4789 sec\n",
            "0.1508 0.1145 0.0970 0.0890 0.0847 0.0829 0.0815 0.0809 0.0804 0.0802 0.0800 0.0799 0.0799 0.0798 0.0797 0.0797 \n",
            "\n",
            "[TRAIN] Epoch[1](307/1214); Loss: 0.082159; Backpropagation: 0.6067 sec; Batch: 4.4737 sec\n",
            "0.1492 0.1060 0.0871 0.0804 0.0770 0.0754 0.0744 0.0741 0.0739 0.0737 0.0738 0.0737 0.0739 0.0739 0.0740 0.0740 \n",
            "\n",
            "[TRAIN] Epoch[1](308/1214); Loss: 0.088484; Backpropagation: 0.6149 sec; Batch: 4.4947 sec\n",
            "0.1552 0.1131 0.0943 0.0880 0.0838 0.0824 0.0809 0.0805 0.0800 0.0797 0.0794 0.0797 0.0795 0.0796 0.0797 0.0798 \n",
            "\n",
            "[TRAIN] Epoch[1](309/1214); Loss: 0.083655; Backpropagation: 0.6151 sec; Batch: 4.4896 sec\n",
            "0.1409 0.1015 0.0895 0.0830 0.0794 0.0780 0.0771 0.0768 0.0765 0.0764 0.0764 0.0764 0.0764 0.0765 0.0767 0.0770 \n",
            "\n",
            "[TRAIN] Epoch[1](310/1214); Loss: 0.078812; Backpropagation: 0.6148 sec; Batch: 4.4886 sec\n",
            "0.1457 0.1012 0.0858 0.0777 0.0738 0.0727 0.0713 0.0710 0.0706 0.0705 0.0702 0.0702 0.0700 0.0701 0.0700 0.0701 \n",
            "\n",
            "[TRAIN] Epoch[1](311/1214); Loss: 0.074434; Backpropagation: 0.6171 sec; Batch: 4.4911 sec\n",
            "0.1404 0.0967 0.0799 0.0739 0.0704 0.0680 0.0674 0.0668 0.0663 0.0659 0.0660 0.0659 0.0658 0.0659 0.0658 0.0658 \n",
            "\n",
            "[TRAIN] Epoch[1](312/1214); Loss: 0.077531; Backpropagation: 0.6114 sec; Batch: 4.4837 sec\n",
            "0.1500 0.1002 0.0824 0.0749 0.0725 0.0707 0.0697 0.0690 0.0691 0.0690 0.0689 0.0687 0.0688 0.0688 0.0690 0.0689 \n",
            "\n",
            "[TRAIN] Epoch[1](313/1214); Loss: 0.077581; Backpropagation: 0.6112 sec; Batch: 4.4855 sec\n",
            "0.1476 0.0997 0.0815 0.0750 0.0722 0.0710 0.0701 0.0695 0.0696 0.0692 0.0692 0.0692 0.0692 0.0692 0.0694 0.0697 \n",
            "\n",
            "[TRAIN] Epoch[1](314/1214); Loss: 0.079316; Backpropagation: 0.6108 sec; Batch: 4.4936 sec\n",
            "0.1387 0.1001 0.0833 0.0777 0.0746 0.0734 0.0725 0.0720 0.0718 0.0719 0.0720 0.0720 0.0721 0.0721 0.0723 0.0725 \n",
            "\n",
            "[TRAIN] Epoch[1](315/1214); Loss: 0.070883; Backpropagation: 0.6128 sec; Batch: 4.4847 sec\n",
            "0.1434 0.0955 0.0752 0.0686 0.0658 0.0643 0.0632 0.0627 0.0621 0.0621 0.0618 0.0619 0.0617 0.0619 0.0620 0.0620 \n",
            "\n",
            "[TRAIN] Epoch[1](316/1214); Loss: 0.086756; Backpropagation: 0.6163 sec; Batch: 4.4876 sec\n",
            "0.1627 0.1126 0.0951 0.0865 0.0820 0.0794 0.0782 0.0775 0.0772 0.0769 0.0768 0.0766 0.0766 0.0768 0.0766 0.0767 \n",
            "\n",
            "[TRAIN] Epoch[1](317/1214); Loss: 0.075985; Backpropagation: 0.6048 sec; Batch: 4.4813 sec\n",
            "0.1400 0.0979 0.0806 0.0737 0.0706 0.0693 0.0687 0.0686 0.0684 0.0686 0.0681 0.0683 0.0680 0.0683 0.0681 0.0684 \n",
            "\n",
            "[TRAIN] Epoch[1](318/1214); Loss: 0.071958; Backpropagation: 0.6168 sec; Batch: 4.4912 sec\n",
            "0.1442 0.0953 0.0760 0.0692 0.0655 0.0646 0.0637 0.0636 0.0634 0.0634 0.0635 0.0634 0.0637 0.0637 0.0641 0.0641 \n",
            "\n",
            "[TRAIN] Epoch[1](319/1214); Loss: 0.084047; Backpropagation: 0.6138 sec; Batch: 4.4907 sec\n",
            "0.1374 0.0994 0.0869 0.0820 0.0798 0.0792 0.0784 0.0781 0.0780 0.0778 0.0779 0.0777 0.0779 0.0780 0.0781 0.0783 \n",
            "\n",
            "[TRAIN] Epoch[1](320/1214); Loss: 0.079122; Backpropagation: 0.6153 sec; Batch: 4.4902 sec\n",
            "0.1485 0.1028 0.0821 0.0767 0.0734 0.0722 0.0714 0.0711 0.0708 0.0707 0.0705 0.0709 0.0710 0.0712 0.0712 0.0714 \n",
            "\n",
            "[TRAIN] Epoch[1](321/1214); Loss: 0.088447; Backpropagation: 0.6175 sec; Batch: 4.4960 sec\n",
            "0.1546 0.1150 0.0953 0.0877 0.0838 0.0817 0.0806 0.0803 0.0799 0.0796 0.0795 0.0793 0.0794 0.0793 0.0795 0.0796 \n",
            "\n",
            "[TRAIN] Epoch[1](322/1214); Loss: 0.092949; Backpropagation: 0.6145 sec; Batch: 4.4911 sec\n",
            "0.1528 0.1101 0.0963 0.0920 0.0894 0.0881 0.0870 0.0863 0.0862 0.0859 0.0858 0.0856 0.0856 0.0853 0.0855 0.0855 \n",
            "\n",
            "[TRAIN] Epoch[1](323/1214); Loss: 0.064927; Backpropagation: 0.6159 sec; Batch: 4.4915 sec\n",
            "0.1289 0.0844 0.0694 0.0652 0.0607 0.0594 0.0582 0.0577 0.0571 0.0570 0.0568 0.0568 0.0567 0.0568 0.0567 0.0570 \n",
            "\n",
            "[TRAIN] Epoch[1](324/1214); Loss: 0.077668; Backpropagation: 0.6121 sec; Batch: 4.4744 sec\n",
            "0.1325 0.0939 0.0819 0.0761 0.0744 0.0725 0.0719 0.0714 0.0711 0.0711 0.0708 0.0710 0.0708 0.0710 0.0711 0.0711 \n",
            "\n",
            "[TRAIN] Epoch[1](325/1214); Loss: 0.077192; Backpropagation: 0.6068 sec; Batch: 4.4750 sec\n",
            "0.1381 0.0941 0.0803 0.0754 0.0731 0.0714 0.0709 0.0704 0.0701 0.0699 0.0700 0.0700 0.0701 0.0702 0.0703 0.0706 \n",
            "\n",
            "[TRAIN] Epoch[1](326/1214); Loss: 0.083970; Backpropagation: 0.6119 sec; Batch: 4.4832 sec\n",
            "0.1470 0.1080 0.0881 0.0831 0.0794 0.0781 0.0769 0.0764 0.0762 0.0760 0.0757 0.0755 0.0758 0.0758 0.0759 0.0758 \n",
            "\n",
            "[TRAIN] Epoch[1](327/1214); Loss: 0.078094; Backpropagation: 0.6152 sec; Batch: 4.4950 sec\n",
            "0.1425 0.0978 0.0839 0.0767 0.0725 0.0715 0.0704 0.0702 0.0700 0.0700 0.0702 0.0704 0.0704 0.0705 0.0710 0.0713 \n",
            "\n",
            "[TRAIN] Epoch[1](328/1214); Loss: 0.086650; Backpropagation: 0.6077 sec; Batch: 4.4829 sec\n",
            "0.1647 0.1130 0.0923 0.0864 0.0809 0.0788 0.0778 0.0774 0.0771 0.0769 0.0768 0.0767 0.0769 0.0768 0.0770 0.0769 \n",
            "\n",
            "[TRAIN] Epoch[1](329/1214); Loss: 0.070393; Backpropagation: 0.6144 sec; Batch: 4.4922 sec\n",
            "0.1357 0.0871 0.0750 0.0676 0.0657 0.0641 0.0635 0.0634 0.0632 0.0630 0.0629 0.0630 0.0629 0.0631 0.0630 0.0631 \n",
            "\n",
            "[TRAIN] Epoch[1](330/1214); Loss: 0.093220; Backpropagation: 0.6169 sec; Batch: 4.4975 sec\n",
            "0.1564 0.1151 0.0991 0.0934 0.0886 0.0868 0.0862 0.0856 0.0855 0.0853 0.0852 0.0849 0.0850 0.0848 0.0849 0.0846 \n",
            "\n",
            "[TRAIN] Epoch[1](331/1214); Loss: 0.076728; Backpropagation: 0.6134 sec; Batch: 4.4891 sec\n",
            "0.1309 0.0926 0.0793 0.0748 0.0730 0.0716 0.0709 0.0704 0.0705 0.0702 0.0703 0.0703 0.0706 0.0707 0.0707 0.0709 \n",
            "\n",
            "[TRAIN] Epoch[1](332/1214); Loss: 0.078745; Backpropagation: 0.6139 sec; Batch: 4.4866 sec\n",
            "0.1284 0.0947 0.0832 0.0780 0.0753 0.0743 0.0734 0.0730 0.0727 0.0726 0.0722 0.0723 0.0722 0.0725 0.0724 0.0727 \n",
            "\n",
            "[TRAIN] Epoch[1](333/1214); Loss: 0.073394; Backpropagation: 0.6234 sec; Batch: 4.4960 sec\n",
            "0.1449 0.0928 0.0791 0.0717 0.0683 0.0666 0.0659 0.0654 0.0651 0.0650 0.0650 0.0649 0.0649 0.0648 0.0649 0.0650 \n",
            "\n",
            "[TRAIN] Epoch[1](334/1214); Loss: 0.076031; Backpropagation: 0.6191 sec; Batch: 4.4982 sec\n",
            "0.1418 0.0990 0.0798 0.0744 0.0712 0.0696 0.0686 0.0684 0.0679 0.0679 0.0677 0.0679 0.0678 0.0681 0.0680 0.0682 \n",
            "\n",
            "[TRAIN] Epoch[1](335/1214); Loss: 0.075028; Backpropagation: 0.6196 sec; Batch: 4.4926 sec\n",
            "0.1491 0.0953 0.0780 0.0728 0.0697 0.0684 0.0675 0.0672 0.0667 0.0667 0.0666 0.0666 0.0664 0.0665 0.0665 0.0665 \n",
            "\n",
            "[TRAIN] Epoch[1](336/1214); Loss: 0.073003; Backpropagation: 0.6103 sec; Batch: 4.4852 sec\n",
            "0.1442 0.0944 0.0783 0.0717 0.0678 0.0663 0.0654 0.0649 0.0647 0.0644 0.0644 0.0643 0.0643 0.0642 0.0644 0.0644 \n",
            "\n",
            "[TRAIN] Epoch[1](337/1214); Loss: 0.069566; Backpropagation: 0.6119 sec; Batch: 4.4898 sec\n",
            "0.1452 0.0862 0.0722 0.0668 0.0642 0.0636 0.0624 0.0620 0.0616 0.0614 0.0612 0.0612 0.0612 0.0613 0.0613 0.0613 \n",
            "\n",
            "[TRAIN] Epoch[1](338/1214); Loss: 0.078223; Backpropagation: 0.6099 sec; Batch: 4.4858 sec\n",
            "0.1360 0.0955 0.0822 0.0766 0.0741 0.0730 0.0722 0.0721 0.0715 0.0714 0.0712 0.0711 0.0710 0.0712 0.0711 0.0713 \n",
            "\n",
            "[TRAIN] Epoch[1](339/1214); Loss: 0.072562; Backpropagation: 0.6176 sec; Batch: 4.4962 sec\n",
            "0.1347 0.0870 0.0748 0.0710 0.0677 0.0667 0.0660 0.0659 0.0657 0.0657 0.0658 0.0657 0.0659 0.0659 0.0662 0.0662 \n",
            "\n",
            "[TRAIN] Epoch[1](340/1214); Loss: 0.077008; Backpropagation: 0.6124 sec; Batch: 4.4845 sec\n",
            "0.1612 0.1012 0.0799 0.0736 0.0704 0.0693 0.0684 0.0682 0.0680 0.0676 0.0675 0.0673 0.0674 0.0673 0.0674 0.0674 \n",
            "\n",
            "[TRAIN] Epoch[1](341/1214); Loss: 0.076676; Backpropagation: 0.6059 sec; Batch: 4.4791 sec\n",
            "0.1446 0.0967 0.0802 0.0745 0.0714 0.0702 0.0696 0.0693 0.0691 0.0688 0.0688 0.0685 0.0687 0.0687 0.0689 0.0688 \n",
            "\n",
            "[TRAIN] Epoch[1](342/1214); Loss: 0.063493; Backpropagation: 0.6241 sec; Batch: 4.5009 sec\n",
            "0.1272 0.0798 0.0685 0.0618 0.0595 0.0578 0.0571 0.0564 0.0562 0.0561 0.0560 0.0559 0.0559 0.0559 0.0558 0.0561 \n",
            "\n",
            "[TRAIN] Epoch[1](343/1214); Loss: 0.068875; Backpropagation: 0.6078 sec; Batch: 4.4806 sec\n",
            "0.1400 0.0870 0.0713 0.0665 0.0636 0.0624 0.0618 0.0614 0.0612 0.0610 0.0610 0.0609 0.0609 0.0609 0.0610 0.0610 \n",
            "\n",
            "[TRAIN] Epoch[1](344/1214); Loss: 0.071307; Backpropagation: 0.6153 sec; Batch: 4.4868 sec\n",
            "0.1565 0.0916 0.0743 0.0673 0.0646 0.0631 0.0629 0.0626 0.0625 0.0623 0.0623 0.0622 0.0621 0.0622 0.0622 0.0621 \n",
            "\n",
            "[TRAIN] Epoch[1](345/1214); Loss: 0.075147; Backpropagation: 0.6160 sec; Batch: 4.4918 sec\n",
            "0.1362 0.0971 0.0833 0.0756 0.0709 0.0692 0.0677 0.0675 0.0670 0.0672 0.0668 0.0668 0.0667 0.0668 0.0668 0.0669 \n",
            "\n",
            "[TRAIN] Epoch[1](346/1214); Loss: 0.072900; Backpropagation: 0.6074 sec; Batch: 4.4812 sec\n",
            "0.1496 0.0908 0.0749 0.0695 0.0669 0.0658 0.0653 0.0648 0.0647 0.0647 0.0648 0.0646 0.0649 0.0649 0.0651 0.0652 \n",
            "\n",
            "[TRAIN] Epoch[1](347/1214); Loss: 0.078648; Backpropagation: 0.6157 sec; Batch: 4.4895 sec\n",
            "0.1295 0.0974 0.0840 0.0786 0.0752 0.0737 0.0727 0.0724 0.0722 0.0719 0.0718 0.0717 0.0719 0.0718 0.0718 0.0718 \n",
            "\n",
            "[TRAIN] Epoch[1](348/1214); Loss: 0.081017; Backpropagation: 0.6122 sec; Batch: 4.4844 sec\n",
            "0.1402 0.0988 0.0838 0.0805 0.0774 0.0760 0.0748 0.0745 0.0740 0.0738 0.0737 0.0736 0.0737 0.0738 0.0738 0.0739 \n",
            "\n",
            "[TRAIN] Epoch[1](349/1214); Loss: 0.071806; Backpropagation: 0.6197 sec; Batch: 4.4950 sec\n",
            "0.1235 0.0880 0.0748 0.0705 0.0680 0.0667 0.0660 0.0657 0.0655 0.0655 0.0654 0.0656 0.0658 0.0658 0.0659 0.0662 \n",
            "\n",
            "[TRAIN] Epoch[1](350/1214); Loss: 0.088010; Backpropagation: 0.6127 sec; Batch: 4.4846 sec\n",
            "0.1559 0.1098 0.0924 0.0874 0.0835 0.0820 0.0809 0.0805 0.0800 0.0798 0.0795 0.0795 0.0793 0.0792 0.0793 0.0792 \n",
            "\n",
            "[TRAIN] Epoch[1](351/1214); Loss: 0.080521; Backpropagation: 0.6155 sec; Batch: 4.4929 sec\n",
            "0.1400 0.0995 0.0850 0.0796 0.0761 0.0745 0.0742 0.0736 0.0736 0.0734 0.0734 0.0732 0.0731 0.0730 0.0731 0.0731 \n",
            "\n",
            "[TRAIN] Epoch[1](352/1214); Loss: 0.071539; Backpropagation: 0.6137 sec; Batch: 4.4869 sec\n",
            "0.1213 0.0844 0.0739 0.0705 0.0685 0.0671 0.0666 0.0662 0.0660 0.0659 0.0657 0.0657 0.0656 0.0657 0.0657 0.0659 \n",
            "\n",
            "[TRAIN] Epoch[1](353/1214); Loss: 0.076395; Backpropagation: 0.6179 sec; Batch: 4.4888 sec\n",
            "0.1383 0.0958 0.0791 0.0759 0.0721 0.0708 0.0698 0.0694 0.0691 0.0689 0.0689 0.0687 0.0688 0.0690 0.0689 0.0689 \n",
            "\n",
            "[TRAIN] Epoch[1](354/1214); Loss: 0.071465; Backpropagation: 0.6150 sec; Batch: 4.4878 sec\n",
            "0.1356 0.0926 0.0756 0.0694 0.0665 0.0654 0.0648 0.0643 0.0640 0.0638 0.0637 0.0635 0.0635 0.0636 0.0636 0.0637 \n",
            "\n",
            "[TRAIN] Epoch[1](355/1214); Loss: 0.084715; Backpropagation: 0.6137 sec; Batch: 4.4869 sec\n",
            "0.1443 0.1001 0.0903 0.0841 0.0809 0.0796 0.0789 0.0782 0.0780 0.0776 0.0776 0.0772 0.0773 0.0771 0.0772 0.0771 \n",
            "\n",
            "[TRAIN] Epoch[1](356/1214); Loss: 0.077574; Backpropagation: 0.6113 sec; Batch: 4.4893 sec\n",
            "0.1433 0.0929 0.0801 0.0754 0.0729 0.0720 0.0714 0.0710 0.0706 0.0705 0.0702 0.0702 0.0702 0.0702 0.0702 0.0702 \n",
            "\n",
            "[TRAIN] Epoch[1](357/1214); Loss: 0.077582; Backpropagation: 0.6136 sec; Batch: 4.4856 sec\n",
            "0.1375 0.0905 0.0798 0.0760 0.0734 0.0725 0.0717 0.0714 0.0712 0.0711 0.0710 0.0710 0.0710 0.0711 0.0710 0.0711 \n",
            "\n",
            "[TRAIN] Epoch[1](358/1214); Loss: 0.075538; Backpropagation: 0.6161 sec; Batch: 4.4975 sec\n",
            "0.1289 0.0895 0.0788 0.0739 0.0719 0.0707 0.0702 0.0698 0.0697 0.0693 0.0693 0.0693 0.0694 0.0692 0.0693 0.0694 \n",
            "\n",
            "[TRAIN] Epoch[1](359/1214); Loss: 0.085358; Backpropagation: 0.6119 sec; Batch: 4.4854 sec\n",
            "0.1339 0.0999 0.0896 0.0850 0.0821 0.0809 0.0800 0.0797 0.0796 0.0794 0.0794 0.0792 0.0793 0.0792 0.0793 0.0793 \n",
            "\n",
            "[TRAIN] Epoch[1](360/1214); Loss: 0.079495; Backpropagation: 0.6106 sec; Batch: 4.4861 sec\n",
            "0.1307 0.0967 0.0846 0.0794 0.0766 0.0750 0.0742 0.0735 0.0733 0.0729 0.0727 0.0725 0.0725 0.0723 0.0725 0.0726 \n",
            "\n",
            "[TRAIN] Epoch[1](361/1214); Loss: 0.073722; Backpropagation: 0.6424 sec; Batch: 4.5194 sec\n",
            "0.1514 0.0891 0.0752 0.0710 0.0684 0.0674 0.0662 0.0660 0.0658 0.0658 0.0656 0.0656 0.0655 0.0656 0.0654 0.0656 \n",
            "\n",
            "[TRAIN] Epoch[1](362/1214); Loss: 0.074221; Backpropagation: 0.6175 sec; Batch: 4.4913 sec\n",
            "0.1302 0.0892 0.0760 0.0719 0.0698 0.0689 0.0686 0.0684 0.0683 0.0681 0.0681 0.0679 0.0680 0.0680 0.0681 0.0682 \n",
            "\n",
            "[TRAIN] Epoch[1](363/1214); Loss: 0.089856; Backpropagation: 0.6181 sec; Batch: 4.5007 sec\n",
            "0.1367 0.1054 0.0943 0.0895 0.0867 0.0854 0.0848 0.0846 0.0841 0.0841 0.0838 0.0838 0.0836 0.0838 0.0836 0.0836 \n",
            "\n",
            "[TRAIN] Epoch[1](364/1214); Loss: 0.082976; Backpropagation: 0.6202 sec; Batch: 4.4936 sec\n",
            "0.1385 0.1039 0.0900 0.0821 0.0793 0.0777 0.0768 0.0763 0.0758 0.0756 0.0756 0.0752 0.0751 0.0752 0.0752 0.0752 \n",
            "\n",
            "[TRAIN] Epoch[1](365/1214); Loss: 0.080946; Backpropagation: 0.6163 sec; Batch: 4.4943 sec\n",
            "0.1398 0.1021 0.0857 0.0802 0.0776 0.0757 0.0747 0.0741 0.0737 0.0733 0.0732 0.0731 0.0730 0.0730 0.0730 0.0730 \n",
            "\n",
            "[TRAIN] Epoch[1](366/1214); Loss: 0.069785; Backpropagation: 0.6202 sec; Batch: 4.5024 sec\n",
            "0.1248 0.0951 0.0788 0.0689 0.0657 0.0641 0.0632 0.0624 0.0623 0.0617 0.0617 0.0615 0.0617 0.0614 0.0616 0.0616 \n",
            "\n",
            "[TRAIN] Epoch[1](367/1214); Loss: 0.084137; Backpropagation: 0.6134 sec; Batch: 4.4821 sec\n",
            "0.1460 0.1038 0.0885 0.0830 0.0798 0.0779 0.0773 0.0769 0.0769 0.0767 0.0766 0.0765 0.0765 0.0766 0.0765 0.0767 \n",
            "\n",
            "[TRAIN] Epoch[1](368/1214); Loss: 0.077815; Backpropagation: 0.6151 sec; Batch: 4.4887 sec\n",
            "0.1357 0.0919 0.0809 0.0758 0.0741 0.0726 0.0720 0.0716 0.0715 0.0714 0.0713 0.0712 0.0713 0.0712 0.0713 0.0715 \n",
            "\n",
            "[TRAIN] Epoch[1](369/1214); Loss: 0.073724; Backpropagation: 0.6173 sec; Batch: 4.4967 sec\n",
            "0.1345 0.0904 0.0773 0.0721 0.0698 0.0679 0.0680 0.0671 0.0670 0.0665 0.0665 0.0664 0.0666 0.0665 0.0665 0.0664 \n",
            "\n",
            "[TRAIN] Epoch[1](370/1214); Loss: 0.080395; Backpropagation: 0.6169 sec; Batch: 4.4924 sec\n",
            "0.1311 0.0977 0.0839 0.0798 0.0773 0.0763 0.0751 0.0747 0.0742 0.0741 0.0738 0.0739 0.0736 0.0736 0.0735 0.0735 \n",
            "\n",
            "[TRAIN] Epoch[1](371/1214); Loss: 0.073893; Backpropagation: 0.6094 sec; Batch: 4.4856 sec\n",
            "0.1307 0.0913 0.0777 0.0734 0.0703 0.0688 0.0680 0.0674 0.0671 0.0669 0.0668 0.0667 0.0668 0.0668 0.0669 0.0667 \n",
            "\n",
            "[TRAIN] Epoch[1](372/1214); Loss: 0.073400; Backpropagation: 0.6062 sec; Batch: 4.4743 sec\n",
            "0.1310 0.0948 0.0776 0.0723 0.0695 0.0680 0.0670 0.0667 0.0664 0.0662 0.0661 0.0659 0.0659 0.0657 0.0657 0.0656 \n",
            "\n",
            "[TRAIN] Epoch[1](373/1214); Loss: 0.076706; Backpropagation: 0.6194 sec; Batch: 4.4935 sec\n",
            "0.1239 0.0969 0.0812 0.0763 0.0740 0.0729 0.0716 0.0709 0.0705 0.0702 0.0701 0.0702 0.0698 0.0697 0.0696 0.0696 \n",
            "\n",
            "[TRAIN] Epoch[1](374/1214); Loss: 0.076186; Backpropagation: 0.6088 sec; Batch: 4.4863 sec\n",
            "0.1452 0.0953 0.0803 0.0741 0.0716 0.0701 0.0694 0.0688 0.0687 0.0682 0.0681 0.0677 0.0678 0.0677 0.0680 0.0679 \n",
            "\n",
            "[TRAIN] Epoch[1](375/1214); Loss: 0.078806; Backpropagation: 0.6132 sec; Batch: 4.4895 sec\n",
            "0.1471 0.1034 0.0848 0.0777 0.0737 0.0724 0.0715 0.0709 0.0705 0.0702 0.0700 0.0698 0.0699 0.0698 0.0697 0.0697 \n",
            "\n",
            "[TRAIN] Epoch[1](376/1214); Loss: 0.074420; Backpropagation: 0.6125 sec; Batch: 4.4852 sec\n",
            "0.1285 0.0953 0.0797 0.0736 0.0709 0.0692 0.0683 0.0676 0.0675 0.0672 0.0671 0.0669 0.0671 0.0671 0.0672 0.0672 \n",
            "\n",
            "[TRAIN] Epoch[1](377/1214); Loss: 0.078266; Backpropagation: 0.6122 sec; Batch: 4.4836 sec\n",
            "0.1318 0.0908 0.0820 0.0767 0.0750 0.0735 0.0732 0.0725 0.0726 0.0721 0.0723 0.0719 0.0720 0.0719 0.0721 0.0720 \n",
            "\n",
            "[TRAIN] Epoch[1](378/1214); Loss: 0.077932; Backpropagation: 0.6119 sec; Batch: 4.4933 sec\n",
            "0.1323 0.0969 0.0827 0.0770 0.0741 0.0733 0.0722 0.0719 0.0714 0.0711 0.0708 0.0709 0.0707 0.0706 0.0705 0.0705 \n",
            "\n",
            "[TRAIN] Epoch[1](379/1214); Loss: 0.068597; Backpropagation: 0.6185 sec; Batch: 4.4885 sec\n",
            "0.1450 0.0931 0.0733 0.0660 0.0630 0.0614 0.0607 0.0600 0.0597 0.0594 0.0595 0.0596 0.0592 0.0592 0.0592 0.0592 \n",
            "\n",
            "[TRAIN] Epoch[1](380/1214); Loss: 0.070784; Backpropagation: 0.6130 sec; Batch: 4.4863 sec\n",
            "0.1287 0.0876 0.0743 0.0695 0.0668 0.0658 0.0651 0.0644 0.0639 0.0638 0.0638 0.0638 0.0637 0.0639 0.0637 0.0638 \n",
            "\n",
            "[TRAIN] Epoch[1](381/1214); Loss: 0.071547; Backpropagation: 0.6163 sec; Batch: 4.4901 sec\n",
            "0.1349 0.0877 0.0753 0.0709 0.0683 0.0663 0.0654 0.0648 0.0645 0.0643 0.0639 0.0639 0.0637 0.0638 0.0636 0.0635 \n",
            "\n",
            "[TRAIN] Epoch[1](382/1214); Loss: 0.073648; Backpropagation: 0.6138 sec; Batch: 4.4866 sec\n",
            "0.1228 0.0914 0.0788 0.0726 0.0704 0.0689 0.0683 0.0677 0.0674 0.0672 0.0673 0.0672 0.0672 0.0671 0.0671 0.0670 \n",
            "\n",
            "[TRAIN] Epoch[1](383/1214); Loss: 0.076996; Backpropagation: 0.6162 sec; Batch: 4.4891 sec\n",
            "0.1410 0.0943 0.0822 0.0759 0.0732 0.0716 0.0708 0.0699 0.0696 0.0693 0.0692 0.0690 0.0690 0.0689 0.0689 0.0689 \n",
            "\n",
            "[TRAIN] Epoch[1](384/1214); Loss: 0.078877; Backpropagation: 0.6149 sec; Batch: 4.4936 sec\n",
            "0.1471 0.0978 0.0869 0.0773 0.0745 0.0730 0.0721 0.0716 0.0708 0.0707 0.0703 0.0702 0.0701 0.0700 0.0698 0.0697 \n",
            "\n",
            "[TRAIN] Epoch[1](385/1214); Loss: 0.082452; Backpropagation: 0.6144 sec; Batch: 4.4876 sec\n",
            "0.1426 0.1026 0.0884 0.0815 0.0789 0.0775 0.0763 0.0756 0.0750 0.0748 0.0746 0.0745 0.0743 0.0743 0.0743 0.0741 \n",
            "\n",
            "[TRAIN] Epoch[1](386/1214); Loss: 0.083294; Backpropagation: 0.6105 sec; Batch: 4.4894 sec\n",
            "0.1478 0.1002 0.0868 0.0819 0.0795 0.0778 0.0770 0.0765 0.0760 0.0759 0.0758 0.0756 0.0755 0.0755 0.0755 0.0754 \n",
            "\n",
            "[TRAIN] Epoch[1](387/1214); Loss: 0.074496; Backpropagation: 0.6137 sec; Batch: 4.4912 sec\n",
            "0.1481 0.0982 0.0824 0.0736 0.0696 0.0672 0.0662 0.0657 0.0654 0.0652 0.0652 0.0649 0.0650 0.0650 0.0652 0.0651 \n",
            "\n",
            "[TRAIN] Epoch[1](388/1214); Loss: 0.072331; Backpropagation: 0.6116 sec; Batch: 4.4888 sec\n",
            "0.1404 0.0893 0.0756 0.0699 0.0679 0.0663 0.0657 0.0652 0.0652 0.0649 0.0648 0.0644 0.0645 0.0643 0.0644 0.0644 \n",
            "\n",
            "[TRAIN] Epoch[1](389/1214); Loss: 0.076250; Backpropagation: 0.6141 sec; Batch: 4.4829 sec\n",
            "0.1440 0.0931 0.0799 0.0752 0.0724 0.0705 0.0696 0.0690 0.0687 0.0686 0.0683 0.0682 0.0679 0.0683 0.0681 0.0682 \n",
            "\n",
            "[TRAIN] Epoch[1](390/1214); Loss: 0.073093; Backpropagation: 0.6126 sec; Batch: 4.4838 sec\n",
            "0.1303 0.0929 0.0775 0.0721 0.0700 0.0679 0.0674 0.0666 0.0665 0.0659 0.0657 0.0654 0.0655 0.0653 0.0653 0.0652 \n",
            "\n",
            "[TRAIN] Epoch[1](391/1214); Loss: 0.078553; Backpropagation: 0.6113 sec; Batch: 4.4884 sec\n",
            "0.1422 0.0987 0.0824 0.0774 0.0747 0.0733 0.0723 0.0715 0.0710 0.0708 0.0707 0.0706 0.0705 0.0702 0.0704 0.0702 \n",
            "\n",
            "[TRAIN] Epoch[1](392/1214); Loss: 0.071417; Backpropagation: 0.6168 sec; Batch: 4.4971 sec\n",
            "0.1265 0.0852 0.0764 0.0711 0.0686 0.0672 0.0660 0.0655 0.0649 0.0649 0.0645 0.0644 0.0643 0.0644 0.0644 0.0645 \n",
            "\n",
            "[TRAIN] Epoch[1](393/1214); Loss: 0.074495; Backpropagation: 0.6137 sec; Batch: 4.4864 sec\n",
            "0.1312 0.0902 0.0802 0.0743 0.0713 0.0698 0.0687 0.0681 0.0676 0.0675 0.0672 0.0672 0.0672 0.0672 0.0670 0.0671 \n",
            "\n",
            "[TRAIN] Epoch[1](394/1214); Loss: 0.071958; Backpropagation: 0.6160 sec; Batch: 4.4935 sec\n",
            "0.1204 0.0856 0.0746 0.0712 0.0686 0.0679 0.0670 0.0667 0.0662 0.0661 0.0661 0.0661 0.0661 0.0663 0.0661 0.0663 \n",
            "\n",
            "[TRAIN] Epoch[1](395/1214); Loss: 0.067406; Backpropagation: 0.6183 sec; Batch: 4.4952 sec\n",
            "0.1179 0.0860 0.0729 0.0669 0.0643 0.0624 0.0618 0.0611 0.0609 0.0606 0.0605 0.0605 0.0604 0.0608 0.0608 0.0607 \n",
            "\n",
            "[TRAIN] Epoch[1](396/1214); Loss: 0.077212; Backpropagation: 0.6077 sec; Batch: 4.4799 sec\n",
            "0.1456 0.0977 0.0811 0.0753 0.0727 0.0711 0.0703 0.0698 0.0693 0.0690 0.0690 0.0688 0.0688 0.0689 0.0689 0.0690 \n",
            "\n",
            "[TRAIN] Epoch[1](397/1214); Loss: 0.083813; Backpropagation: 0.6225 sec; Batch: 4.4950 sec\n",
            "0.1360 0.1002 0.0882 0.0833 0.0802 0.0793 0.0784 0.0780 0.0776 0.0775 0.0772 0.0772 0.0769 0.0771 0.0769 0.0769 \n",
            "\n",
            "[TRAIN] Epoch[1](398/1214); Loss: 0.068754; Backpropagation: 0.6128 sec; Batch: 4.4861 sec\n",
            "0.1378 0.0848 0.0725 0.0670 0.0648 0.0629 0.0620 0.0615 0.0613 0.0611 0.0609 0.0609 0.0607 0.0606 0.0607 0.0607 \n",
            "\n",
            "[TRAIN] Epoch[1](399/1214); Loss: 0.084188; Backpropagation: 0.6160 sec; Batch: 4.4898 sec\n",
            "0.1479 0.1037 0.0879 0.0818 0.0796 0.0790 0.0782 0.0774 0.0771 0.0769 0.0765 0.0764 0.0763 0.0762 0.0760 0.0760 \n",
            "\n",
            "[TRAIN] Epoch[1](400/1214); Loss: 0.086776; Backpropagation: 0.6086 sec; Batch: 4.4882 sec\n",
            "0.1288 0.1011 0.0908 0.0863 0.0843 0.0829 0.0824 0.0818 0.0816 0.0813 0.0813 0.0813 0.0811 0.0811 0.0811 0.0810 \n",
            "\n",
            "[TRAIN] Epoch[1](401/1214); Loss: 0.072556; Backpropagation: 0.6093 sec; Batch: 4.4838 sec\n",
            "0.1205 0.0861 0.0758 0.0718 0.0696 0.0683 0.0678 0.0673 0.0671 0.0669 0.0667 0.0666 0.0665 0.0665 0.0666 0.0667 \n",
            "\n",
            "[TRAIN] Epoch[1](402/1214); Loss: 0.081711; Backpropagation: 0.6171 sec; Batch: 4.4965 sec\n",
            "0.1495 0.1000 0.0855 0.0808 0.0775 0.0763 0.0750 0.0747 0.0742 0.0738 0.0735 0.0734 0.0734 0.0733 0.0733 0.0733 \n",
            "\n",
            "[TRAIN] Epoch[1](403/1214); Loss: 0.085232; Backpropagation: 0.6168 sec; Batch: 4.4929 sec\n",
            "0.1365 0.0991 0.0875 0.0831 0.0814 0.0803 0.0797 0.0796 0.0794 0.0795 0.0794 0.0794 0.0794 0.0797 0.0797 0.0799 \n",
            "\n",
            "[TRAIN] Epoch[1](404/1214); Loss: 0.086632; Backpropagation: 0.6224 sec; Batch: 4.5012 sec\n",
            "0.1305 0.0984 0.0901 0.0859 0.0839 0.0828 0.0821 0.0815 0.0813 0.0810 0.0812 0.0812 0.0814 0.0815 0.0818 0.0818 \n",
            "\n",
            "[TRAIN] Epoch[1](405/1214); Loss: 0.072857; Backpropagation: 0.6116 sec; Batch: 4.4871 sec\n",
            "0.1222 0.0923 0.0769 0.0727 0.0695 0.0681 0.0671 0.0667 0.0663 0.0663 0.0661 0.0661 0.0661 0.0663 0.0664 0.0665 \n",
            "\n",
            "[TRAIN] Epoch[1](406/1214); Loss: 0.074169; Backpropagation: 0.6099 sec; Batch: 4.4829 sec\n",
            "0.1263 0.0931 0.0802 0.0741 0.0712 0.0693 0.0683 0.0677 0.0674 0.0674 0.0672 0.0671 0.0670 0.0670 0.0668 0.0668 \n",
            "\n",
            "[TRAIN] Epoch[1](407/1214); Loss: 0.075472; Backpropagation: 0.6153 sec; Batch: 4.4924 sec\n",
            "0.1315 0.0963 0.0798 0.0741 0.0715 0.0704 0.0693 0.0691 0.0686 0.0685 0.0682 0.0681 0.0680 0.0681 0.0680 0.0680 \n",
            "\n",
            "[TRAIN] Epoch[1](408/1214); Loss: 0.062875; Backpropagation: 0.6090 sec; Batch: 4.4770 sec\n",
            "0.1212 0.0811 0.0668 0.0615 0.0585 0.0573 0.0568 0.0564 0.0560 0.0559 0.0558 0.0557 0.0557 0.0558 0.0557 0.0558 \n",
            "\n",
            "[TRAIN] Epoch[1](409/1214); Loss: 0.079178; Backpropagation: 0.6183 sec; Batch: 4.4992 sec\n",
            "0.1478 0.0982 0.0849 0.0780 0.0744 0.0731 0.0722 0.0716 0.0713 0.0711 0.0709 0.0708 0.0707 0.0707 0.0704 0.0706 \n",
            "\n",
            "[TRAIN] Epoch[1](410/1214); Loss: 0.085466; Backpropagation: 0.6144 sec; Batch: 4.4864 sec\n",
            "0.1313 0.1013 0.0904 0.0846 0.0826 0.0815 0.0807 0.0803 0.0798 0.0795 0.0794 0.0793 0.0792 0.0792 0.0792 0.0791 \n",
            "\n",
            "[TRAIN] Epoch[1](411/1214); Loss: 0.073917; Backpropagation: 0.6118 sec; Batch: 4.4868 sec\n",
            "0.1363 0.0959 0.0807 0.0728 0.0697 0.0677 0.0670 0.0664 0.0662 0.0659 0.0659 0.0657 0.0657 0.0656 0.0657 0.0657 \n",
            "\n",
            "[TRAIN] Epoch[1](412/1214); Loss: 0.074328; Backpropagation: 0.6110 sec; Batch: 4.4854 sec\n",
            "0.1278 0.0906 0.0774 0.0734 0.0710 0.0701 0.0694 0.0687 0.0683 0.0680 0.0678 0.0676 0.0674 0.0674 0.0672 0.0673 \n",
            "\n",
            "[TRAIN] Epoch[1](413/1214); Loss: 0.072804; Backpropagation: 0.6170 sec; Batch: 4.4906 sec\n",
            "0.1296 0.0891 0.0760 0.0707 0.0690 0.0682 0.0673 0.0671 0.0665 0.0664 0.0661 0.0660 0.0657 0.0658 0.0655 0.0658 \n",
            "\n",
            "[TRAIN] Epoch[1](414/1214); Loss: 0.076632; Backpropagation: 0.6098 sec; Batch: 4.4954 sec\n",
            "0.1203 0.0931 0.0803 0.0765 0.0740 0.0731 0.0720 0.0717 0.0712 0.0711 0.0708 0.0707 0.0704 0.0705 0.0702 0.0704 \n",
            "\n",
            "[TRAIN] Epoch[1](415/1214); Loss: 0.073107; Backpropagation: 0.6094 sec; Batch: 4.4825 sec\n",
            "0.1451 0.0940 0.0767 0.0711 0.0683 0.0670 0.0659 0.0653 0.0651 0.0648 0.0645 0.0644 0.0644 0.0644 0.0644 0.0643 \n",
            "\n",
            "[TRAIN] Epoch[1](416/1214); Loss: 0.080172; Backpropagation: 0.6147 sec; Batch: 4.4845 sec\n",
            "0.1501 0.1021 0.0839 0.0786 0.0758 0.0746 0.0733 0.0727 0.0720 0.0717 0.0715 0.0716 0.0713 0.0712 0.0712 0.0712 \n",
            "\n",
            "[TRAIN] Epoch[1](417/1214); Loss: 0.086068; Backpropagation: 0.6103 sec; Batch: 4.4833 sec\n",
            "0.1579 0.1071 0.0918 0.0855 0.0819 0.0799 0.0790 0.0784 0.0779 0.0775 0.0770 0.0771 0.0765 0.0768 0.0764 0.0765 \n",
            "\n",
            "[TRAIN] Epoch[1](418/1214); Loss: 0.081075; Backpropagation: 0.6173 sec; Batch: 4.4937 sec\n",
            "0.1516 0.0997 0.0841 0.0781 0.0762 0.0751 0.0741 0.0739 0.0735 0.0733 0.0730 0.0731 0.0729 0.0730 0.0727 0.0729 \n",
            "\n",
            "[TRAIN] Epoch[1](419/1214); Loss: 0.068544; Backpropagation: 0.6191 sec; Batch: 4.4895 sec\n",
            "0.1197 0.0867 0.0739 0.0683 0.0660 0.0644 0.0634 0.0627 0.0620 0.0618 0.0617 0.0614 0.0613 0.0612 0.0612 0.0611 \n",
            "\n",
            "[TRAIN] Epoch[1](420/1214); Loss: 0.078967; Backpropagation: 0.6088 sec; Batch: 4.4862 sec\n",
            "0.1510 0.0998 0.0841 0.0772 0.0752 0.0732 0.0722 0.0711 0.0708 0.0703 0.0703 0.0698 0.0697 0.0696 0.0696 0.0694 \n",
            "\n",
            "[TRAIN] Epoch[1](421/1214); Loss: 0.069767; Backpropagation: 0.6154 sec; Batch: 4.4945 sec\n",
            "0.1362 0.0841 0.0728 0.0681 0.0649 0.0641 0.0637 0.0632 0.0629 0.0626 0.0625 0.0624 0.0624 0.0623 0.0621 0.0621 \n",
            "\n",
            "[TRAIN] Epoch[1](422/1214); Loss: 0.073139; Backpropagation: 0.6116 sec; Batch: 4.4910 sec\n",
            "0.1378 0.0893 0.0759 0.0716 0.0691 0.0679 0.0673 0.0667 0.0662 0.0660 0.0657 0.0657 0.0654 0.0654 0.0652 0.0652 \n",
            "\n",
            "[TRAIN] Epoch[1](423/1214); Loss: 0.081709; Backpropagation: 0.6125 sec; Batch: 4.4874 sec\n",
            "0.1356 0.0989 0.0886 0.0833 0.0791 0.0774 0.0761 0.0755 0.0749 0.0747 0.0742 0.0742 0.0738 0.0738 0.0736 0.0737 \n",
            "\n",
            "[TRAIN] Epoch[1](424/1214); Loss: 0.090891; Backpropagation: 0.6113 sec; Batch: 4.4869 sec\n",
            "0.1345 0.1096 0.0976 0.0923 0.0891 0.0873 0.0856 0.0852 0.0847 0.0846 0.0842 0.0843 0.0839 0.0839 0.0837 0.0837 \n",
            "\n",
            "[TRAIN] Epoch[1](425/1214); Loss: 0.074691; Backpropagation: 0.6139 sec; Batch: 4.4878 sec\n",
            "0.1291 0.0946 0.0847 0.0773 0.0733 0.0707 0.0692 0.0680 0.0672 0.0663 0.0662 0.0659 0.0657 0.0655 0.0656 0.0655 \n",
            "\n",
            "[TRAIN] Epoch[1](426/1214); Loss: 0.080933; Backpropagation: 0.6135 sec; Batch: 4.4868 sec\n",
            "0.1325 0.0995 0.0913 0.0861 0.0817 0.0791 0.0769 0.0751 0.0737 0.0730 0.0720 0.0715 0.0708 0.0708 0.0704 0.0704 \n",
            "\n",
            "[TRAIN] Epoch[1](427/1214); Loss: 0.070282; Backpropagation: 0.6130 sec; Batch: 4.4851 sec\n",
            "0.1252 0.0901 0.0785 0.0747 0.0694 0.0679 0.0652 0.0645 0.0630 0.0622 0.0612 0.0608 0.0603 0.0604 0.0604 0.0605 \n",
            "\n",
            "[TRAIN] Epoch[1](428/1214); Loss: 0.075870; Backpropagation: 0.6281 sec; Batch: 4.5069 sec\n",
            "0.1279 0.1005 0.0863 0.0799 0.0753 0.0725 0.0705 0.0691 0.0680 0.0672 0.0668 0.0664 0.0662 0.0658 0.0659 0.0657 \n",
            "\n",
            "[TRAIN] Epoch[1](429/1214); Loss: 0.077512; Backpropagation: 0.6104 sec; Batch: 4.4861 sec\n",
            "0.1305 0.0999 0.0853 0.0784 0.0744 0.0732 0.0715 0.0706 0.0700 0.0698 0.0695 0.0694 0.0694 0.0695 0.0695 0.0695 \n",
            "\n",
            "[TRAIN] Epoch[1](430/1214); Loss: 0.079385; Backpropagation: 0.6187 sec; Batch: 4.4929 sec\n",
            "0.1342 0.1001 0.0848 0.0807 0.0765 0.0749 0.0732 0.0727 0.0721 0.0720 0.0718 0.0715 0.0714 0.0715 0.0713 0.0714 \n",
            "\n",
            "[TRAIN] Epoch[1](431/1214); Loss: 0.069084; Backpropagation: 0.6115 sec; Batch: 4.4831 sec\n",
            "0.1309 0.0867 0.0754 0.0691 0.0660 0.0645 0.0627 0.0622 0.0616 0.0613 0.0609 0.0608 0.0608 0.0608 0.0609 0.0608 \n",
            "\n",
            "[TRAIN] Epoch[1](432/1214); Loss: 0.077747; Backpropagation: 0.6108 sec; Batch: 4.4904 sec\n",
            "0.1317 0.1007 0.0850 0.0776 0.0752 0.0727 0.0721 0.0710 0.0704 0.0698 0.0697 0.0696 0.0696 0.0696 0.0696 0.0697 \n",
            "\n",
            "[TRAIN] Epoch[1](433/1214); Loss: 0.087621; Backpropagation: 0.6069 sec; Batch: 4.4810 sec\n",
            "0.1391 0.1048 0.0950 0.0890 0.0848 0.0829 0.0819 0.0813 0.0811 0.0808 0.0805 0.0803 0.0802 0.0801 0.0801 0.0800 \n",
            "\n",
            "[TRAIN] Epoch[1](434/1214); Loss: 0.081786; Backpropagation: 0.6138 sec; Batch: 4.4961 sec\n",
            "0.1381 0.0994 0.0903 0.0819 0.0796 0.0773 0.0764 0.0755 0.0748 0.0742 0.0740 0.0737 0.0736 0.0734 0.0733 0.0733 \n",
            "\n",
            "[TRAIN] Epoch[1](435/1214); Loss: 0.080365; Backpropagation: 0.6141 sec; Batch: 4.4861 sec\n",
            "0.1452 0.1016 0.0877 0.0797 0.0771 0.0748 0.0739 0.0728 0.0725 0.0719 0.0717 0.0716 0.0715 0.0714 0.0714 0.0712 \n",
            "\n",
            "[TRAIN] Epoch[1](436/1214); Loss: 0.075981; Backpropagation: 0.6216 sec; Batch: 4.4992 sec\n",
            "0.1352 0.1011 0.0874 0.0777 0.0734 0.0706 0.0691 0.0681 0.0677 0.0670 0.0668 0.0664 0.0664 0.0663 0.0663 0.0661 \n",
            "\n",
            "[TRAIN] Epoch[1](437/1214); Loss: 0.080452; Backpropagation: 0.6120 sec; Batch: 4.4843 sec\n",
            "0.1358 0.1005 0.0891 0.0831 0.0793 0.0760 0.0747 0.0737 0.0731 0.0723 0.0720 0.0716 0.0715 0.0715 0.0715 0.0715 \n",
            "\n",
            "[TRAIN] Epoch[1](438/1214); Loss: 0.078678; Backpropagation: 0.6136 sec; Batch: 4.4811 sec\n",
            "0.1314 0.0947 0.0834 0.0779 0.0756 0.0744 0.0736 0.0729 0.0724 0.0722 0.0721 0.0717 0.0716 0.0715 0.0717 0.0718 \n",
            "\n",
            "[TRAIN] Epoch[1](439/1214); Loss: 0.085283; Backpropagation: 0.6058 sec; Batch: 4.4728 sec\n",
            "0.1388 0.1059 0.0929 0.0869 0.0837 0.0807 0.0795 0.0785 0.0781 0.0779 0.0776 0.0771 0.0769 0.0767 0.0767 0.0767 \n",
            "\n",
            "[TRAIN] Epoch[1](440/1214); Loss: 0.077932; Backpropagation: 0.6196 sec; Batch: 4.4915 sec\n",
            "0.1321 0.0991 0.0861 0.0792 0.0758 0.0735 0.0724 0.0712 0.0707 0.0701 0.0699 0.0696 0.0695 0.0694 0.0693 0.0692 \n",
            "\n",
            "[TRAIN] Epoch[1](441/1214); Loss: 0.072337; Backpropagation: 0.6123 sec; Batch: 4.4793 sec\n",
            "0.1268 0.0881 0.0797 0.0725 0.0701 0.0680 0.0673 0.0661 0.0655 0.0651 0.0649 0.0646 0.0646 0.0645 0.0645 0.0647 \n",
            "\n",
            "[TRAIN] Epoch[1](442/1214); Loss: 0.081480; Backpropagation: 0.6174 sec; Batch: 4.4879 sec\n",
            "0.1428 0.0998 0.0879 0.0813 0.0783 0.0761 0.0752 0.0744 0.0742 0.0736 0.0736 0.0734 0.0735 0.0733 0.0732 0.0732 \n",
            "\n",
            "[TRAIN] Epoch[1](443/1214); Loss: 0.075608; Backpropagation: 0.6135 sec; Batch: 4.4920 sec\n",
            "0.1386 0.1008 0.0874 0.0753 0.0722 0.0697 0.0683 0.0673 0.0670 0.0666 0.0664 0.0662 0.0660 0.0660 0.0659 0.0659 \n",
            "\n",
            "[TRAIN] Epoch[1](444/1214); Loss: 0.076292; Backpropagation: 0.6090 sec; Batch: 4.4903 sec\n",
            "0.1337 0.0975 0.0852 0.0773 0.0735 0.0709 0.0699 0.0691 0.0686 0.0683 0.0681 0.0679 0.0678 0.0678 0.0677 0.0676 \n",
            "\n",
            "[TRAIN] Epoch[1](445/1214); Loss: 0.077382; Backpropagation: 0.6102 sec; Batch: 4.4940 sec\n",
            "0.1383 0.0934 0.0820 0.0774 0.0743 0.0726 0.0716 0.0711 0.0706 0.0702 0.0698 0.0697 0.0695 0.0693 0.0693 0.0691 \n",
            "\n",
            "[TRAIN] Epoch[1](446/1214); Loss: 0.071542; Backpropagation: 0.6211 sec; Batch: 4.4952 sec\n",
            "0.1398 0.0876 0.0789 0.0718 0.0677 0.0660 0.0650 0.0643 0.0638 0.0635 0.0631 0.0629 0.0627 0.0625 0.0625 0.0625 \n",
            "\n",
            "[TRAIN] Epoch[1](447/1214); Loss: 0.074860; Backpropagation: 0.6048 sec; Batch: 4.4743 sec\n",
            "0.1482 0.1007 0.0869 0.0764 0.0715 0.0682 0.0665 0.0655 0.0650 0.0646 0.0644 0.0642 0.0641 0.0640 0.0638 0.0637 \n",
            "\n",
            "[TRAIN] Epoch[1](448/1214); Loss: 0.070415; Backpropagation: 0.6094 sec; Batch: 4.4839 sec\n",
            "0.1269 0.0957 0.0835 0.0757 0.0701 0.0671 0.0647 0.0628 0.0617 0.0609 0.0604 0.0600 0.0597 0.0593 0.0591 0.0589 \n",
            "\n",
            "[TRAIN] Epoch[1](449/1214); Loss: 0.073262; Backpropagation: 0.6143 sec; Batch: 4.4847 sec\n",
            "0.1405 0.0995 0.0941 0.0828 0.0753 0.0698 0.0663 0.0640 0.0620 0.0611 0.0603 0.0598 0.0594 0.0592 0.0592 0.0590 \n",
            "\n",
            "[TRAIN] Epoch[1](450/1214); Loss: 0.073133; Backpropagation: 0.6190 sec; Batch: 4.4822 sec\n",
            "0.1317 0.0957 0.0845 0.0766 0.0728 0.0690 0.0672 0.0658 0.0647 0.0641 0.0640 0.0633 0.0630 0.0628 0.0625 0.0624 \n",
            "\n",
            "[TRAIN] Epoch[1](451/1214); Loss: 0.080743; Backpropagation: 0.6102 sec; Batch: 4.4880 sec\n",
            "0.1388 0.0998 0.0922 0.0847 0.0811 0.0783 0.0757 0.0742 0.0727 0.0718 0.0711 0.0709 0.0705 0.0702 0.0701 0.0700 \n",
            "\n",
            "[TRAIN] Epoch[1](452/1214); Loss: 0.079493; Backpropagation: 0.6196 sec; Batch: 4.4893 sec\n",
            "0.1391 0.1107 0.0999 0.0893 0.0816 0.0759 0.0724 0.0709 0.0688 0.0677 0.0669 0.0665 0.0656 0.0656 0.0654 0.0654 \n",
            "\n",
            "[TRAIN] Epoch[1](453/1214); Loss: 0.086008; Backpropagation: 0.6108 sec; Batch: 4.4840 sec\n",
            "0.1391 0.1100 0.1026 0.0927 0.0883 0.0849 0.0816 0.0793 0.0775 0.0760 0.0753 0.0744 0.0743 0.0736 0.0735 0.0732 \n",
            "\n",
            "[TRAIN] Epoch[1](454/1214); Loss: 0.089852; Backpropagation: 0.6235 sec; Batch: 4.4942 sec\n",
            "0.1550 0.1240 0.1068 0.0973 0.0918 0.0881 0.0838 0.0813 0.0791 0.0778 0.0768 0.0762 0.0755 0.0750 0.0748 0.0744 \n",
            "\n",
            "[TRAIN] Epoch[1](455/1214); Loss: 0.074829; Backpropagation: 0.6075 sec; Batch: 4.4848 sec\n",
            "0.1342 0.1045 0.0866 0.0767 0.0736 0.0694 0.0684 0.0670 0.0653 0.0653 0.0646 0.0646 0.0640 0.0644 0.0639 0.0646 \n",
            "\n",
            "[TRAIN] Epoch[1](456/1214); Loss: 0.082243; Backpropagation: 0.6119 sec; Batch: 4.4889 sec\n",
            "0.1503 0.1101 0.0942 0.0837 0.0803 0.0779 0.0755 0.0739 0.0727 0.0719 0.0714 0.0711 0.0708 0.0707 0.0706 0.0708 \n",
            "\n",
            "[TRAIN] Epoch[1](457/1214); Loss: 0.081911; Backpropagation: 0.6097 sec; Batch: 4.4900 sec\n",
            "0.1377 0.1085 0.0961 0.0859 0.0816 0.0784 0.0769 0.0742 0.0727 0.0724 0.0718 0.0714 0.0710 0.0709 0.0705 0.0705 \n",
            "\n",
            "[TRAIN] Epoch[1](458/1214); Loss: 0.085319; Backpropagation: 0.6124 sec; Batch: 4.4869 sec\n",
            "0.1485 0.1139 0.0988 0.0863 0.0829 0.0794 0.0782 0.0770 0.0765 0.0756 0.0752 0.0749 0.0746 0.0745 0.0743 0.0744 \n",
            "\n",
            "[TRAIN] Epoch[1](459/1214); Loss: 0.082168; Backpropagation: 0.6223 sec; Batch: 4.4970 sec\n",
            "0.1483 0.1104 0.0947 0.0862 0.0807 0.0785 0.0754 0.0736 0.0722 0.0715 0.0711 0.0706 0.0705 0.0703 0.0704 0.0703 \n",
            "\n",
            "[TRAIN] Epoch[1](460/1214); Loss: 0.094793; Backpropagation: 0.6161 sec; Batch: 4.4940 sec\n",
            "0.1685 0.1270 0.1091 0.0985 0.0930 0.0890 0.0874 0.0853 0.0840 0.0833 0.0825 0.0821 0.0819 0.0818 0.0816 0.0816 \n",
            "\n",
            "[TRAIN] Epoch[1](461/1214); Loss: 0.071935; Backpropagation: 0.6148 sec; Batch: 4.4885 sec\n",
            "0.1429 0.1078 0.0871 0.0767 0.0696 0.0655 0.0631 0.0616 0.0612 0.0602 0.0599 0.0596 0.0594 0.0589 0.0588 0.0587 \n",
            "\n",
            "[TRAIN] Epoch[1](462/1214); Loss: 0.074205; Backpropagation: 0.6108 sec; Batch: 4.4927 sec\n",
            "0.1563 0.1052 0.0838 0.0724 0.0706 0.0673 0.0662 0.0643 0.0638 0.0634 0.0629 0.0627 0.0622 0.0622 0.0621 0.0617 \n",
            "\n",
            "[TRAIN] Epoch[1](463/1214); Loss: 0.076889; Backpropagation: 0.6134 sec; Batch: 4.4848 sec\n",
            "0.1585 0.1076 0.0882 0.0807 0.0742 0.0696 0.0683 0.0670 0.0661 0.0648 0.0648 0.0642 0.0642 0.0641 0.0639 0.0640 \n",
            "\n",
            "[TRAIN] Epoch[1](464/1214); Loss: 0.081904; Backpropagation: 0.6148 sec; Batch: 4.4895 sec\n",
            "0.1649 0.1145 0.0919 0.0832 0.0791 0.0751 0.0731 0.0718 0.0708 0.0705 0.0699 0.0695 0.0693 0.0691 0.0688 0.0688 \n",
            "\n",
            "[TRAIN] Epoch[1](465/1214); Loss: 0.084274; Backpropagation: 0.6165 sec; Batch: 4.4953 sec\n",
            "0.1509 0.1116 0.0929 0.0870 0.0819 0.0787 0.0769 0.0763 0.0752 0.0747 0.0744 0.0740 0.0738 0.0736 0.0735 0.0731 \n",
            "\n",
            "[TRAIN] Epoch[1](466/1214); Loss: 0.083918; Backpropagation: 0.6189 sec; Batch: 4.4952 sec\n",
            "0.1575 0.1099 0.0923 0.0841 0.0806 0.0781 0.0763 0.0752 0.0745 0.0740 0.0736 0.0734 0.0734 0.0733 0.0733 0.0733 \n",
            "\n",
            "[TRAIN] Epoch[1](467/1214); Loss: 0.087327; Backpropagation: 0.6132 sec; Batch: 4.4853 sec\n",
            "0.1429 0.1121 0.1000 0.0910 0.0849 0.0822 0.0809 0.0802 0.0792 0.0783 0.0778 0.0776 0.0775 0.0776 0.0776 0.0775 \n",
            "\n",
            "[TRAIN] Epoch[1](468/1214); Loss: 0.090587; Backpropagation: 0.6160 sec; Batch: 4.4897 sec\n",
            "0.1411 0.1092 0.0985 0.0938 0.0893 0.0860 0.0850 0.0843 0.0836 0.0831 0.0829 0.0828 0.0826 0.0824 0.0824 0.0824 \n",
            "\n",
            "[TRAIN] Epoch[1](469/1214); Loss: 0.085608; Backpropagation: 0.6158 sec; Batch: 4.4960 sec\n",
            "0.1436 0.1088 0.0972 0.0882 0.0847 0.0810 0.0794 0.0779 0.0769 0.0764 0.0761 0.0761 0.0760 0.0758 0.0758 0.0757 \n",
            "\n",
            "[TRAIN] Epoch[1](470/1214); Loss: 0.078245; Backpropagation: 0.6080 sec; Batch: 4.4823 sec\n",
            "0.1524 0.1032 0.0910 0.0802 0.0744 0.0713 0.0700 0.0690 0.0684 0.0680 0.0679 0.0675 0.0674 0.0671 0.0671 0.0671 \n",
            "\n",
            "[TRAIN] Epoch[1](471/1214); Loss: 0.079985; Backpropagation: 0.6237 sec; Batch: 4.4997 sec\n",
            "0.1503 0.1116 0.0956 0.0822 0.0769 0.0731 0.0716 0.0703 0.0697 0.0690 0.0689 0.0682 0.0681 0.0680 0.0681 0.0681 \n",
            "\n",
            "[TRAIN] Epoch[1](472/1214); Loss: 0.069469; Backpropagation: 0.6083 sec; Batch: 4.4801 sec\n",
            "0.1399 0.0954 0.0800 0.0703 0.0667 0.0637 0.0618 0.0602 0.0600 0.0598 0.0592 0.0590 0.0589 0.0588 0.0588 0.0590 \n",
            "\n",
            "[TRAIN] Epoch[1](473/1214); Loss: 0.083241; Backpropagation: 0.6163 sec; Batch: 4.4990 sec\n",
            "0.1453 0.1065 0.0924 0.0843 0.0801 0.0776 0.0765 0.0758 0.0752 0.0749 0.0743 0.0741 0.0739 0.0738 0.0737 0.0736 \n",
            "\n",
            "[TRAIN] Epoch[1](474/1214); Loss: 0.082004; Backpropagation: 0.6145 sec; Batch: 4.4886 sec\n",
            "0.1462 0.1053 0.0908 0.0820 0.0784 0.0762 0.0749 0.0743 0.0739 0.0733 0.0731 0.0729 0.0728 0.0727 0.0726 0.0725 \n",
            "\n",
            "[TRAIN] Epoch[1](475/1214); Loss: 0.078228; Backpropagation: 0.6122 sec; Batch: 4.4888 sec\n",
            "0.1354 0.1049 0.0883 0.0808 0.0761 0.0731 0.0712 0.0707 0.0700 0.0694 0.0691 0.0687 0.0686 0.0686 0.0683 0.0683 \n",
            "\n",
            "[TRAIN] Epoch[1](476/1214); Loss: 0.077076; Backpropagation: 0.6150 sec; Batch: 4.4954 sec\n",
            "0.1517 0.1001 0.0858 0.0766 0.0729 0.0708 0.0696 0.0686 0.0679 0.0677 0.0674 0.0672 0.0668 0.0668 0.0667 0.0667 \n",
            "\n",
            "[TRAIN] Epoch[1](477/1214); Loss: 0.080644; Backpropagation: 0.6138 sec; Batch: 4.4907 sec\n",
            "0.1371 0.1009 0.0881 0.0815 0.0775 0.0758 0.0747 0.0737 0.0734 0.0731 0.0729 0.0725 0.0724 0.0722 0.0723 0.0723 \n",
            "\n",
            "[TRAIN] Epoch[1](478/1214); Loss: 0.083123; Backpropagation: 0.6197 sec; Batch: 4.4976 sec\n",
            "0.1366 0.1048 0.0919 0.0843 0.0805 0.0787 0.0774 0.0766 0.0758 0.0756 0.0750 0.0748 0.0746 0.0745 0.0745 0.0745 \n",
            "\n",
            "[TRAIN] Epoch[1](479/1214); Loss: 0.069092; Backpropagation: 0.6107 sec; Batch: 4.4848 sec\n",
            "0.1332 0.0969 0.0805 0.0686 0.0645 0.0624 0.0612 0.0606 0.0603 0.0599 0.0597 0.0595 0.0595 0.0595 0.0596 0.0594 \n",
            "\n",
            "[TRAIN] Epoch[1](480/1214); Loss: 0.071589; Backpropagation: 0.6104 sec; Batch: 4.4798 sec\n",
            "0.1266 0.0945 0.0777 0.0725 0.0679 0.0667 0.0657 0.0650 0.0645 0.0640 0.0638 0.0633 0.0634 0.0632 0.0634 0.0632 \n",
            "\n",
            "[TRAIN] Epoch[1](481/1214); Loss: 0.088892; Backpropagation: 0.6159 sec; Batch: 4.4903 sec\n",
            "0.1488 0.1113 0.0992 0.0909 0.0866 0.0843 0.0825 0.0813 0.0808 0.0802 0.0799 0.0796 0.0795 0.0792 0.0792 0.0790 \n",
            "\n",
            "[TRAIN] Epoch[1](482/1214); Loss: 0.096578; Backpropagation: 0.6114 sec; Batch: 4.4840 sec\n",
            "0.1677 0.1260 0.1080 0.0996 0.0949 0.0918 0.0894 0.0876 0.0865 0.0857 0.0854 0.0850 0.0847 0.0845 0.0843 0.0841 \n",
            "\n",
            "[TRAIN] Epoch[1](483/1214); Loss: 0.077033; Backpropagation: 0.6180 sec; Batch: 4.4929 sec\n",
            "0.1401 0.0966 0.0837 0.0775 0.0740 0.0721 0.0708 0.0699 0.0693 0.0689 0.0687 0.0684 0.0682 0.0682 0.0681 0.0681 \n",
            "\n",
            "[TRAIN] Epoch[1](484/1214); Loss: 0.087383; Backpropagation: 0.6125 sec; Batch: 4.4895 sec\n",
            "0.1517 0.1087 0.0941 0.0882 0.0845 0.0821 0.0811 0.0803 0.0796 0.0791 0.0787 0.0782 0.0781 0.0780 0.0779 0.0778 \n",
            "\n",
            "[TRAIN] Epoch[1](485/1214); Loss: 0.079028; Backpropagation: 0.6197 sec; Batch: 4.4951 sec\n",
            "0.1375 0.1005 0.0886 0.0803 0.0762 0.0742 0.0729 0.0719 0.0712 0.0707 0.0705 0.0703 0.0700 0.0699 0.0699 0.0697 \n",
            "\n",
            "[TRAIN] Epoch[1](486/1214); Loss: 0.074076; Backpropagation: 0.6138 sec; Batch: 4.4897 sec\n",
            "0.1379 0.0964 0.0795 0.0737 0.0708 0.0685 0.0674 0.0668 0.0662 0.0659 0.0656 0.0655 0.0652 0.0653 0.0652 0.0652 \n",
            "\n",
            "[TRAIN] Epoch[1](487/1214); Loss: 0.082285; Backpropagation: 0.6089 sec; Batch: 4.4894 sec\n",
            "0.1364 0.1044 0.0896 0.0830 0.0799 0.0777 0.0763 0.0754 0.0753 0.0746 0.0744 0.0740 0.0740 0.0739 0.0738 0.0737 \n",
            "\n",
            "[TRAIN] Epoch[1](488/1214); Loss: 0.075937; Backpropagation: 0.6168 sec; Batch: 4.4959 sec\n",
            "0.1496 0.0989 0.0813 0.0754 0.0716 0.0695 0.0684 0.0675 0.0673 0.0669 0.0667 0.0666 0.0665 0.0662 0.0664 0.0664 \n",
            "\n",
            "[TRAIN] Epoch[1](489/1214); Loss: 0.086475; Backpropagation: 0.6105 sec; Batch: 4.4860 sec\n",
            "0.1319 0.1042 0.0940 0.0887 0.0847 0.0830 0.0818 0.0812 0.0806 0.0799 0.0795 0.0790 0.0790 0.0788 0.0788 0.0784 \n",
            "\n",
            "[TRAIN] Epoch[1](490/1214); Loss: 0.076727; Backpropagation: 0.6204 sec; Batch: 4.5002 sec\n",
            "0.1538 0.1034 0.0822 0.0755 0.0717 0.0703 0.0688 0.0681 0.0676 0.0673 0.0667 0.0667 0.0666 0.0665 0.0663 0.0662 \n",
            "\n",
            "[TRAIN] Epoch[1](491/1214); Loss: 0.081995; Backpropagation: 0.6113 sec; Batch: 4.4889 sec\n",
            "0.1526 0.1080 0.0890 0.0820 0.0777 0.0762 0.0750 0.0740 0.0733 0.0728 0.0725 0.0722 0.0720 0.0717 0.0715 0.0714 \n",
            "\n",
            "[TRAIN] Epoch[1](492/1214); Loss: 0.075668; Backpropagation: 0.6121 sec; Batch: 4.4877 sec\n",
            "0.1417 0.0975 0.0806 0.0745 0.0720 0.0706 0.0693 0.0687 0.0681 0.0676 0.0672 0.0668 0.0667 0.0665 0.0665 0.0663 \n",
            "\n",
            "[TRAIN] Epoch[1](493/1214); Loss: 0.075586; Backpropagation: 0.6090 sec; Batch: 4.4885 sec\n",
            "0.1497 0.1021 0.0860 0.0765 0.0715 0.0686 0.0670 0.0665 0.0662 0.0658 0.0655 0.0651 0.0648 0.0648 0.0647 0.0646 \n",
            "\n",
            "[TRAIN] Epoch[1](494/1214); Loss: 0.075960; Backpropagation: 0.6097 sec; Batch: 4.4796 sec\n",
            "0.1405 0.1010 0.0850 0.0750 0.0722 0.0703 0.0693 0.0682 0.0675 0.0672 0.0669 0.0666 0.0665 0.0665 0.0664 0.0663 \n",
            "\n",
            "[TRAIN] Epoch[1](495/1214); Loss: 0.078137; Backpropagation: 0.6239 sec; Batch: 4.4995 sec\n",
            "0.1404 0.0968 0.0833 0.0779 0.0751 0.0737 0.0722 0.0716 0.0708 0.0704 0.0701 0.0700 0.0697 0.0695 0.0694 0.0693 \n",
            "\n",
            "[TRAIN] Epoch[1](496/1214); Loss: 0.071658; Backpropagation: 0.6134 sec; Batch: 4.4864 sec\n",
            "0.1416 0.0953 0.0789 0.0731 0.0681 0.0656 0.0644 0.0634 0.0629 0.0625 0.0622 0.0620 0.0617 0.0617 0.0616 0.0616 \n",
            "\n",
            "[TRAIN] Epoch[1](497/1214); Loss: 0.082278; Backpropagation: 0.6188 sec; Batch: 4.4942 sec\n",
            "0.1358 0.1049 0.0908 0.0829 0.0789 0.0772 0.0763 0.0756 0.0751 0.0747 0.0743 0.0741 0.0741 0.0740 0.0740 0.0738 \n",
            "\n",
            "[TRAIN] Epoch[1](498/1214); Loss: 0.075169; Backpropagation: 0.6139 sec; Batch: 4.4892 sec\n",
            "0.1351 0.0998 0.0830 0.0755 0.0717 0.0697 0.0685 0.0679 0.0674 0.0670 0.0666 0.0664 0.0661 0.0661 0.0659 0.0660 \n",
            "\n",
            "[TRAIN] Epoch[1](499/1214); Loss: 0.081197; Backpropagation: 0.6099 sec; Batch: 4.4863 sec\n",
            "0.1461 0.1095 0.0878 0.0816 0.0783 0.0759 0.0744 0.0735 0.0730 0.0723 0.0718 0.0715 0.0711 0.0709 0.0708 0.0707 \n",
            "\n",
            "[TRAIN] Epoch[1](500/1214); Loss: 0.072530; Backpropagation: 0.6228 sec; Batch: 4.5042 sec\n",
            "0.1393 0.0966 0.0814 0.0732 0.0694 0.0670 0.0656 0.0647 0.0642 0.0636 0.0632 0.0629 0.0626 0.0624 0.0623 0.0623 \n",
            "\n",
            "[TRAIN] Epoch[1](501/1214); Loss: 0.081638; Backpropagation: 0.6140 sec; Batch: 4.4860 sec\n",
            "0.1389 0.1067 0.0926 0.0830 0.0784 0.0768 0.0753 0.0743 0.0738 0.0733 0.0728 0.0725 0.0722 0.0719 0.0718 0.0717 \n",
            "\n",
            "[TRAIN] Epoch[1](502/1214); Loss: 0.076491; Backpropagation: 0.6214 sec; Batch: 4.4899 sec\n",
            "0.1260 0.1028 0.0882 0.0781 0.0745 0.0721 0.0707 0.0699 0.0691 0.0686 0.0681 0.0677 0.0673 0.0671 0.0669 0.0667 \n",
            "\n",
            "[TRAIN] Epoch[1](503/1214); Loss: 0.077155; Backpropagation: 0.6197 sec; Batch: 4.4861 sec\n",
            "0.1426 0.1055 0.0864 0.0785 0.0729 0.0706 0.0697 0.0688 0.0684 0.0680 0.0676 0.0672 0.0672 0.0671 0.0670 0.0670 \n",
            "\n",
            "[TRAIN] Epoch[1](504/1214); Loss: 0.078495; Backpropagation: 0.6154 sec; Batch: 4.4882 sec\n",
            "0.1511 0.1051 0.0872 0.0783 0.0739 0.0718 0.0706 0.0699 0.0694 0.0690 0.0687 0.0686 0.0681 0.0682 0.0680 0.0682 \n",
            "\n",
            "[TRAIN] Epoch[1](505/1214); Loss: 0.070550; Backpropagation: 0.6142 sec; Batch: 4.4859 sec\n",
            "0.1447 0.0933 0.0774 0.0696 0.0660 0.0638 0.0630 0.0620 0.0617 0.0614 0.0614 0.0610 0.0611 0.0608 0.0609 0.0607 \n",
            "\n",
            "[TRAIN] Epoch[1](506/1214); Loss: 0.071557; Backpropagation: 0.6116 sec; Batch: 4.4880 sec\n",
            "0.1489 0.0955 0.0777 0.0702 0.0661 0.0650 0.0640 0.0631 0.0626 0.0624 0.0621 0.0618 0.0617 0.0614 0.0612 0.0612 \n",
            "\n",
            "[TRAIN] Epoch[1](507/1214); Loss: 0.082946; Backpropagation: 0.6147 sec; Batch: 4.4882 sec\n",
            "0.1520 0.1153 0.0926 0.0837 0.0791 0.0769 0.0755 0.0745 0.0736 0.0731 0.0724 0.0722 0.0719 0.0717 0.0714 0.0713 \n",
            "\n",
            "[TRAIN] Epoch[1](508/1214); Loss: 0.090134; Backpropagation: 0.6268 sec; Batch: 4.5101 sec\n",
            "0.1629 0.1136 0.0983 0.0900 0.0858 0.0842 0.0829 0.0820 0.0814 0.0809 0.0806 0.0802 0.0801 0.0799 0.0797 0.0796 \n",
            "\n",
            "[TRAIN] Epoch[1](509/1214); Loss: 0.078049; Backpropagation: 0.6147 sec; Batch: 4.4985 sec\n",
            "0.1589 0.1059 0.0846 0.0787 0.0743 0.0718 0.0700 0.0689 0.0681 0.0677 0.0673 0.0669 0.0667 0.0665 0.0664 0.0663 \n",
            "\n",
            "[TRAIN] Epoch[1](510/1214); Loss: 0.079035; Backpropagation: 0.6176 sec; Batch: 4.4991 sec\n",
            "0.1487 0.1066 0.0879 0.0805 0.0756 0.0734 0.0719 0.0709 0.0700 0.0694 0.0689 0.0687 0.0683 0.0681 0.0679 0.0678 \n",
            "\n",
            "[TRAIN] Epoch[1](511/1214); Loss: 0.076039; Backpropagation: 0.6205 sec; Batch: 4.4967 sec\n",
            "0.1410 0.0985 0.0828 0.0771 0.0730 0.0711 0.0702 0.0691 0.0685 0.0676 0.0673 0.0666 0.0664 0.0660 0.0658 0.0655 \n",
            "\n",
            "[TRAIN] Epoch[1](512/1214); Loss: 0.080489; Backpropagation: 0.6155 sec; Batch: 4.4891 sec\n",
            "0.1385 0.1005 0.0869 0.0807 0.0771 0.0754 0.0746 0.0739 0.0734 0.0729 0.0726 0.0726 0.0723 0.0723 0.0720 0.0721 \n",
            "\n",
            "[TRAIN] Epoch[1](513/1214); Loss: 0.076713; Backpropagation: 0.6157 sec; Batch: 4.4861 sec\n",
            "0.1359 0.0996 0.0850 0.0769 0.0735 0.0718 0.0704 0.0699 0.0692 0.0688 0.0684 0.0681 0.0678 0.0676 0.0674 0.0673 \n",
            "\n",
            "[TRAIN] Epoch[1](514/1214); Loss: 0.087771; Backpropagation: 0.6148 sec; Batch: 4.4892 sec\n",
            "0.1566 0.1129 0.0937 0.0881 0.0847 0.0820 0.0809 0.0799 0.0792 0.0787 0.0785 0.0782 0.0779 0.0779 0.0776 0.0775 \n",
            "\n",
            "[TRAIN] Epoch[1](515/1214); Loss: 0.081334; Backpropagation: 0.6155 sec; Batch: 4.4923 sec\n",
            "0.1564 0.1157 0.0949 0.0859 0.0782 0.0750 0.0723 0.0712 0.0703 0.0697 0.0692 0.0689 0.0686 0.0685 0.0683 0.0682 \n",
            "\n",
            "[TRAIN] Epoch[1](516/1214); Loss: 0.075890; Backpropagation: 0.6138 sec; Batch: 4.4888 sec\n",
            "0.1366 0.0952 0.0825 0.0773 0.0729 0.0711 0.0701 0.0692 0.0686 0.0682 0.0676 0.0674 0.0671 0.0669 0.0667 0.0667 \n",
            "\n",
            "[TRAIN] Epoch[1](517/1214); Loss: 0.068698; Backpropagation: 0.6186 sec; Batch: 4.5009 sec\n",
            "0.1377 0.0924 0.0773 0.0693 0.0652 0.0633 0.0617 0.0607 0.0600 0.0594 0.0591 0.0589 0.0587 0.0586 0.0584 0.0584 \n",
            "\n",
            "[TRAIN] Epoch[1](518/1214); Loss: 0.077723; Backpropagation: 0.6047 sec; Batch: 4.4718 sec\n",
            "0.1463 0.1003 0.0836 0.0771 0.0737 0.0716 0.0707 0.0700 0.0694 0.0692 0.0689 0.0688 0.0686 0.0685 0.0683 0.0683 \n",
            "\n",
            "[TRAIN] Epoch[1](519/1214); Loss: 0.077595; Backpropagation: 0.6146 sec; Batch: 4.4897 sec\n",
            "0.1412 0.0999 0.0837 0.0783 0.0747 0.0723 0.0711 0.0701 0.0698 0.0692 0.0691 0.0686 0.0685 0.0684 0.0684 0.0682 \n",
            "\n",
            "[TRAIN] Epoch[1](520/1214); Loss: 0.081032; Backpropagation: 0.6172 sec; Batch: 4.4926 sec\n",
            "0.1528 0.1059 0.0908 0.0833 0.0781 0.0748 0.0730 0.0722 0.0715 0.0712 0.0709 0.0707 0.0706 0.0703 0.0703 0.0701 \n",
            "\n",
            "[TRAIN] Epoch[1](521/1214); Loss: 0.074335; Backpropagation: 0.6123 sec; Batch: 4.4914 sec\n",
            "0.1360 0.0968 0.0802 0.0750 0.0709 0.0692 0.0678 0.0670 0.0665 0.0664 0.0659 0.0659 0.0656 0.0655 0.0653 0.0653 \n",
            "\n",
            "[TRAIN] Epoch[1](522/1214); Loss: 0.075347; Backpropagation: 0.6231 sec; Batch: 4.4981 sec\n",
            "0.1389 0.0969 0.0812 0.0739 0.0715 0.0700 0.0687 0.0682 0.0679 0.0676 0.0672 0.0672 0.0668 0.0668 0.0666 0.0666 \n",
            "\n",
            "[TRAIN] Epoch[1](523/1214); Loss: 0.073924; Backpropagation: 0.6097 sec; Batch: 4.4840 sec\n",
            "0.1291 0.0936 0.0808 0.0736 0.0709 0.0695 0.0681 0.0676 0.0670 0.0668 0.0663 0.0662 0.0659 0.0659 0.0657 0.0658 \n",
            "\n",
            "[TRAIN] Epoch[1](524/1214); Loss: 0.084857; Backpropagation: 0.6185 sec; Batch: 4.4936 sec\n",
            "0.1476 0.1041 0.0909 0.0842 0.0815 0.0796 0.0787 0.0779 0.0775 0.0771 0.0768 0.0766 0.0764 0.0762 0.0763 0.0762 \n",
            "\n",
            "[TRAIN] Epoch[1](525/1214); Loss: 0.083937; Backpropagation: 0.6110 sec; Batch: 4.4879 sec\n",
            "0.1528 0.1061 0.0911 0.0827 0.0802 0.0780 0.0770 0.0760 0.0758 0.0752 0.0751 0.0747 0.0747 0.0745 0.0746 0.0744 \n",
            "\n",
            "[TRAIN] Epoch[1](526/1214); Loss: 0.073673; Backpropagation: 0.6110 sec; Batch: 4.4880 sec\n",
            "0.1300 0.0965 0.0829 0.0749 0.0706 0.0687 0.0671 0.0665 0.0659 0.0655 0.0653 0.0652 0.0650 0.0649 0.0649 0.0648 \n",
            "\n",
            "[TRAIN] Epoch[1](527/1214); Loss: 0.078192; Backpropagation: 0.6141 sec; Batch: 4.4884 sec\n",
            "0.1487 0.1059 0.0891 0.0785 0.0743 0.0722 0.0708 0.0698 0.0689 0.0684 0.0679 0.0677 0.0675 0.0673 0.0671 0.0671 \n",
            "\n",
            "[TRAIN] Epoch[1](528/1214); Loss: 0.083466; Backpropagation: 0.6090 sec; Batch: 4.4802 sec\n",
            "0.1378 0.1016 0.0902 0.0836 0.0808 0.0792 0.0783 0.0774 0.0767 0.0763 0.0760 0.0758 0.0756 0.0756 0.0754 0.0754 \n",
            "\n",
            "[TRAIN] Epoch[1](529/1214); Loss: 0.089999; Backpropagation: 0.6124 sec; Batch: 4.4863 sec\n",
            "0.1538 0.1159 0.0997 0.0906 0.0870 0.0844 0.0833 0.0823 0.0815 0.0810 0.0807 0.0803 0.0802 0.0799 0.0798 0.0797 \n",
            "\n",
            "[TRAIN] Epoch[1](530/1214); Loss: 0.081834; Backpropagation: 0.6142 sec; Batch: 4.4980 sec\n",
            "0.1332 0.1001 0.0888 0.0826 0.0796 0.0778 0.0767 0.0756 0.0753 0.0748 0.0746 0.0742 0.0741 0.0740 0.0740 0.0739 \n",
            "\n",
            "[TRAIN] Epoch[1](531/1214); Loss: 0.079458; Backpropagation: 0.6117 sec; Batch: 4.4847 sec\n",
            "0.1481 0.1056 0.0911 0.0803 0.0761 0.0736 0.0719 0.0714 0.0703 0.0700 0.0694 0.0691 0.0687 0.0686 0.0685 0.0685 \n",
            "\n",
            "[TRAIN] Epoch[1](532/1214); Loss: 0.073274; Backpropagation: 0.6114 sec; Batch: 4.4946 sec\n",
            "0.1237 0.0940 0.0821 0.0748 0.0715 0.0690 0.0678 0.0670 0.0665 0.0661 0.0656 0.0653 0.0651 0.0648 0.0646 0.0645 \n",
            "\n",
            "[TRAIN] Epoch[1](533/1214); Loss: 0.079301; Backpropagation: 0.6121 sec; Batch: 4.4874 sec\n",
            "0.1553 0.1056 0.0927 0.0803 0.0762 0.0730 0.0710 0.0703 0.0693 0.0691 0.0685 0.0682 0.0677 0.0675 0.0671 0.0671 \n",
            "\n",
            "[TRAIN] Epoch[1](534/1214); Loss: 0.073476; Backpropagation: 0.6106 sec; Batch: 4.4945 sec\n",
            "0.1402 0.0992 0.0826 0.0741 0.0693 0.0679 0.0663 0.0654 0.0647 0.0644 0.0639 0.0638 0.0635 0.0634 0.0632 0.0635 \n",
            "\n",
            "[TRAIN] Epoch[1](535/1214); Loss: 0.075679; Backpropagation: 0.6125 sec; Batch: 4.4873 sec\n",
            "0.1406 0.1075 0.0911 0.0776 0.0726 0.0698 0.0678 0.0670 0.0660 0.0657 0.0650 0.0648 0.0642 0.0640 0.0636 0.0636 \n",
            "\n",
            "[TRAIN] Epoch[1](536/1214); Loss: 0.088110; Backpropagation: 0.6207 sec; Batch: 4.4957 sec\n",
            "0.1490 0.1147 0.0983 0.0899 0.0848 0.0824 0.0814 0.0803 0.0798 0.0791 0.0788 0.0784 0.0783 0.0781 0.0783 0.0781 \n",
            "\n",
            "[TRAIN] Epoch[1](537/1214); Loss: 0.071852; Backpropagation: 0.6195 sec; Batch: 4.4998 sec\n",
            "0.1263 0.0908 0.0797 0.0735 0.0694 0.0674 0.0659 0.0653 0.0646 0.0641 0.0638 0.0637 0.0636 0.0637 0.0637 0.0639 \n",
            "\n",
            "[TRAIN] Epoch[1](538/1214); Loss: 0.072298; Backpropagation: 0.6149 sec; Batch: 4.4877 sec\n",
            "0.1514 0.0965 0.0787 0.0726 0.0673 0.0657 0.0640 0.0634 0.0627 0.0621 0.0620 0.0619 0.0618 0.0620 0.0623 0.0625 \n",
            "\n",
            "[TRAIN] Epoch[1](539/1214); Loss: 0.082395; Backpropagation: 0.6101 sec; Batch: 4.4862 sec\n",
            "0.1484 0.1069 0.0903 0.0833 0.0790 0.0774 0.0758 0.0747 0.0740 0.0733 0.0729 0.0726 0.0725 0.0723 0.0724 0.0724 \n",
            "\n",
            "[TRAIN] Epoch[1](540/1214); Loss: 0.080945; Backpropagation: 0.6091 sec; Batch: 4.4877 sec\n",
            "0.1529 0.1070 0.0872 0.0804 0.0771 0.0753 0.0733 0.0728 0.0720 0.0717 0.0712 0.0710 0.0709 0.0707 0.0708 0.0708 \n",
            "\n",
            "[TRAIN] Epoch[1](541/1214); Loss: 0.077103; Backpropagation: 0.6165 sec; Batch: 4.4957 sec\n",
            "0.1360 0.1018 0.0872 0.0792 0.0739 0.0721 0.0701 0.0694 0.0687 0.0683 0.0681 0.0678 0.0679 0.0676 0.0677 0.0677 \n",
            "\n",
            "[TRAIN] Epoch[1](542/1214); Loss: 0.080614; Backpropagation: 0.6173 sec; Batch: 4.4914 sec\n",
            "0.1410 0.1005 0.0870 0.0817 0.0786 0.0765 0.0751 0.0742 0.0734 0.0728 0.0723 0.0720 0.0716 0.0713 0.0711 0.0708 \n",
            "\n",
            "[TRAIN] Epoch[1](543/1214); Loss: 0.073748; Backpropagation: 0.6089 sec; Batch: 4.4857 sec\n",
            "0.1293 0.0931 0.0796 0.0748 0.0719 0.0696 0.0681 0.0674 0.0667 0.0662 0.0661 0.0656 0.0656 0.0654 0.0654 0.0652 \n",
            "\n",
            "[TRAIN] Epoch[1](544/1214); Loss: 0.085112; Backpropagation: 0.6093 sec; Batch: 4.4812 sec\n",
            "0.1446 0.1049 0.0903 0.0863 0.0821 0.0810 0.0795 0.0789 0.0782 0.0778 0.0771 0.0768 0.0764 0.0763 0.0758 0.0758 \n",
            "\n",
            "[TRAIN] Epoch[1](545/1214); Loss: 0.079156; Backpropagation: 0.6118 sec; Batch: 4.4901 sec\n",
            "0.1348 0.1017 0.0882 0.0805 0.0778 0.0748 0.0734 0.0724 0.0717 0.0713 0.0707 0.0703 0.0701 0.0697 0.0695 0.0695 \n",
            "\n",
            "[TRAIN] Epoch[1](546/1214); Loss: 0.081418; Backpropagation: 0.6127 sec; Batch: 4.4878 sec\n",
            "0.1314 0.1021 0.0880 0.0832 0.0800 0.0778 0.0765 0.0756 0.0750 0.0744 0.0739 0.0735 0.0731 0.0730 0.0727 0.0727 \n",
            "\n",
            "[TRAIN] Epoch[1](547/1214); Loss: 0.075798; Backpropagation: 0.6091 sec; Batch: 4.4812 sec\n",
            "0.1471 0.1041 0.0843 0.0768 0.0715 0.0695 0.0683 0.0674 0.0668 0.0664 0.0659 0.0655 0.0652 0.0649 0.0647 0.0644 \n",
            "\n",
            "[TRAIN] Epoch[1](548/1214); Loss: 0.073182; Backpropagation: 0.6287 sec; Batch: 4.5103 sec\n",
            "0.1255 0.0950 0.0793 0.0741 0.0708 0.0689 0.0676 0.0669 0.0663 0.0659 0.0655 0.0653 0.0651 0.0650 0.0648 0.0648 \n",
            "\n",
            "[TRAIN] Epoch[1](549/1214); Loss: 0.060630; Backpropagation: 0.6119 sec; Batch: 4.4841 sec\n",
            "0.1306 0.0802 0.0654 0.0608 0.0570 0.0552 0.0539 0.0529 0.0523 0.0518 0.0518 0.0517 0.0516 0.0516 0.0516 0.0517 \n",
            "\n",
            "[TRAIN] Epoch[1](550/1214); Loss: 0.066974; Backpropagation: 0.6253 sec; Batch: 4.4999 sec\n",
            "0.1234 0.0895 0.0754 0.0695 0.0642 0.0620 0.0608 0.0596 0.0592 0.0587 0.0586 0.0583 0.0583 0.0580 0.0581 0.0580 \n",
            "\n",
            "[TRAIN] Epoch[1](551/1214); Loss: 0.068721; Backpropagation: 0.6196 sec; Batch: 4.4956 sec\n",
            "0.1343 0.0938 0.0746 0.0673 0.0641 0.0625 0.0617 0.0607 0.0604 0.0601 0.0599 0.0600 0.0600 0.0601 0.0600 0.0600 \n",
            "\n",
            "[TRAIN] Epoch[1](552/1214); Loss: 0.069224; Backpropagation: 0.6126 sec; Batch: 4.4855 sec\n",
            "0.1259 0.0914 0.0770 0.0699 0.0662 0.0642 0.0629 0.0620 0.0616 0.0611 0.0610 0.0608 0.0608 0.0608 0.0610 0.0610 \n",
            "\n",
            "[TRAIN] Epoch[1](553/1214); Loss: 0.076449; Backpropagation: 0.6126 sec; Batch: 4.4897 sec\n",
            "0.1307 0.1013 0.0853 0.0773 0.0739 0.0715 0.0701 0.0695 0.0690 0.0688 0.0681 0.0679 0.0676 0.0675 0.0673 0.0673 \n",
            "\n",
            "[TRAIN] Epoch[1](554/1214); Loss: 0.082306; Backpropagation: 0.6152 sec; Batch: 4.4919 sec\n",
            "0.1375 0.1039 0.0909 0.0839 0.0810 0.0786 0.0768 0.0757 0.0748 0.0741 0.0738 0.0734 0.0732 0.0733 0.0731 0.0731 \n",
            "\n",
            "[TRAIN] Epoch[1](555/1214); Loss: 0.077180; Backpropagation: 0.6199 sec; Batch: 4.4941 sec\n",
            "0.1407 0.1055 0.0846 0.0783 0.0742 0.0726 0.0708 0.0696 0.0686 0.0682 0.0676 0.0672 0.0670 0.0668 0.0666 0.0665 \n",
            "\n",
            "[TRAIN] Epoch[1](556/1214); Loss: 0.090704; Backpropagation: 0.6109 sec; Batch: 4.4826 sec\n",
            "0.1487 0.1082 0.0977 0.0913 0.0888 0.0861 0.0853 0.0842 0.0836 0.0832 0.0829 0.0826 0.0824 0.0823 0.0820 0.0819 \n",
            "\n",
            "[TRAIN] Epoch[1](557/1214); Loss: 0.064827; Backpropagation: 0.6145 sec; Batch: 4.4951 sec\n",
            "0.1270 0.0883 0.0703 0.0651 0.0612 0.0594 0.0584 0.0576 0.0567 0.0565 0.0562 0.0563 0.0562 0.0561 0.0560 0.0559 \n",
            "\n",
            "[TRAIN] Epoch[1](558/1214); Loss: 0.071674; Backpropagation: 0.6137 sec; Batch: 4.4915 sec\n",
            "0.1467 0.0953 0.0802 0.0719 0.0681 0.0654 0.0641 0.0635 0.0625 0.0621 0.0616 0.0613 0.0611 0.0610 0.0610 0.0609 \n",
            "\n",
            "[TRAIN] Epoch[1](559/1214); Loss: 0.076807; Backpropagation: 0.6147 sec; Batch: 4.4869 sec\n",
            "0.1340 0.0982 0.0848 0.0788 0.0740 0.0719 0.0706 0.0699 0.0693 0.0689 0.0685 0.0682 0.0681 0.0680 0.0678 0.0677 \n",
            "\n",
            "[TRAIN] Epoch[1](560/1214); Loss: 0.071607; Backpropagation: 0.6105 sec; Batch: 4.4821 sec\n",
            "0.1263 0.0951 0.0792 0.0718 0.0697 0.0674 0.0657 0.0652 0.0640 0.0637 0.0633 0.0633 0.0629 0.0627 0.0626 0.0628 \n",
            "\n",
            "[TRAIN] Epoch[1](561/1214); Loss: 0.079458; Backpropagation: 0.6106 sec; Batch: 4.4877 sec\n",
            "0.1376 0.0996 0.0854 0.0798 0.0761 0.0745 0.0734 0.0729 0.0723 0.0718 0.0716 0.0714 0.0713 0.0712 0.0713 0.0711 \n",
            "\n",
            "[TRAIN] Epoch[1](562/1214); Loss: 0.075932; Backpropagation: 0.6155 sec; Batch: 4.4862 sec\n",
            "0.1468 0.0979 0.0823 0.0759 0.0717 0.0702 0.0689 0.0681 0.0675 0.0670 0.0668 0.0666 0.0665 0.0664 0.0662 0.0662 \n",
            "\n",
            "[TRAIN] Epoch[1](563/1214); Loss: 0.077007; Backpropagation: 0.6081 sec; Batch: 4.4903 sec\n",
            "0.1287 0.0939 0.0834 0.0772 0.0748 0.0727 0.0719 0.0709 0.0706 0.0700 0.0699 0.0696 0.0696 0.0695 0.0697 0.0697 \n",
            "\n",
            "[TRAIN] Epoch[1](564/1214); Loss: 0.079086; Backpropagation: 0.6119 sec; Batch: 4.4840 sec\n",
            "0.1362 0.0987 0.0855 0.0792 0.0768 0.0749 0.0739 0.0728 0.0722 0.0716 0.0711 0.0708 0.0706 0.0705 0.0703 0.0703 \n",
            "\n",
            "[TRAIN] Epoch[1](565/1214); Loss: 0.067056; Backpropagation: 0.6143 sec; Batch: 4.4884 sec\n",
            "0.1321 0.0895 0.0733 0.0667 0.0637 0.0621 0.0609 0.0600 0.0592 0.0586 0.0582 0.0579 0.0578 0.0577 0.0577 0.0576 \n",
            "\n",
            "[TRAIN] Epoch[1](566/1214); Loss: 0.079104; Backpropagation: 0.6123 sec; Batch: 4.4850 sec\n",
            "0.1289 0.0965 0.0852 0.0802 0.0771 0.0755 0.0743 0.0734 0.0729 0.0723 0.0721 0.0717 0.0716 0.0714 0.0714 0.0712 \n",
            "\n",
            "[TRAIN] Epoch[1](567/1214); Loss: 0.071078; Backpropagation: 0.6161 sec; Batch: 4.4918 sec\n",
            "0.1414 0.0952 0.0766 0.0701 0.0673 0.0655 0.0641 0.0632 0.0628 0.0621 0.0619 0.0616 0.0615 0.0613 0.0614 0.0614 \n",
            "\n",
            "[TRAIN] Epoch[1](568/1214); Loss: 0.071111; Backpropagation: 0.6101 sec; Batch: 4.4807 sec\n",
            "0.1455 0.0938 0.0767 0.0713 0.0676 0.0654 0.0640 0.0629 0.0622 0.0618 0.0615 0.0612 0.0610 0.0609 0.0608 0.0610 \n",
            "\n",
            "[TRAIN] Epoch[1](569/1214); Loss: 0.071608; Backpropagation: 0.6141 sec; Batch: 4.4815 sec\n",
            "0.1215 0.0895 0.0764 0.0728 0.0696 0.0680 0.0666 0.0660 0.0653 0.0650 0.0645 0.0644 0.0642 0.0641 0.0639 0.0640 \n",
            "\n",
            "[TRAIN] Epoch[1](570/1214); Loss: 0.066429; Backpropagation: 0.6114 sec; Batch: 4.4858 sec\n",
            "0.1430 0.0904 0.0710 0.0650 0.0617 0.0599 0.0588 0.0581 0.0576 0.0573 0.0571 0.0570 0.0568 0.0565 0.0564 0.0564 \n",
            "\n",
            "[TRAIN] Epoch[1](571/1214); Loss: 0.074882; Backpropagation: 0.6203 sec; Batch: 4.4996 sec\n",
            "0.1457 0.0982 0.0800 0.0749 0.0720 0.0698 0.0687 0.0672 0.0666 0.0659 0.0655 0.0651 0.0650 0.0646 0.0645 0.0643 \n",
            "\n",
            "[TRAIN] Epoch[1](572/1214); Loss: 0.068690; Backpropagation: 0.6157 sec; Batch: 4.4917 sec\n",
            "0.1246 0.0848 0.0737 0.0696 0.0669 0.0648 0.0636 0.0630 0.0624 0.0619 0.0613 0.0611 0.0606 0.0604 0.0602 0.0602 \n",
            "\n",
            "[TRAIN] Epoch[1](573/1214); Loss: 0.075602; Backpropagation: 0.6158 sec; Batch: 4.4907 sec\n",
            "0.1306 0.0969 0.0822 0.0759 0.0735 0.0721 0.0707 0.0696 0.0690 0.0683 0.0677 0.0673 0.0670 0.0666 0.0663 0.0661 \n",
            "\n",
            "[TRAIN] Epoch[1](574/1214); Loss: 0.070462; Backpropagation: 0.6273 sec; Batch: 4.5077 sec\n",
            "0.1254 0.0876 0.0782 0.0707 0.0679 0.0661 0.0653 0.0644 0.0640 0.0633 0.0629 0.0626 0.0626 0.0622 0.0621 0.0621 \n",
            "\n",
            "[TRAIN] Epoch[1](575/1214); Loss: 0.078976; Backpropagation: 0.6227 sec; Batch: 4.5006 sec\n",
            "0.1307 0.0983 0.0862 0.0809 0.0766 0.0752 0.0738 0.0729 0.0722 0.0719 0.0713 0.0710 0.0707 0.0707 0.0706 0.0704 \n",
            "\n",
            "[TRAIN] Epoch[1](576/1214); Loss: 0.074013; Backpropagation: 0.6122 sec; Batch: 4.4883 sec\n",
            "0.1407 0.0973 0.0790 0.0731 0.0710 0.0689 0.0675 0.0668 0.0660 0.0656 0.0652 0.0650 0.0647 0.0646 0.0644 0.0642 \n",
            "\n",
            "[TRAIN] Epoch[1](577/1214); Loss: 0.069451; Backpropagation: 0.6091 sec; Batch: 4.4843 sec\n",
            "0.1342 0.0906 0.0757 0.0692 0.0658 0.0644 0.0629 0.0625 0.0616 0.0614 0.0609 0.0607 0.0603 0.0603 0.0602 0.0603 \n",
            "\n",
            "[TRAIN] Epoch[1](578/1214); Loss: 0.071343; Backpropagation: 0.6106 sec; Batch: 4.4863 sec\n",
            "0.1253 0.0902 0.0763 0.0710 0.0682 0.0672 0.0662 0.0656 0.0651 0.0647 0.0642 0.0640 0.0636 0.0635 0.0633 0.0632 \n",
            "\n",
            "[TRAIN] Epoch[1](579/1214); Loss: 0.079861; Backpropagation: 0.6151 sec; Batch: 4.4879 sec\n",
            "0.1501 0.1022 0.0869 0.0793 0.0770 0.0754 0.0738 0.0730 0.0719 0.0712 0.0705 0.0700 0.0696 0.0693 0.0690 0.0688 \n",
            "\n",
            "[TRAIN] Epoch[1](580/1214); Loss: 0.062824; Backpropagation: 0.6128 sec; Batch: 4.4818 sec\n",
            "0.1301 0.0882 0.0696 0.0634 0.0593 0.0579 0.0564 0.0555 0.0546 0.0539 0.0535 0.0530 0.0528 0.0524 0.0524 0.0522 \n",
            "\n",
            "[TRAIN] Epoch[1](581/1214); Loss: 0.069137; Backpropagation: 0.6101 sec; Batch: 4.4781 sec\n",
            "0.1329 0.0933 0.0775 0.0704 0.0656 0.0640 0.0626 0.0620 0.0610 0.0606 0.0602 0.0599 0.0595 0.0592 0.0588 0.0587 \n",
            "\n",
            "[TRAIN] Epoch[1](582/1214); Loss: 0.077487; Backpropagation: 0.6110 sec; Batch: 4.4777 sec\n",
            "0.1322 0.0971 0.0846 0.0786 0.0764 0.0741 0.0732 0.0718 0.0710 0.0699 0.0694 0.0689 0.0686 0.0682 0.0679 0.0678 \n",
            "\n",
            "[TRAIN] Epoch[1](583/1214); Loss: 0.064049; Backpropagation: 0.6135 sec; Batch: 4.4877 sec\n",
            "0.1252 0.0811 0.0695 0.0644 0.0613 0.0595 0.0586 0.0576 0.0570 0.0566 0.0563 0.0559 0.0556 0.0555 0.0554 0.0552 \n",
            "\n",
            "[TRAIN] Epoch[1](584/1214); Loss: 0.074185; Backpropagation: 0.6148 sec; Batch: 4.4913 sec\n",
            "0.1419 0.0951 0.0808 0.0736 0.0710 0.0697 0.0685 0.0675 0.0667 0.0658 0.0653 0.0648 0.0644 0.0642 0.0639 0.0637 \n",
            "\n",
            "[TRAIN] Epoch[1](585/1214); Loss: 0.069248; Backpropagation: 0.6083 sec; Batch: 4.4838 sec\n",
            "0.1387 0.0901 0.0768 0.0706 0.0670 0.0652 0.0631 0.0619 0.0609 0.0602 0.0596 0.0592 0.0589 0.0587 0.0585 0.0586 \n",
            "\n",
            "[TRAIN] Epoch[1](586/1214); Loss: 0.061455; Backpropagation: 0.6195 sec; Batch: 4.4995 sec\n",
            "0.1167 0.0780 0.0657 0.0615 0.0589 0.0575 0.0564 0.0558 0.0552 0.0547 0.0541 0.0539 0.0537 0.0536 0.0536 0.0538 \n",
            "\n",
            "[TRAIN] Epoch[1](587/1214); Loss: 0.071068; Backpropagation: 0.6094 sec; Batch: 4.4868 sec\n",
            "0.1292 0.0939 0.0809 0.0751 0.0704 0.0671 0.0654 0.0639 0.0631 0.0622 0.0618 0.0612 0.0611 0.0608 0.0606 0.0604 \n",
            "\n",
            "[TRAIN] Epoch[1](588/1214); Loss: 0.074970; Backpropagation: 0.6132 sec; Batch: 4.4862 sec\n",
            "0.1361 0.0992 0.0847 0.0783 0.0734 0.0701 0.0685 0.0675 0.0666 0.0660 0.0656 0.0652 0.0649 0.0647 0.0644 0.0644 \n",
            "\n",
            "[TRAIN] Epoch[1](589/1214); Loss: 0.060963; Backpropagation: 0.6196 sec; Batch: 4.4906 sec\n",
            "0.1244 0.0842 0.0702 0.0629 0.0585 0.0557 0.0539 0.0531 0.0525 0.0521 0.0519 0.0515 0.0513 0.0511 0.0512 0.0510 \n",
            "\n",
            "[TRAIN] Epoch[1](590/1214); Loss: 0.065051; Backpropagation: 0.6156 sec; Batch: 4.4889 sec\n",
            "0.1249 0.0842 0.0716 0.0663 0.0627 0.0610 0.0598 0.0587 0.0580 0.0573 0.0568 0.0563 0.0559 0.0558 0.0556 0.0559 \n",
            "\n",
            "[TRAIN] Epoch[1](591/1214); Loss: 0.065421; Backpropagation: 0.6141 sec; Batch: 4.4875 sec\n",
            "0.1359 0.0868 0.0725 0.0656 0.0633 0.0609 0.0594 0.0583 0.0574 0.0565 0.0559 0.0553 0.0551 0.0547 0.0546 0.0545 \n",
            "\n",
            "[TRAIN] Epoch[1](592/1214); Loss: 0.068526; Backpropagation: 0.6117 sec; Batch: 4.4847 sec\n",
            "0.1302 0.0872 0.0759 0.0693 0.0661 0.0639 0.0629 0.0616 0.0610 0.0602 0.0602 0.0597 0.0599 0.0594 0.0595 0.0595 \n",
            "\n",
            "[TRAIN] Epoch[1](593/1214); Loss: 0.060687; Backpropagation: 0.6177 sec; Batch: 4.4954 sec\n",
            "0.1257 0.0855 0.0696 0.0626 0.0584 0.0568 0.0546 0.0531 0.0521 0.0516 0.0508 0.0504 0.0501 0.0497 0.0499 0.0500 \n",
            "\n",
            "[TRAIN] Epoch[1](594/1214); Loss: 0.060145; Backpropagation: 0.6156 sec; Batch: 4.4880 sec\n",
            "0.1301 0.0802 0.0652 0.0593 0.0563 0.0546 0.0535 0.0525 0.0523 0.0515 0.0513 0.0510 0.0511 0.0510 0.0511 0.0513 \n",
            "\n",
            "[TRAIN] Epoch[1](595/1214); Loss: 0.083572; Backpropagation: 0.6111 sec; Batch: 4.4909 sec\n",
            "0.1424 0.1043 0.0919 0.0860 0.0829 0.0807 0.0787 0.0775 0.0763 0.0753 0.0747 0.0739 0.0736 0.0732 0.0731 0.0727 \n",
            "\n",
            "[TRAIN] Epoch[1](596/1214); Loss: 0.085090; Backpropagation: 0.6116 sec; Batch: 4.4938 sec\n",
            "0.1386 0.1056 0.0928 0.0879 0.0838 0.0820 0.0801 0.0789 0.0782 0.0774 0.0768 0.0764 0.0761 0.0757 0.0756 0.0756 \n",
            "\n",
            "[TRAIN] Epoch[1](597/1214); Loss: 0.065218; Backpropagation: 0.6127 sec; Batch: 4.4883 sec\n",
            "0.1274 0.0817 0.0715 0.0651 0.0628 0.0615 0.0603 0.0590 0.0582 0.0573 0.0571 0.0564 0.0564 0.0563 0.0562 0.0563 \n",
            "\n",
            "[TRAIN] Epoch[1](598/1214); Loss: 0.063603; Backpropagation: 0.6178 sec; Batch: 4.4935 sec\n",
            "0.1220 0.0881 0.0721 0.0655 0.0623 0.0606 0.0591 0.0574 0.0563 0.0553 0.0542 0.0539 0.0530 0.0531 0.0525 0.0525 \n",
            "\n",
            "[TRAIN] Epoch[1](599/1214); Loss: 0.066793; Backpropagation: 0.6151 sec; Batch: 4.4883 sec\n",
            "0.1363 0.0914 0.0760 0.0670 0.0648 0.0620 0.0601 0.0590 0.0582 0.0573 0.0568 0.0565 0.0562 0.0558 0.0557 0.0555 \n",
            "\n",
            "[TRAIN] Epoch[1](600/1214); Loss: 0.070101; Backpropagation: 0.6142 sec; Batch: 4.4907 sec\n",
            "0.1318 0.0939 0.0779 0.0724 0.0690 0.0658 0.0647 0.0631 0.0623 0.0613 0.0608 0.0603 0.0600 0.0597 0.0594 0.0593 \n",
            "\n",
            "[TRAIN] Epoch[1](601/1214); Loss: 0.077944; Backpropagation: 0.6128 sec; Batch: 4.4868 sec\n",
            "0.1376 0.1000 0.0844 0.0796 0.0760 0.0732 0.0719 0.0709 0.0700 0.0696 0.0692 0.0689 0.0688 0.0688 0.0689 0.0689 \n",
            "\n",
            "[TRAIN] Epoch[1](602/1214); Loss: 0.073907; Backpropagation: 0.6116 sec; Batch: 4.4832 sec\n",
            "0.1385 0.0956 0.0811 0.0741 0.0707 0.0690 0.0677 0.0666 0.0659 0.0652 0.0649 0.0646 0.0646 0.0645 0.0647 0.0647 \n",
            "\n",
            "[TRAIN] Epoch[1](603/1214); Loss: 0.079123; Backpropagation: 0.6113 sec; Batch: 4.4881 sec\n",
            "0.1372 0.1003 0.0881 0.0822 0.0777 0.0752 0.0735 0.0724 0.0715 0.0706 0.0703 0.0697 0.0696 0.0693 0.0693 0.0690 \n",
            "\n",
            "[TRAIN] Epoch[1](604/1214); Loss: 0.083144; Backpropagation: 0.6097 sec; Batch: 4.4856 sec\n",
            "0.1495 0.1067 0.0922 0.0850 0.0807 0.0786 0.0768 0.0759 0.0746 0.0741 0.0732 0.0729 0.0726 0.0727 0.0724 0.0725 \n",
            "\n",
            "[TRAIN] Epoch[1](605/1214); Loss: 0.081555; Backpropagation: 0.6117 sec; Batch: 4.4905 sec\n",
            "0.1478 0.1105 0.0946 0.0855 0.0803 0.0770 0.0747 0.0730 0.0721 0.0710 0.0706 0.0699 0.0698 0.0694 0.0694 0.0693 \n",
            "\n",
            "[TRAIN] Epoch[1](606/1214); Loss: 0.083512; Backpropagation: 0.6110 sec; Batch: 4.4863 sec\n",
            "0.1488 0.1099 0.0941 0.0857 0.0818 0.0794 0.0771 0.0759 0.0746 0.0740 0.0734 0.0729 0.0725 0.0722 0.0720 0.0719 \n",
            "\n",
            "[TRAIN] Epoch[1](607/1214); Loss: 0.066653; Backpropagation: 0.6127 sec; Batch: 4.4870 sec\n",
            "0.1328 0.0895 0.0803 0.0699 0.0649 0.0617 0.0603 0.0588 0.0578 0.0571 0.0564 0.0558 0.0555 0.0552 0.0552 0.0551 \n",
            "\n",
            "[TRAIN] Epoch[1](608/1214); Loss: 0.072708; Backpropagation: 0.6148 sec; Batch: 4.4903 sec\n",
            "0.1355 0.0938 0.0806 0.0741 0.0709 0.0684 0.0666 0.0656 0.0645 0.0639 0.0633 0.0632 0.0631 0.0631 0.0631 0.0635 \n",
            "\n",
            "[TRAIN] Epoch[1](609/1214); Loss: 0.075109; Backpropagation: 0.6177 sec; Batch: 4.4908 sec\n",
            "0.1416 0.1015 0.0864 0.0765 0.0729 0.0703 0.0685 0.0675 0.0662 0.0658 0.0649 0.0644 0.0642 0.0637 0.0638 0.0636 \n",
            "\n",
            "[TRAIN] Epoch[1](610/1214); Loss: 0.067465; Backpropagation: 0.6203 sec; Batch: 4.4914 sec\n",
            "0.1221 0.0867 0.0732 0.0687 0.0648 0.0635 0.0618 0.0613 0.0605 0.0604 0.0596 0.0598 0.0591 0.0593 0.0593 0.0595 \n",
            "\n",
            "[TRAIN] Epoch[1](611/1214); Loss: 0.071410; Backpropagation: 0.6142 sec; Batch: 4.4888 sec\n",
            "0.1339 0.0882 0.0758 0.0709 0.0682 0.0665 0.0657 0.0649 0.0645 0.0641 0.0637 0.0633 0.0634 0.0630 0.0632 0.0633 \n",
            "\n",
            "[TRAIN] Epoch[1](612/1214); Loss: 0.064677; Backpropagation: 0.6160 sec; Batch: 4.4928 sec\n",
            "0.1214 0.0856 0.0694 0.0643 0.0619 0.0601 0.0590 0.0583 0.0576 0.0573 0.0569 0.0567 0.0566 0.0565 0.0565 0.0566 \n",
            "\n",
            "[TRAIN] Epoch[1](613/1214); Loss: 0.075445; Backpropagation: 0.6150 sec; Batch: 4.4892 sec\n",
            "0.1383 0.0991 0.0846 0.0778 0.0738 0.0718 0.0693 0.0680 0.0670 0.0665 0.0658 0.0655 0.0651 0.0649 0.0648 0.0647 \n",
            "\n",
            "[TRAIN] Epoch[1](614/1214); Loss: 0.071230; Backpropagation: 0.6070 sec; Batch: 4.4819 sec\n",
            "0.1279 0.0897 0.0768 0.0721 0.0688 0.0668 0.0660 0.0652 0.0645 0.0636 0.0635 0.0631 0.0632 0.0629 0.0629 0.0627 \n",
            "\n",
            "[TRAIN] Epoch[1](615/1214); Loss: 0.070131; Backpropagation: 0.6078 sec; Batch: 4.4884 sec\n",
            "0.1391 0.0939 0.0781 0.0719 0.0682 0.0656 0.0641 0.0628 0.0617 0.0609 0.0603 0.0599 0.0594 0.0589 0.0588 0.0586 \n",
            "\n",
            "[TRAIN] Epoch[1](616/1214); Loss: 0.060421; Backpropagation: 0.6122 sec; Batch: 4.4864 sec\n",
            "0.1241 0.0768 0.0657 0.0602 0.0579 0.0560 0.0546 0.0539 0.0533 0.0526 0.0524 0.0521 0.0519 0.0518 0.0519 0.0517 \n",
            "\n",
            "[TRAIN] Epoch[1](617/1214); Loss: 0.083786; Backpropagation: 0.6185 sec; Batch: 4.4962 sec\n",
            "0.1396 0.1038 0.0921 0.0850 0.0823 0.0800 0.0786 0.0774 0.0766 0.0759 0.0753 0.0750 0.0749 0.0747 0.0746 0.0747 \n",
            "\n",
            "[TRAIN] Epoch[1](618/1214); Loss: 0.072177; Backpropagation: 0.6098 sec; Batch: 4.4885 sec\n",
            "0.1264 0.0932 0.0796 0.0742 0.0707 0.0686 0.0673 0.0659 0.0650 0.0643 0.0639 0.0635 0.0634 0.0631 0.0629 0.0628 \n",
            "\n",
            "[TRAIN] Epoch[1](619/1214); Loss: 0.071301; Backpropagation: 0.6167 sec; Batch: 4.4945 sec\n",
            "0.1406 0.0974 0.0811 0.0730 0.0690 0.0660 0.0640 0.0628 0.0616 0.0615 0.0607 0.0608 0.0606 0.0606 0.0605 0.0607 \n",
            "\n",
            "[TRAIN] Epoch[1](620/1214); Loss: 0.062932; Backpropagation: 0.6147 sec; Batch: 4.4843 sec\n",
            "0.1074 0.0764 0.0683 0.0637 0.0611 0.0599 0.0589 0.0581 0.0575 0.0570 0.0567 0.0564 0.0564 0.0564 0.0563 0.0563 \n",
            "\n",
            "[TRAIN] Epoch[1](621/1214); Loss: 0.075564; Backpropagation: 0.6130 sec; Batch: 4.4889 sec\n",
            "0.1373 0.0946 0.0820 0.0763 0.0735 0.0715 0.0706 0.0690 0.0682 0.0674 0.0671 0.0668 0.0664 0.0662 0.0661 0.0661 \n",
            "\n",
            "[TRAIN] Epoch[1](622/1214); Loss: 0.057783; Backpropagation: 0.6132 sec; Batch: 4.4921 sec\n",
            "0.1272 0.0787 0.0640 0.0575 0.0544 0.0530 0.0511 0.0505 0.0495 0.0492 0.0487 0.0486 0.0482 0.0481 0.0480 0.0479 \n",
            "\n",
            "[TRAIN] Epoch[1](623/1214); Loss: 0.063983; Backpropagation: 0.6079 sec; Batch: 4.4883 sec\n",
            "0.1311 0.0841 0.0712 0.0640 0.0603 0.0584 0.0570 0.0564 0.0558 0.0555 0.0552 0.0550 0.0550 0.0548 0.0549 0.0550 \n",
            "\n",
            "[TRAIN] Epoch[1](624/1214); Loss: 0.071483; Backpropagation: 0.6251 sec; Batch: 4.5051 sec\n",
            "0.1323 0.0935 0.0814 0.0742 0.0716 0.0676 0.0659 0.0643 0.0633 0.0625 0.0620 0.0614 0.0613 0.0610 0.0608 0.0606 \n",
            "\n",
            "[TRAIN] Epoch[1](625/1214); Loss: 0.072112; Backpropagation: 0.6135 sec; Batch: 4.4917 sec\n",
            "0.1324 0.0938 0.0803 0.0731 0.0693 0.0671 0.0657 0.0650 0.0643 0.0639 0.0635 0.0632 0.0631 0.0630 0.0631 0.0629 \n",
            "\n",
            "[TRAIN] Epoch[1](626/1214); Loss: 0.062943; Backpropagation: 0.6089 sec; Batch: 4.4899 sec\n",
            "0.1199 0.0857 0.0722 0.0656 0.0631 0.0592 0.0579 0.0563 0.0552 0.0544 0.0536 0.0535 0.0528 0.0528 0.0525 0.0524 \n",
            "\n",
            "[TRAIN] Epoch[1](627/1214); Loss: 0.068554; Backpropagation: 0.6101 sec; Batch: 4.4830 sec\n",
            "0.1093 0.0859 0.0767 0.0715 0.0681 0.0660 0.0645 0.0636 0.0627 0.0620 0.0616 0.0614 0.0612 0.0610 0.0608 0.0606 \n",
            "\n",
            "[TRAIN] Epoch[1](628/1214); Loss: 0.070932; Backpropagation: 0.6108 sec; Batch: 4.4843 sec\n",
            "0.1169 0.0912 0.0786 0.0737 0.0699 0.0678 0.0663 0.0657 0.0645 0.0641 0.0634 0.0632 0.0627 0.0626 0.0624 0.0622 \n",
            "\n",
            "[TRAIN] Epoch[1](629/1214); Loss: 0.068825; Backpropagation: 0.6198 sec; Batch: 4.4951 sec\n",
            "0.1516 0.0905 0.0758 0.0687 0.0658 0.0633 0.0614 0.0603 0.0593 0.0588 0.0584 0.0579 0.0575 0.0574 0.0572 0.0573 \n",
            "\n",
            "[TRAIN] Epoch[1](630/1214); Loss: 0.062853; Backpropagation: 0.6155 sec; Batch: 4.4930 sec\n",
            "0.1312 0.0875 0.0725 0.0645 0.0605 0.0582 0.0566 0.0551 0.0540 0.0535 0.0527 0.0523 0.0520 0.0518 0.0516 0.0516 \n",
            "\n",
            "[TRAIN] Epoch[1](631/1214); Loss: 0.071037; Backpropagation: 0.6124 sec; Batch: 4.4861 sec\n",
            "0.1338 0.0929 0.0785 0.0717 0.0685 0.0671 0.0654 0.0643 0.0633 0.0627 0.0620 0.0617 0.0613 0.0613 0.0611 0.0610 \n",
            "\n",
            "[TRAIN] Epoch[1](632/1214); Loss: 0.069451; Backpropagation: 0.6126 sec; Batch: 4.4881 sec\n",
            "0.1344 0.0925 0.0766 0.0711 0.0667 0.0649 0.0635 0.0627 0.0615 0.0607 0.0600 0.0597 0.0595 0.0592 0.0592 0.0592 \n",
            "\n",
            "[TRAIN] Epoch[1](633/1214); Loss: 0.071028; Backpropagation: 0.6140 sec; Batch: 4.4951 sec\n",
            "0.1430 0.0925 0.0796 0.0729 0.0703 0.0670 0.0653 0.0634 0.0621 0.0613 0.0609 0.0602 0.0599 0.0596 0.0593 0.0592 \n",
            "\n",
            "[TRAIN] Epoch[1](634/1214); Loss: 0.060459; Backpropagation: 0.6136 sec; Batch: 4.4832 sec\n",
            "0.1289 0.0858 0.0713 0.0644 0.0591 0.0560 0.0536 0.0529 0.0513 0.0506 0.0496 0.0494 0.0489 0.0488 0.0484 0.0484 \n",
            "\n",
            "[TRAIN] Epoch[1](635/1214); Loss: 0.079774; Backpropagation: 0.6071 sec; Batch: 4.4770 sec\n",
            "0.1436 0.1074 0.0928 0.0856 0.0817 0.0779 0.0754 0.0723 0.0708 0.0691 0.0682 0.0671 0.0667 0.0663 0.0659 0.0655 \n",
            "\n",
            "[TRAIN] Epoch[1](636/1214); Loss: 0.074389; Backpropagation: 0.6241 sec; Batch: 4.5033 sec\n",
            "0.1316 0.0971 0.0845 0.0787 0.0751 0.0721 0.0698 0.0684 0.0668 0.0658 0.0647 0.0643 0.0635 0.0630 0.0626 0.0623 \n",
            "\n",
            "[TRAIN] Epoch[1](637/1214); Loss: 0.063742; Backpropagation: 0.6138 sec; Batch: 4.4956 sec\n",
            "0.1296 0.0862 0.0723 0.0654 0.0618 0.0594 0.0577 0.0563 0.0558 0.0550 0.0543 0.0539 0.0534 0.0531 0.0530 0.0528 \n",
            "\n",
            "[TRAIN] Epoch[1](638/1214); Loss: 0.073686; Backpropagation: 0.6118 sec; Batch: 4.4923 sec\n",
            "0.1358 0.0971 0.0839 0.0762 0.0726 0.0692 0.0676 0.0661 0.0652 0.0646 0.0641 0.0637 0.0636 0.0633 0.0631 0.0628 \n",
            "\n",
            "[TRAIN] Epoch[1](639/1214); Loss: 0.065929; Backpropagation: 0.6164 sec; Batch: 4.4920 sec\n",
            "0.1255 0.0897 0.0755 0.0685 0.0649 0.0620 0.0602 0.0587 0.0574 0.0571 0.0564 0.0561 0.0558 0.0557 0.0556 0.0557 \n",
            "\n",
            "[TRAIN] Epoch[1](640/1214); Loss: 0.066669; Backpropagation: 0.6077 sec; Batch: 4.4827 sec\n",
            "0.1282 0.0910 0.0788 0.0706 0.0650 0.0621 0.0603 0.0587 0.0579 0.0571 0.0567 0.0564 0.0561 0.0560 0.0560 0.0558 \n",
            "\n",
            "[TRAIN] Epoch[1](641/1214); Loss: 0.078569; Backpropagation: 0.6134 sec; Batch: 4.4899 sec\n",
            "0.1327 0.0997 0.0861 0.0806 0.0765 0.0751 0.0738 0.0726 0.0716 0.0708 0.0702 0.0699 0.0696 0.0694 0.0692 0.0691 \n",
            "\n",
            "[TRAIN] Epoch[1](642/1214); Loss: 0.068718; Backpropagation: 0.6103 sec; Batch: 4.4820 sec\n",
            "0.1251 0.0903 0.0773 0.0706 0.0667 0.0649 0.0634 0.0623 0.0615 0.0607 0.0604 0.0600 0.0596 0.0591 0.0588 0.0587 \n",
            "\n",
            "[TRAIN] Epoch[1](643/1214); Loss: 0.075633; Backpropagation: 0.6166 sec; Batch: 4.4848 sec\n",
            "0.1311 0.1004 0.0851 0.0788 0.0745 0.0714 0.0697 0.0690 0.0678 0.0671 0.0666 0.0662 0.0658 0.0657 0.0655 0.0654 \n",
            "\n",
            "[TRAIN] Epoch[1](644/1214); Loss: 0.079996; Backpropagation: 0.6187 sec; Batch: 4.4982 sec\n",
            "0.1360 0.1060 0.0922 0.0838 0.0792 0.0763 0.0745 0.0731 0.0715 0.0709 0.0702 0.0698 0.0694 0.0692 0.0691 0.0690 \n",
            "\n",
            "[TRAIN] Epoch[1](645/1214); Loss: 0.070136; Backpropagation: 0.6133 sec; Batch: 4.4872 sec\n",
            "0.1210 0.0915 0.0794 0.0739 0.0696 0.0668 0.0652 0.0642 0.0631 0.0623 0.0616 0.0612 0.0609 0.0606 0.0605 0.0603 \n",
            "\n",
            "[TRAIN] Epoch[1](646/1214); Loss: 0.084705; Backpropagation: 0.6119 sec; Batch: 4.4882 sec\n",
            "0.1456 0.1073 0.0961 0.0881 0.0827 0.0802 0.0784 0.0775 0.0766 0.0759 0.0753 0.0748 0.0744 0.0742 0.0741 0.0742 \n",
            "\n",
            "[TRAIN] Epoch[1](647/1214); Loss: 0.078671; Backpropagation: 0.6085 sec; Batch: 4.4777 sec\n",
            "0.1466 0.1031 0.0896 0.0805 0.0766 0.0743 0.0724 0.0708 0.0701 0.0691 0.0684 0.0680 0.0675 0.0673 0.0672 0.0671 \n",
            "\n",
            "[TRAIN] Epoch[1](648/1214); Loss: 0.061845; Backpropagation: 0.6248 sec; Batch: 4.5052 sec\n",
            "0.1248 0.0897 0.0725 0.0650 0.0595 0.0574 0.0549 0.0539 0.0526 0.0520 0.0515 0.0513 0.0510 0.0510 0.0510 0.0513 \n",
            "\n",
            "[TRAIN] Epoch[1](649/1214); Loss: 0.069325; Backpropagation: 0.6108 sec; Batch: 4.4865 sec\n",
            "0.1430 0.0941 0.0813 0.0732 0.0671 0.0648 0.0627 0.0611 0.0596 0.0587 0.0580 0.0576 0.0573 0.0571 0.0569 0.0567 \n",
            "\n",
            "[TRAIN] Epoch[1](650/1214); Loss: 0.067968; Backpropagation: 0.6348 sec; Batch: 4.5138 sec\n",
            "0.1383 0.0943 0.0772 0.0692 0.0658 0.0629 0.0611 0.0593 0.0585 0.0580 0.0577 0.0573 0.0571 0.0569 0.0569 0.0569 \n",
            "\n",
            "[TRAIN] Epoch[1](651/1214); Loss: 0.076342; Backpropagation: 0.6152 sec; Batch: 4.4985 sec\n",
            "0.1537 0.1081 0.0895 0.0808 0.0745 0.0716 0.0692 0.0674 0.0662 0.0648 0.0638 0.0630 0.0626 0.0623 0.0620 0.0618 \n",
            "\n",
            "[TRAIN] Epoch[1](652/1214); Loss: 0.067343; Backpropagation: 0.6162 sec; Batch: 4.4923 sec\n",
            "0.1219 0.0886 0.0760 0.0697 0.0662 0.0639 0.0624 0.0610 0.0599 0.0592 0.0587 0.0581 0.0581 0.0578 0.0579 0.0580 \n",
            "\n",
            "[TRAIN] Epoch[1](653/1214); Loss: 0.067657; Backpropagation: 0.6198 sec; Batch: 4.4962 sec\n",
            "0.1448 0.0930 0.0797 0.0706 0.0666 0.0632 0.0608 0.0590 0.0577 0.0569 0.0561 0.0554 0.0550 0.0547 0.0546 0.0546 \n",
            "\n",
            "[TRAIN] Epoch[1](654/1214); Loss: 0.071204; Backpropagation: 0.6112 sec; Batch: 4.4848 sec\n",
            "0.1275 0.0899 0.0800 0.0737 0.0707 0.0676 0.0665 0.0646 0.0640 0.0632 0.0629 0.0623 0.0620 0.0617 0.0615 0.0611 \n",
            "\n",
            "[TRAIN] Epoch[1](655/1214); Loss: 0.069237; Backpropagation: 0.6152 sec; Batch: 4.4864 sec\n",
            "0.1266 0.0925 0.0761 0.0716 0.0671 0.0654 0.0633 0.0624 0.0614 0.0609 0.0606 0.0603 0.0600 0.0599 0.0597 0.0598 \n",
            "\n",
            "[TRAIN] Epoch[1](656/1214); Loss: 0.080965; Backpropagation: 0.6198 sec; Batch: 4.5002 sec\n",
            "0.1318 0.1042 0.0912 0.0853 0.0814 0.0786 0.0763 0.0748 0.0734 0.0727 0.0718 0.0715 0.0711 0.0707 0.0704 0.0703 \n",
            "\n",
            "[TRAIN] Epoch[1](657/1214); Loss: 0.059986; Backpropagation: 0.6179 sec; Batch: 4.4979 sec\n",
            "0.1271 0.0813 0.0677 0.0618 0.0575 0.0557 0.0537 0.0527 0.0515 0.0509 0.0505 0.0501 0.0500 0.0497 0.0498 0.0498 \n",
            "\n",
            "[TRAIN] Epoch[1](658/1214); Loss: 0.072899; Backpropagation: 0.6111 sec; Batch: 4.4879 sec\n",
            "0.1448 0.0981 0.0821 0.0736 0.0696 0.0673 0.0662 0.0651 0.0642 0.0635 0.0629 0.0623 0.0620 0.0617 0.0615 0.0614 \n",
            "\n",
            "[TRAIN] Epoch[1](659/1214); Loss: 0.072967; Backpropagation: 0.6085 sec; Batch: 4.4876 sec\n",
            "0.1199 0.0937 0.0822 0.0758 0.0725 0.0705 0.0689 0.0676 0.0662 0.0655 0.0647 0.0645 0.0641 0.0639 0.0639 0.0638 \n",
            "\n",
            "[TRAIN] Epoch[1](660/1214); Loss: 0.074108; Backpropagation: 0.6219 sec; Batch: 4.4913 sec\n",
            "0.1401 0.0950 0.0823 0.0760 0.0718 0.0700 0.0680 0.0668 0.0656 0.0650 0.0647 0.0644 0.0643 0.0641 0.0640 0.0638 \n",
            "\n",
            "[TRAIN] Epoch[1](661/1214); Loss: 0.062888; Backpropagation: 0.6148 sec; Batch: 4.4931 sec\n",
            "0.1333 0.0849 0.0713 0.0628 0.0597 0.0574 0.0560 0.0545 0.0540 0.0534 0.0533 0.0531 0.0532 0.0530 0.0532 0.0530 \n",
            "\n",
            "[TRAIN] Epoch[1](662/1214); Loss: 0.077418; Backpropagation: 0.6136 sec; Batch: 4.4983 sec\n",
            "0.1317 0.1015 0.0868 0.0808 0.0766 0.0740 0.0721 0.0709 0.0697 0.0688 0.0683 0.0680 0.0677 0.0675 0.0673 0.0672 \n",
            "\n",
            "[TRAIN] Epoch[1](663/1214); Loss: 0.075493; Backpropagation: 0.6179 sec; Batch: 4.4920 sec\n",
            "0.1408 0.1006 0.0850 0.0789 0.0733 0.0711 0.0687 0.0676 0.0666 0.0659 0.0654 0.0651 0.0649 0.0647 0.0647 0.0645 \n",
            "\n",
            "[TRAIN] Epoch[1](664/1214); Loss: 0.064265; Backpropagation: 0.6180 sec; Batch: 4.4968 sec\n",
            "0.1201 0.0822 0.0713 0.0662 0.0632 0.0608 0.0589 0.0581 0.0571 0.0565 0.0562 0.0559 0.0556 0.0554 0.0554 0.0554 \n",
            "\n",
            "[TRAIN] Epoch[1](665/1214); Loss: 0.075131; Backpropagation: 0.6222 sec; Batch: 4.4988 sec\n",
            "0.1274 0.0958 0.0841 0.0782 0.0744 0.0722 0.0698 0.0684 0.0674 0.0669 0.0664 0.0665 0.0662 0.0663 0.0661 0.0661 \n",
            "\n",
            "[TRAIN] Epoch[1](666/1214); Loss: 0.074965; Backpropagation: 0.6182 sec; Batch: 4.4912 sec\n",
            "0.1328 0.0967 0.0831 0.0768 0.0734 0.0717 0.0698 0.0687 0.0675 0.0667 0.0661 0.0657 0.0655 0.0653 0.0649 0.0647 \n",
            "\n",
            "[TRAIN] Epoch[1](667/1214); Loss: 0.060939; Backpropagation: 0.6262 sec; Batch: 4.5002 sec\n",
            "0.1319 0.0872 0.0727 0.0622 0.0586 0.0556 0.0536 0.0524 0.0515 0.0509 0.0503 0.0500 0.0497 0.0496 0.0494 0.0494 \n",
            "\n",
            "[TRAIN] Epoch[1](668/1214); Loss: 0.077350; Backpropagation: 0.6167 sec; Batch: 4.4901 sec\n",
            "0.1239 0.0947 0.0854 0.0799 0.0774 0.0749 0.0732 0.0719 0.0709 0.0703 0.0698 0.0695 0.0692 0.0689 0.0688 0.0688 \n",
            "\n",
            "[TRAIN] Epoch[1](669/1214); Loss: 0.067850; Backpropagation: 0.6166 sec; Batch: 4.4967 sec\n",
            "0.1312 0.0875 0.0758 0.0700 0.0660 0.0634 0.0619 0.0608 0.0601 0.0593 0.0589 0.0586 0.0582 0.0581 0.0579 0.0579 \n",
            "\n",
            "[TRAIN] Epoch[1](670/1214); Loss: 0.078913; Backpropagation: 0.6196 sec; Batch: 4.4950 sec\n",
            "0.1349 0.1070 0.0907 0.0831 0.0778 0.0748 0.0727 0.0715 0.0704 0.0696 0.0690 0.0686 0.0684 0.0683 0.0679 0.0678 \n",
            "\n",
            "[TRAIN] Epoch[1](671/1214); Loss: 0.073284; Backpropagation: 0.6146 sec; Batch: 4.4929 sec\n",
            "0.1461 0.1016 0.0851 0.0764 0.0729 0.0685 0.0665 0.0645 0.0631 0.0624 0.0616 0.0612 0.0609 0.0607 0.0606 0.0603 \n",
            "\n",
            "[TRAIN] Epoch[1](672/1214); Loss: 0.077019; Backpropagation: 0.6242 sec; Batch: 4.5010 sec\n",
            "0.1405 0.0987 0.0848 0.0778 0.0741 0.0721 0.0710 0.0701 0.0693 0.0686 0.0682 0.0678 0.0676 0.0674 0.0672 0.0671 \n",
            "\n",
            "[TRAIN] Epoch[1](673/1214); Loss: 0.068666; Backpropagation: 0.6213 sec; Batch: 4.5003 sec\n",
            "0.1270 0.0926 0.0788 0.0730 0.0688 0.0664 0.0637 0.0622 0.0604 0.0595 0.0586 0.0582 0.0577 0.0574 0.0573 0.0572 \n",
            "\n",
            "[TRAIN] Epoch[1](674/1214); Loss: 0.081476; Backpropagation: 0.6101 sec; Batch: 4.4842 sec\n",
            "0.1386 0.1016 0.0900 0.0832 0.0797 0.0779 0.0763 0.0752 0.0741 0.0734 0.0728 0.0726 0.0723 0.0722 0.0719 0.0719 \n",
            "\n",
            "[TRAIN] Epoch[1](675/1214); Loss: 0.060974; Backpropagation: 0.6147 sec; Batch: 4.4940 sec\n",
            "0.1120 0.0817 0.0696 0.0659 0.0608 0.0578 0.0558 0.0545 0.0534 0.0529 0.0524 0.0521 0.0518 0.0518 0.0516 0.0515 \n",
            "\n",
            "[TRAIN] Epoch[1](676/1214); Loss: 0.077477; Backpropagation: 0.6131 sec; Batch: 4.4927 sec\n",
            "0.1351 0.1031 0.0884 0.0807 0.0773 0.0742 0.0728 0.0704 0.0694 0.0684 0.0676 0.0670 0.0666 0.0663 0.0662 0.0660 \n",
            "\n",
            "[TRAIN] Epoch[1](677/1214); Loss: 0.072482; Backpropagation: 0.6116 sec; Batch: 4.4882 sec\n",
            "0.1215 0.0909 0.0809 0.0743 0.0721 0.0693 0.0675 0.0661 0.0653 0.0649 0.0648 0.0646 0.0644 0.0644 0.0643 0.0644 \n",
            "\n",
            "[TRAIN] Epoch[1](678/1214); Loss: 0.071941; Backpropagation: 0.6128 sec; Batch: 4.4878 sec\n",
            "0.1203 0.0935 0.0834 0.0766 0.0728 0.0690 0.0670 0.0651 0.0640 0.0634 0.0631 0.0628 0.0627 0.0625 0.0625 0.0625 \n",
            "\n",
            "[TRAIN] Epoch[1](679/1214); Loss: 0.071409; Backpropagation: 0.6132 sec; Batch: 4.4877 sec\n",
            "0.1332 0.0954 0.0807 0.0740 0.0706 0.0678 0.0657 0.0644 0.0630 0.0623 0.0616 0.0613 0.0609 0.0607 0.0605 0.0604 \n",
            "\n",
            "[TRAIN] Epoch[1](680/1214); Loss: 0.063386; Backpropagation: 0.6192 sec; Batch: 4.4977 sec\n",
            "0.1230 0.0813 0.0697 0.0635 0.0614 0.0596 0.0584 0.0572 0.0564 0.0556 0.0552 0.0549 0.0547 0.0546 0.0545 0.0545 \n",
            "\n",
            "[TRAIN] Epoch[1](681/1214); Loss: 0.063884; Backpropagation: 0.6129 sec; Batch: 4.4921 sec\n",
            "0.1155 0.0822 0.0730 0.0662 0.0634 0.0609 0.0587 0.0576 0.0569 0.0564 0.0559 0.0555 0.0552 0.0550 0.0549 0.0548 \n",
            "\n",
            "[TRAIN] Epoch[1](682/1214); Loss: 0.061421; Backpropagation: 0.6171 sec; Batch: 4.4867 sec\n",
            "0.1241 0.0823 0.0701 0.0633 0.0586 0.0565 0.0549 0.0542 0.0535 0.0529 0.0524 0.0522 0.0520 0.0520 0.0518 0.0519 \n",
            "\n",
            "[TRAIN] Epoch[1](683/1214); Loss: 0.066629; Backpropagation: 0.6106 sec; Batch: 4.4855 sec\n",
            "0.1215 0.0855 0.0743 0.0687 0.0652 0.0632 0.0613 0.0602 0.0593 0.0587 0.0584 0.0581 0.0580 0.0580 0.0579 0.0578 \n",
            "\n",
            "[TRAIN] Epoch[1](684/1214); Loss: 0.085121; Backpropagation: 0.6167 sec; Batch: 4.4915 sec\n",
            "0.1453 0.1042 0.0939 0.0875 0.0845 0.0814 0.0796 0.0781 0.0772 0.0764 0.0760 0.0757 0.0756 0.0754 0.0755 0.0754 \n",
            "\n",
            "[TRAIN] Epoch[1](685/1214); Loss: 0.066102; Backpropagation: 0.6140 sec; Batch: 4.4863 sec\n",
            "0.1312 0.0891 0.0753 0.0676 0.0641 0.0615 0.0596 0.0587 0.0576 0.0569 0.0564 0.0562 0.0560 0.0559 0.0557 0.0558 \n",
            "\n",
            "[TRAIN] Epoch[1](686/1214); Loss: 0.074570; Backpropagation: 0.6089 sec; Batch: 4.4808 sec\n",
            "0.1323 0.0959 0.0823 0.0762 0.0723 0.0698 0.0682 0.0675 0.0669 0.0664 0.0661 0.0660 0.0659 0.0657 0.0657 0.0657 \n",
            "\n",
            "[TRAIN] Epoch[1](687/1214); Loss: 0.073196; Backpropagation: 0.6077 sec; Batch: 4.4847 sec\n",
            "0.1398 0.0974 0.0828 0.0760 0.0723 0.0692 0.0672 0.0656 0.0643 0.0634 0.0628 0.0625 0.0622 0.0619 0.0618 0.0618 \n",
            "\n",
            "[TRAIN] Epoch[1](688/1214); Loss: 0.071108; Backpropagation: 0.6117 sec; Batch: 4.4872 sec\n",
            "0.1316 0.0924 0.0789 0.0728 0.0688 0.0668 0.0654 0.0643 0.0636 0.0630 0.0625 0.0621 0.0617 0.0615 0.0613 0.0611 \n",
            "\n",
            "[TRAIN] Epoch[1](689/1214); Loss: 0.060247; Backpropagation: 0.6146 sec; Batch: 4.4865 sec\n",
            "0.1120 0.0798 0.0684 0.0623 0.0600 0.0563 0.0548 0.0540 0.0531 0.0526 0.0522 0.0520 0.0517 0.0516 0.0515 0.0516 \n",
            "\n",
            "[TRAIN] Epoch[1](690/1214); Loss: 0.076845; Backpropagation: 0.6173 sec; Batch: 4.4956 sec\n",
            "0.1267 0.0982 0.0856 0.0805 0.0762 0.0735 0.0717 0.0704 0.0697 0.0690 0.0685 0.0681 0.0680 0.0679 0.0678 0.0677 \n",
            "\n",
            "[TRAIN] Epoch[1](691/1214); Loss: 0.066191; Backpropagation: 0.6133 sec; Batch: 4.4975 sec\n",
            "0.1284 0.0885 0.0759 0.0686 0.0648 0.0619 0.0597 0.0589 0.0576 0.0572 0.0567 0.0564 0.0561 0.0561 0.0561 0.0561 \n",
            "\n",
            "[TRAIN] Epoch[1](692/1214); Loss: 0.058925; Backpropagation: 0.6118 sec; Batch: 4.4875 sec\n",
            "0.1166 0.0817 0.0667 0.0606 0.0568 0.0546 0.0532 0.0519 0.0512 0.0507 0.0504 0.0501 0.0499 0.0496 0.0494 0.0494 \n",
            "\n",
            "[TRAIN] Epoch[1](693/1214); Loss: 0.068619; Backpropagation: 0.6155 sec; Batch: 4.4888 sec\n",
            "0.1183 0.0862 0.0741 0.0691 0.0668 0.0653 0.0639 0.0632 0.0623 0.0620 0.0615 0.0614 0.0611 0.0610 0.0608 0.0609 \n",
            "\n",
            "[TRAIN] Epoch[1](694/1214); Loss: 0.070353; Backpropagation: 0.6090 sec; Batch: 4.4810 sec\n",
            "0.1278 0.0939 0.0794 0.0735 0.0691 0.0669 0.0647 0.0632 0.0621 0.0615 0.0611 0.0609 0.0605 0.0604 0.0603 0.0603 \n",
            "\n",
            "[TRAIN] Epoch[1](695/1214); Loss: 0.069780; Backpropagation: 0.6100 sec; Batch: 4.4844 sec\n",
            "0.1209 0.0907 0.0769 0.0712 0.0678 0.0662 0.0647 0.0635 0.0628 0.0622 0.0618 0.0617 0.0616 0.0615 0.0616 0.0616 \n",
            "\n",
            "[TRAIN] Epoch[1](696/1214); Loss: 0.067553; Backpropagation: 0.6186 sec; Batch: 4.4954 sec\n",
            "0.1236 0.0872 0.0768 0.0694 0.0660 0.0638 0.0620 0.0609 0.0602 0.0594 0.0591 0.0585 0.0585 0.0584 0.0585 0.0585 \n",
            "\n",
            "[TRAIN] Epoch[1](697/1214); Loss: 0.072804; Backpropagation: 0.6084 sec; Batch: 4.4895 sec\n",
            "0.1296 0.0957 0.0802 0.0746 0.0707 0.0687 0.0671 0.0661 0.0652 0.0646 0.0641 0.0638 0.0637 0.0636 0.0636 0.0636 \n",
            "\n",
            "[TRAIN] Epoch[1](698/1214); Loss: 0.060058; Backpropagation: 0.6177 sec; Batch: 4.5010 sec\n",
            "0.1129 0.0786 0.0675 0.0620 0.0593 0.0568 0.0548 0.0539 0.0530 0.0524 0.0521 0.0517 0.0516 0.0514 0.0514 0.0515 \n",
            "\n",
            "[TRAIN] Epoch[1](699/1214); Loss: 0.061691; Backpropagation: 0.6246 sec; Batch: 4.4973 sec\n",
            "0.1146 0.0812 0.0675 0.0623 0.0597 0.0581 0.0566 0.0560 0.0550 0.0544 0.0540 0.0538 0.0536 0.0535 0.0534 0.0534 \n",
            "\n",
            "[TRAIN] Epoch[1](700/1214); Loss: 0.052166; Backpropagation: 0.6116 sec; Batch: 4.4772 sec\n",
            "0.1155 0.0728 0.0587 0.0538 0.0495 0.0479 0.0462 0.0451 0.0445 0.0437 0.0434 0.0431 0.0428 0.0425 0.0426 0.0426 \n",
            "\n",
            "[TRAIN] Epoch[1](701/1214); Loss: 0.069713; Backpropagation: 0.6121 sec; Batch: 4.4873 sec\n",
            "0.1248 0.0889 0.0785 0.0723 0.0688 0.0667 0.0648 0.0635 0.0626 0.0618 0.0613 0.0608 0.0605 0.0601 0.0601 0.0599 \n",
            "\n",
            "[TRAIN] Epoch[1](702/1214); Loss: 0.068184; Backpropagation: 0.6091 sec; Batch: 4.4824 sec\n",
            "0.1305 0.0979 0.0789 0.0698 0.0657 0.0634 0.0613 0.0599 0.0593 0.0588 0.0582 0.0578 0.0576 0.0575 0.0573 0.0572 \n",
            "\n",
            "[TRAIN] Epoch[1](703/1214); Loss: 0.065189; Backpropagation: 0.6198 sec; Batch: 4.4917 sec\n",
            "0.1231 0.0850 0.0723 0.0668 0.0634 0.0614 0.0597 0.0586 0.0578 0.0571 0.0568 0.0566 0.0563 0.0561 0.0560 0.0559 \n",
            "\n",
            "[TRAIN] Epoch[1](704/1214); Loss: 0.065394; Backpropagation: 0.6187 sec; Batch: 4.4922 sec\n",
            "0.1193 0.0841 0.0721 0.0662 0.0629 0.0613 0.0600 0.0592 0.0587 0.0582 0.0578 0.0577 0.0574 0.0573 0.0571 0.0571 \n",
            "\n",
            "[TRAIN] Epoch[1](705/1214); Loss: 0.057612; Backpropagation: 0.6177 sec; Batch: 4.4984 sec\n",
            "0.1164 0.0744 0.0641 0.0596 0.0560 0.0546 0.0523 0.0514 0.0503 0.0498 0.0493 0.0491 0.0488 0.0488 0.0485 0.0485 \n",
            "\n",
            "[TRAIN] Epoch[1](706/1214); Loss: 0.065727; Backpropagation: 0.6266 sec; Batch: 4.5064 sec\n",
            "0.1235 0.0861 0.0746 0.0685 0.0648 0.0618 0.0601 0.0588 0.0580 0.0574 0.0569 0.0566 0.0563 0.0561 0.0560 0.0560 \n",
            "\n",
            "[TRAIN] Epoch[1](707/1214); Loss: 0.064216; Backpropagation: 0.6111 sec; Batch: 4.4847 sec\n",
            "0.1187 0.0840 0.0730 0.0668 0.0630 0.0603 0.0584 0.0575 0.0568 0.0562 0.0558 0.0556 0.0554 0.0553 0.0553 0.0553 \n",
            "\n",
            "[TRAIN] Epoch[1](708/1214); Loss: 0.059889; Backpropagation: 0.6247 sec; Batch: 4.5018 sec\n",
            "0.1189 0.0780 0.0679 0.0613 0.0574 0.0553 0.0536 0.0528 0.0524 0.0522 0.0519 0.0518 0.0513 0.0513 0.0509 0.0510 \n",
            "\n",
            "[TRAIN] Epoch[1](709/1214); Loss: 0.064024; Backpropagation: 0.6167 sec; Batch: 4.4899 sec\n",
            "0.1305 0.0883 0.0769 0.0674 0.0628 0.0595 0.0577 0.0561 0.0550 0.0540 0.0534 0.0531 0.0527 0.0525 0.0523 0.0523 \n",
            "\n",
            "[TRAIN] Epoch[1](710/1214); Loss: 0.070176; Backpropagation: 0.6131 sec; Batch: 4.4894 sec\n",
            "0.1227 0.0909 0.0779 0.0720 0.0691 0.0668 0.0652 0.0640 0.0629 0.0626 0.0620 0.0618 0.0614 0.0613 0.0611 0.0612 \n",
            "\n",
            "[TRAIN] Epoch[1](711/1214); Loss: 0.066839; Backpropagation: 0.6138 sec; Batch: 4.4859 sec\n",
            "0.1279 0.0848 0.0750 0.0692 0.0656 0.0630 0.0609 0.0599 0.0590 0.0584 0.0580 0.0578 0.0576 0.0575 0.0574 0.0574 \n",
            "\n",
            "[TRAIN] Epoch[1](712/1214); Loss: 0.069423; Backpropagation: 0.6092 sec; Batch: 4.4783 sec\n",
            "0.1293 0.0899 0.0771 0.0714 0.0682 0.0657 0.0639 0.0628 0.0616 0.0610 0.0605 0.0601 0.0600 0.0598 0.0599 0.0597 \n",
            "\n",
            "[TRAIN] Epoch[1](713/1214); Loss: 0.052642; Backpropagation: 0.6220 sec; Batch: 4.4987 sec\n",
            "0.1153 0.0696 0.0589 0.0526 0.0490 0.0476 0.0468 0.0461 0.0456 0.0452 0.0448 0.0445 0.0444 0.0441 0.0440 0.0439 \n",
            "\n",
            "[TRAIN] Epoch[1](714/1214); Loss: 0.068296; Backpropagation: 0.6126 sec; Batch: 4.4902 sec\n",
            "0.1229 0.0861 0.0749 0.0684 0.0661 0.0646 0.0632 0.0625 0.0618 0.0611 0.0607 0.0605 0.0602 0.0601 0.0599 0.0598 \n",
            "\n",
            "[TRAIN] Epoch[1](715/1214); Loss: 0.068604; Backpropagation: 0.6151 sec; Batch: 4.4855 sec\n",
            "0.1279 0.0915 0.0775 0.0716 0.0666 0.0642 0.0621 0.0614 0.0604 0.0599 0.0595 0.0593 0.0591 0.0591 0.0589 0.0589 \n",
            "\n",
            "[TRAIN] Epoch[1](716/1214); Loss: 0.059511; Backpropagation: 0.6146 sec; Batch: 4.4892 sec\n",
            "0.1153 0.0824 0.0698 0.0619 0.0579 0.0554 0.0537 0.0525 0.0516 0.0509 0.0505 0.0503 0.0500 0.0500 0.0499 0.0500 \n",
            "\n",
            "[TRAIN] Epoch[1](717/1214); Loss: 0.059874; Backpropagation: 0.6154 sec; Batch: 4.4891 sec\n",
            "0.1101 0.0796 0.0670 0.0615 0.0582 0.0563 0.0548 0.0538 0.0532 0.0527 0.0522 0.0520 0.0518 0.0516 0.0515 0.0515 \n",
            "\n",
            "[TRAIN] Epoch[1](718/1214); Loss: 0.065617; Backpropagation: 0.6134 sec; Batch: 4.4928 sec\n",
            "0.1237 0.0890 0.0738 0.0676 0.0643 0.0620 0.0601 0.0587 0.0578 0.0570 0.0567 0.0561 0.0560 0.0559 0.0556 0.0556 \n",
            "\n",
            "[TRAIN] Epoch[1](719/1214); Loss: 0.056873; Backpropagation: 0.6126 sec; Batch: 4.4904 sec\n",
            "0.1263 0.0763 0.0640 0.0575 0.0538 0.0518 0.0507 0.0494 0.0487 0.0480 0.0477 0.0474 0.0473 0.0471 0.0470 0.0470 \n",
            "\n",
            "[TRAIN] Epoch[1](720/1214); Loss: 0.063186; Backpropagation: 0.6212 sec; Batch: 4.5063 sec\n",
            "0.1207 0.0815 0.0705 0.0659 0.0618 0.0597 0.0581 0.0567 0.0558 0.0551 0.0547 0.0544 0.0542 0.0541 0.0539 0.0539 \n",
            "\n",
            "[TRAIN] Epoch[1](721/1214); Loss: 0.063260; Backpropagation: 0.6123 sec; Batch: 4.4864 sec\n",
            "0.1340 0.0838 0.0699 0.0643 0.0606 0.0581 0.0564 0.0553 0.0547 0.0542 0.0538 0.0536 0.0535 0.0534 0.0533 0.0534 \n",
            "\n",
            "[TRAIN] Epoch[1](722/1214); Loss: 0.059758; Backpropagation: 0.6098 sec; Batch: 4.4806 sec\n",
            "0.1221 0.0840 0.0697 0.0632 0.0583 0.0559 0.0535 0.0522 0.0512 0.0506 0.0500 0.0495 0.0493 0.0490 0.0489 0.0488 \n",
            "\n",
            "[TRAIN] Epoch[1](723/1214); Loss: 0.055550; Backpropagation: 0.6117 sec; Batch: 4.4922 sec\n",
            "0.1120 0.0737 0.0611 0.0555 0.0529 0.0512 0.0499 0.0490 0.0486 0.0482 0.0480 0.0479 0.0477 0.0477 0.0477 0.0478 \n",
            "\n",
            "[TRAIN] Epoch[1](724/1214); Loss: 0.062971; Backpropagation: 0.6133 sec; Batch: 4.4844 sec\n",
            "0.1194 0.0815 0.0716 0.0655 0.0615 0.0594 0.0575 0.0563 0.0555 0.0549 0.0545 0.0543 0.0541 0.0540 0.0538 0.0538 \n",
            "\n",
            "[TRAIN] Epoch[1](725/1214); Loss: 0.061132; Backpropagation: 0.6172 sec; Batch: 4.4931 sec\n",
            "0.1194 0.0819 0.0690 0.0633 0.0590 0.0571 0.0556 0.0543 0.0534 0.0530 0.0524 0.0522 0.0520 0.0519 0.0518 0.0518 \n",
            "\n",
            "[TRAIN] Epoch[1](726/1214); Loss: 0.068348; Backpropagation: 0.6130 sec; Batch: 4.4881 sec\n",
            "0.1203 0.0872 0.0753 0.0702 0.0664 0.0645 0.0633 0.0623 0.0616 0.0609 0.0606 0.0604 0.0602 0.0601 0.0601 0.0601 \n",
            "\n",
            "[TRAIN] Epoch[1](727/1214); Loss: 0.065530; Backpropagation: 0.6146 sec; Batch: 4.4928 sec\n",
            "0.1280 0.0881 0.0748 0.0675 0.0628 0.0602 0.0588 0.0578 0.0572 0.0568 0.0565 0.0562 0.0561 0.0560 0.0559 0.0559 \n",
            "\n",
            "[TRAIN] Epoch[1](728/1214); Loss: 0.060661; Backpropagation: 0.6154 sec; Batch: 4.4924 sec\n",
            "0.1230 0.0842 0.0707 0.0644 0.0587 0.0556 0.0539 0.0527 0.0521 0.0515 0.0512 0.0507 0.0507 0.0505 0.0505 0.0503 \n",
            "\n",
            "[TRAIN] Epoch[1](729/1214); Loss: 0.064654; Backpropagation: 0.6131 sec; Batch: 4.4896 sec\n",
            "0.1213 0.0885 0.0730 0.0677 0.0626 0.0606 0.0584 0.0576 0.0567 0.0561 0.0557 0.0555 0.0553 0.0552 0.0552 0.0551 \n",
            "\n",
            "[TRAIN] Epoch[1](730/1214); Loss: 0.065199; Backpropagation: 0.6106 sec; Batch: 4.4813 sec\n",
            "0.1238 0.0929 0.0758 0.0684 0.0619 0.0600 0.0583 0.0576 0.0569 0.0562 0.0557 0.0555 0.0552 0.0551 0.0549 0.0549 \n",
            "\n",
            "[TRAIN] Epoch[1](731/1214); Loss: 0.062998; Backpropagation: 0.6089 sec; Batch: 4.4812 sec\n",
            "0.1157 0.0866 0.0743 0.0676 0.0622 0.0594 0.0572 0.0560 0.0552 0.0544 0.0540 0.0535 0.0532 0.0530 0.0529 0.0527 \n",
            "\n",
            "[TRAIN] Epoch[1](732/1214); Loss: 0.075525; Backpropagation: 0.6133 sec; Batch: 4.4871 sec\n",
            "0.1415 0.0961 0.0817 0.0776 0.0727 0.0712 0.0694 0.0683 0.0674 0.0672 0.0665 0.0663 0.0659 0.0657 0.0655 0.0655 \n",
            "\n",
            "[TRAIN] Epoch[1](733/1214); Loss: 0.066116; Backpropagation: 0.6131 sec; Batch: 4.4891 sec\n",
            "0.1178 0.0877 0.0759 0.0689 0.0648 0.0622 0.0605 0.0591 0.0587 0.0583 0.0579 0.0576 0.0574 0.0572 0.0571 0.0570 \n",
            "\n",
            "[TRAIN] Epoch[1](734/1214); Loss: 0.068423; Backpropagation: 0.6237 sec; Batch: 4.4961 sec\n",
            "0.1233 0.0876 0.0775 0.0718 0.0683 0.0654 0.0638 0.0625 0.0611 0.0605 0.0598 0.0593 0.0589 0.0586 0.0583 0.0581 \n",
            "\n",
            "[TRAIN] Epoch[1](735/1214); Loss: 0.065401; Backpropagation: 0.6118 sec; Batch: 4.4832 sec\n",
            "0.1154 0.0847 0.0733 0.0684 0.0644 0.0625 0.0607 0.0594 0.0585 0.0579 0.0575 0.0572 0.0569 0.0567 0.0565 0.0565 \n",
            "\n",
            "[TRAIN] Epoch[1](736/1214); Loss: 0.071516; Backpropagation: 0.6089 sec; Batch: 4.4833 sec\n",
            "0.1275 0.0948 0.0809 0.0727 0.0698 0.0674 0.0661 0.0647 0.0638 0.0631 0.0628 0.0625 0.0623 0.0621 0.0620 0.0619 \n",
            "\n",
            "[TRAIN] Epoch[1](737/1214); Loss: 0.077005; Backpropagation: 0.6093 sec; Batch: 4.4870 sec\n",
            "0.1329 0.1050 0.0895 0.0826 0.0766 0.0739 0.0716 0.0692 0.0681 0.0671 0.0665 0.0663 0.0659 0.0657 0.0656 0.0655 \n",
            "\n",
            "[TRAIN] Epoch[1](738/1214); Loss: 0.063524; Backpropagation: 0.6092 sec; Batch: 4.4826 sec\n",
            "0.1245 0.0870 0.0748 0.0682 0.0633 0.0602 0.0581 0.0564 0.0551 0.0544 0.0538 0.0530 0.0526 0.0522 0.0516 0.0512 \n",
            "\n",
            "[TRAIN] Epoch[1](739/1214); Loss: 0.072124; Backpropagation: 0.6236 sec; Batch: 4.4996 sec\n",
            "0.1243 0.0936 0.0825 0.0772 0.0728 0.0694 0.0674 0.0660 0.0647 0.0640 0.0630 0.0624 0.0620 0.0618 0.0615 0.0613 \n",
            "\n",
            "[TRAIN] Epoch[1](740/1214); Loss: 0.063609; Backpropagation: 0.6184 sec; Batch: 4.4877 sec\n",
            "0.1311 0.0888 0.0729 0.0641 0.0600 0.0582 0.0568 0.0557 0.0548 0.0543 0.0538 0.0536 0.0534 0.0534 0.0534 0.0534 \n",
            "\n",
            "[TRAIN] Epoch[1](741/1214); Loss: 0.074275; Backpropagation: 0.6171 sec; Batch: 4.4899 sec\n",
            "0.1356 0.0972 0.0864 0.0783 0.0739 0.0700 0.0677 0.0665 0.0654 0.0647 0.0642 0.0641 0.0638 0.0637 0.0634 0.0635 \n",
            "\n",
            "[TRAIN] Epoch[1](742/1214); Loss: 0.082725; Backpropagation: 0.6126 sec; Batch: 4.4869 sec\n",
            "0.1326 0.1065 0.0928 0.0877 0.0825 0.0792 0.0773 0.0760 0.0749 0.0742 0.0738 0.0736 0.0733 0.0732 0.0730 0.0730 \n",
            "\n",
            "[TRAIN] Epoch[1](743/1214); Loss: 0.068756; Backpropagation: 0.6068 sec; Batch: 4.4837 sec\n",
            "0.1311 0.0954 0.0802 0.0727 0.0697 0.0650 0.0623 0.0609 0.0599 0.0589 0.0581 0.0576 0.0573 0.0571 0.0570 0.0569 \n",
            "\n",
            "[TRAIN] Epoch[1](744/1214); Loss: 0.072319; Backpropagation: 0.6135 sec; Batch: 4.4878 sec\n",
            "0.1251 0.1002 0.0859 0.0760 0.0725 0.0704 0.0676 0.0656 0.0641 0.0634 0.0625 0.0615 0.0610 0.0608 0.0604 0.0603 \n",
            "\n",
            "[TRAIN] Epoch[1](745/1214); Loss: 0.062958; Backpropagation: 0.6131 sec; Batch: 4.4887 sec\n",
            "0.1258 0.0868 0.0754 0.0685 0.0629 0.0588 0.0573 0.0554 0.0538 0.0527 0.0522 0.0519 0.0516 0.0514 0.0514 0.0514 \n",
            "\n",
            "[TRAIN] Epoch[1](746/1214); Loss: 0.068275; Backpropagation: 0.6158 sec; Batch: 4.4894 sec\n",
            "0.1287 0.0940 0.0783 0.0718 0.0674 0.0653 0.0628 0.0616 0.0599 0.0589 0.0582 0.0575 0.0573 0.0570 0.0569 0.0568 \n",
            "\n",
            "[TRAIN] Epoch[1](747/1214); Loss: 0.061846; Backpropagation: 0.6117 sec; Batch: 4.4830 sec\n",
            "0.1164 0.0801 0.0691 0.0642 0.0609 0.0581 0.0563 0.0553 0.0547 0.0543 0.0539 0.0534 0.0533 0.0532 0.0532 0.0532 \n",
            "\n",
            "[TRAIN] Epoch[1](748/1214); Loss: 0.069022; Backpropagation: 0.6119 sec; Batch: 4.4856 sec\n",
            "0.1280 0.0993 0.0816 0.0734 0.0687 0.0648 0.0626 0.0617 0.0597 0.0591 0.0583 0.0583 0.0575 0.0574 0.0570 0.0569 \n",
            "\n",
            "[TRAIN] Epoch[1](749/1214); Loss: 0.062599; Backpropagation: 0.6178 sec; Batch: 4.4969 sec\n",
            "0.1326 0.0875 0.0708 0.0659 0.0610 0.0580 0.0558 0.0544 0.0535 0.0530 0.0524 0.0518 0.0514 0.0514 0.0511 0.0510 \n",
            "\n",
            "[TRAIN] Epoch[1](750/1214); Loss: 0.069976; Backpropagation: 0.6100 sec; Batch: 4.4834 sec\n",
            "0.1432 0.0992 0.0841 0.0747 0.0697 0.0651 0.0620 0.0601 0.0590 0.0587 0.0580 0.0577 0.0571 0.0571 0.0569 0.0572 \n",
            "\n",
            "[TRAIN] Epoch[1](751/1214); Loss: 0.070094; Backpropagation: 0.6273 sec; Batch: 4.5040 sec\n",
            "0.1455 0.1007 0.0845 0.0734 0.0679 0.0644 0.0625 0.0610 0.0598 0.0588 0.0579 0.0574 0.0572 0.0570 0.0568 0.0567 \n",
            "\n",
            "[TRAIN] Epoch[1](752/1214); Loss: 0.066551; Backpropagation: 0.6118 sec; Batch: 4.4899 sec\n",
            "0.1453 0.1027 0.0823 0.0731 0.0671 0.0618 0.0583 0.0559 0.0544 0.0530 0.0524 0.0521 0.0518 0.0517 0.0515 0.0514 \n",
            "\n",
            "[TRAIN] Epoch[1](753/1214); Loss: 0.065350; Backpropagation: 0.6180 sec; Batch: 4.4943 sec\n",
            "0.1284 0.0903 0.0742 0.0685 0.0642 0.0617 0.0590 0.0576 0.0565 0.0562 0.0556 0.0552 0.0548 0.0546 0.0544 0.0544 \n",
            "\n",
            "[TRAIN] Epoch[1](754/1214); Loss: 0.067935; Backpropagation: 0.6144 sec; Batch: 4.4879 sec\n",
            "0.1291 0.0939 0.0781 0.0699 0.0666 0.0636 0.0618 0.0603 0.0593 0.0586 0.0582 0.0579 0.0576 0.0575 0.0573 0.0573 \n",
            "\n",
            "[TRAIN] Epoch[1](755/1214); Loss: 0.066956; Backpropagation: 0.6163 sec; Batch: 4.4903 sec\n",
            "0.1327 0.0900 0.0762 0.0697 0.0653 0.0620 0.0605 0.0591 0.0581 0.0576 0.0571 0.0569 0.0566 0.0566 0.0565 0.0564 \n",
            "\n",
            "[TRAIN] Epoch[1](756/1214); Loss: 0.070450; Backpropagation: 0.6188 sec; Batch: 4.4976 sec\n",
            "0.1419 0.0947 0.0823 0.0729 0.0676 0.0651 0.0633 0.0619 0.0611 0.0604 0.0600 0.0594 0.0592 0.0591 0.0592 0.0590 \n",
            "\n",
            "[TRAIN] Epoch[1](757/1214); Loss: 0.072440; Backpropagation: 0.6087 sec; Batch: 4.4882 sec\n",
            "0.1423 0.0997 0.0847 0.0752 0.0704 0.0675 0.0657 0.0644 0.0630 0.0621 0.0615 0.0610 0.0608 0.0603 0.0603 0.0601 \n",
            "\n",
            "[TRAIN] Epoch[1](758/1214); Loss: 0.063427; Backpropagation: 0.6144 sec; Batch: 4.4914 sec\n",
            "0.1198 0.0867 0.0739 0.0663 0.0619 0.0595 0.0576 0.0564 0.0556 0.0550 0.0546 0.0540 0.0538 0.0534 0.0533 0.0532 \n",
            "\n",
            "[TRAIN] Epoch[1](759/1214); Loss: 0.071907; Backpropagation: 0.6101 sec; Batch: 4.4887 sec\n",
            "0.1360 0.0937 0.0827 0.0760 0.0706 0.0681 0.0661 0.0645 0.0631 0.0623 0.0619 0.0615 0.0612 0.0610 0.0609 0.0607 \n",
            "\n",
            "[TRAIN] Epoch[1](760/1214); Loss: 0.072072; Backpropagation: 0.6143 sec; Batch: 4.4919 sec\n",
            "0.1378 0.0999 0.0832 0.0751 0.0711 0.0679 0.0657 0.0639 0.0625 0.0620 0.0611 0.0611 0.0606 0.0606 0.0602 0.0603 \n",
            "\n",
            "[TRAIN] Epoch[1](761/1214); Loss: 0.072514; Backpropagation: 0.6106 sec; Batch: 4.4938 sec\n",
            "0.1239 0.0979 0.0821 0.0741 0.0718 0.0685 0.0674 0.0659 0.0651 0.0642 0.0639 0.0634 0.0633 0.0629 0.0630 0.0627 \n",
            "\n",
            "[TRAIN] Epoch[1](762/1214); Loss: 0.063003; Backpropagation: 0.6114 sec; Batch: 4.4872 sec\n",
            "0.1097 0.0842 0.0726 0.0671 0.0626 0.0598 0.0581 0.0567 0.0559 0.0553 0.0549 0.0548 0.0542 0.0542 0.0540 0.0539 \n",
            "\n",
            "[TRAIN] Epoch[1](763/1214); Loss: 0.067713; Backpropagation: 0.6278 sec; Batch: 4.5047 sec\n",
            "0.1229 0.0914 0.0767 0.0701 0.0664 0.0646 0.0622 0.0610 0.0596 0.0593 0.0587 0.0586 0.0582 0.0580 0.0578 0.0578 \n",
            "\n",
            "[TRAIN] Epoch[1](764/1214); Loss: 0.070582; Backpropagation: 0.6072 sec; Batch: 4.4810 sec\n",
            "0.1271 0.0980 0.0814 0.0746 0.0702 0.0669 0.0651 0.0634 0.0624 0.0611 0.0609 0.0600 0.0600 0.0594 0.0597 0.0592 \n",
            "\n",
            "[TRAIN] Epoch[1](765/1214); Loss: 0.071918; Backpropagation: 0.6138 sec; Batch: 4.4859 sec\n",
            "0.1386 0.1053 0.0882 0.0787 0.0718 0.0681 0.0655 0.0627 0.0612 0.0600 0.0595 0.0585 0.0585 0.0582 0.0581 0.0578 \n",
            "\n",
            "[TRAIN] Epoch[1](766/1214); Loss: 0.065319; Backpropagation: 0.6110 sec; Batch: 4.4780 sec\n",
            "0.1273 0.0919 0.0758 0.0680 0.0641 0.0614 0.0590 0.0573 0.0563 0.0558 0.0554 0.0552 0.0548 0.0546 0.0541 0.0541 \n",
            "\n",
            "[TRAIN] Epoch[1](767/1214); Loss: 0.076459; Backpropagation: 0.6140 sec; Batch: 4.4862 sec\n",
            "0.1278 0.0981 0.0883 0.0820 0.0763 0.0737 0.0712 0.0700 0.0687 0.0679 0.0672 0.0669 0.0665 0.0663 0.0661 0.0662 \n",
            "\n",
            "[TRAIN] Epoch[1](768/1214); Loss: 0.068954; Backpropagation: 0.6264 sec; Batch: 4.5001 sec\n",
            "0.1180 0.0911 0.0793 0.0714 0.0668 0.0654 0.0636 0.0629 0.0618 0.0611 0.0608 0.0606 0.0603 0.0601 0.0601 0.0600 \n",
            "\n",
            "[TRAIN] Epoch[1](769/1214); Loss: 0.074981; Backpropagation: 0.6148 sec; Batch: 4.4843 sec\n",
            "0.1389 0.1011 0.0861 0.0783 0.0735 0.0707 0.0683 0.0670 0.0660 0.0653 0.0649 0.0644 0.0642 0.0639 0.0637 0.0636 \n",
            "\n",
            "[TRAIN] Epoch[1](770/1214); Loss: 0.070495; Backpropagation: 0.6248 sec; Batch: 4.5000 sec\n",
            "0.1287 0.0969 0.0819 0.0741 0.0696 0.0665 0.0643 0.0630 0.0619 0.0612 0.0607 0.0603 0.0600 0.0597 0.0596 0.0595 \n",
            "\n",
            "[TRAIN] Epoch[1](771/1214); Loss: 0.071812; Backpropagation: 0.6120 sec; Batch: 4.4833 sec\n",
            "0.1273 0.0978 0.0833 0.0755 0.0712 0.0673 0.0655 0.0641 0.0635 0.0628 0.0624 0.0620 0.0619 0.0616 0.0615 0.0613 \n",
            "\n",
            "[TRAIN] Epoch[1](772/1214); Loss: 0.065960; Backpropagation: 0.6092 sec; Batch: 4.4885 sec\n",
            "0.1169 0.0891 0.0789 0.0707 0.0669 0.0638 0.0611 0.0593 0.0579 0.0571 0.0565 0.0559 0.0557 0.0554 0.0552 0.0550 \n",
            "\n",
            "[TRAIN] Epoch[1](773/1214); Loss: 0.058776; Backpropagation: 0.6171 sec; Batch: 4.4882 sec\n",
            "0.1131 0.0814 0.0694 0.0623 0.0577 0.0549 0.0533 0.0521 0.0508 0.0501 0.0497 0.0495 0.0492 0.0491 0.0489 0.0490 \n",
            "\n",
            "[TRAIN] Epoch[1](774/1214); Loss: 0.062857; Backpropagation: 0.6080 sec; Batch: 4.4880 sec\n",
            "0.1120 0.0830 0.0721 0.0649 0.0620 0.0596 0.0582 0.0570 0.0561 0.0555 0.0550 0.0546 0.0542 0.0539 0.0538 0.0537 \n",
            "\n",
            "[TRAIN] Epoch[1](775/1214); Loss: 0.063748; Backpropagation: 0.6180 sec; Batch: 4.4936 sec\n",
            "0.1175 0.0856 0.0735 0.0676 0.0637 0.0609 0.0587 0.0572 0.0560 0.0554 0.0546 0.0542 0.0540 0.0538 0.0537 0.0536 \n",
            "\n",
            "[TRAIN] Epoch[1](776/1214); Loss: 0.058589; Backpropagation: 0.6106 sec; Batch: 4.4785 sec\n",
            "0.1238 0.0800 0.0669 0.0604 0.0561 0.0542 0.0522 0.0510 0.0503 0.0497 0.0493 0.0488 0.0488 0.0487 0.0486 0.0487 \n",
            "\n",
            "[TRAIN] Epoch[1](777/1214); Loss: 0.068795; Backpropagation: 0.6166 sec; Batch: 4.4923 sec\n",
            "0.1339 0.0917 0.0801 0.0726 0.0673 0.0644 0.0625 0.0608 0.0599 0.0592 0.0588 0.0585 0.0582 0.0579 0.0576 0.0574 \n",
            "\n",
            "[TRAIN] Epoch[1](778/1214); Loss: 0.073878; Backpropagation: 0.6148 sec; Batch: 4.4880 sec\n",
            "0.1333 0.0992 0.0885 0.0792 0.0735 0.0714 0.0689 0.0664 0.0647 0.0637 0.0630 0.0626 0.0622 0.0619 0.0618 0.0617 \n",
            "\n",
            "[TRAIN] Epoch[1](779/1214); Loss: 0.059291; Backpropagation: 0.6196 sec; Batch: 4.4928 sec\n",
            "0.1220 0.0792 0.0666 0.0616 0.0568 0.0544 0.0528 0.0519 0.0513 0.0508 0.0505 0.0503 0.0503 0.0501 0.0501 0.0501 \n",
            "\n",
            "[TRAIN] Epoch[1](780/1214); Loss: 0.072512; Backpropagation: 0.6109 sec; Batch: 4.4890 sec\n",
            "0.1244 0.0915 0.0815 0.0749 0.0709 0.0690 0.0674 0.0663 0.0656 0.0650 0.0646 0.0642 0.0640 0.0638 0.0636 0.0635 \n",
            "\n",
            "[TRAIN] Epoch[1](781/1214); Loss: 0.066431; Backpropagation: 0.6159 sec; Batch: 4.4861 sec\n",
            "0.1251 0.0890 0.0756 0.0695 0.0646 0.0617 0.0601 0.0592 0.0584 0.0578 0.0576 0.0572 0.0571 0.0568 0.0567 0.0566 \n",
            "\n",
            "[TRAIN] Epoch[1](782/1214); Loss: 0.071855; Backpropagation: 0.6149 sec; Batch: 4.4913 sec\n",
            "0.1473 0.1085 0.0885 0.0758 0.0700 0.0665 0.0635 0.0616 0.0602 0.0594 0.0588 0.0584 0.0581 0.0578 0.0577 0.0575 \n",
            "\n",
            "[TRAIN] Epoch[1](783/1214); Loss: 0.070525; Backpropagation: 0.6137 sec; Batch: 4.4895 sec\n",
            "0.1460 0.1088 0.0885 0.0759 0.0714 0.0662 0.0632 0.0604 0.0589 0.0573 0.0564 0.0557 0.0553 0.0550 0.0547 0.0546 \n",
            "\n",
            "[TRAIN] Epoch[1](784/1214); Loss: 0.085135; Backpropagation: 0.6153 sec; Batch: 4.4929 sec\n",
            "0.1569 0.1251 0.1036 0.0957 0.0882 0.0821 0.0784 0.0750 0.0729 0.0713 0.0702 0.0695 0.0690 0.0685 0.0681 0.0678 \n",
            "\n",
            "[TRAIN] Epoch[1](785/1214); Loss: 0.084805; Backpropagation: 0.6172 sec; Batch: 4.4981 sec\n",
            "0.1729 0.1384 0.1054 0.0938 0.0868 0.0777 0.0745 0.0712 0.0697 0.0684 0.0674 0.0669 0.0664 0.0661 0.0657 0.0655 \n",
            "\n",
            "[TRAIN] Epoch[1](786/1214); Loss: 0.076860; Backpropagation: 0.6138 sec; Batch: 4.4878 sec\n",
            "0.1621 0.1388 0.0989 0.0879 0.0777 0.0719 0.0675 0.0647 0.0618 0.0604 0.0587 0.0577 0.0565 0.0556 0.0550 0.0545 \n",
            "\n",
            "[TRAIN] Epoch[1](787/1214); Loss: 0.084331; Backpropagation: 0.6149 sec; Batch: 4.4904 sec\n",
            "0.1686 0.1372 0.1052 0.0960 0.0863 0.0790 0.0757 0.0720 0.0698 0.0681 0.0670 0.0658 0.0651 0.0647 0.0645 0.0642 \n",
            "\n",
            "[TRAIN] Epoch[1](788/1214); Loss: 0.076743; Backpropagation: 0.6129 sec; Batch: 4.4868 sec\n",
            "0.1323 0.1184 0.0971 0.0862 0.0774 0.0729 0.0695 0.0672 0.0653 0.0643 0.0634 0.0632 0.0629 0.0627 0.0626 0.0626 \n",
            "\n",
            "[TRAIN] Epoch[1](789/1214); Loss: 0.086559; Backpropagation: 0.6205 sec; Batch: 4.4955 sec\n",
            "0.1465 0.1320 0.1075 0.0988 0.0887 0.0822 0.0783 0.0754 0.0743 0.0730 0.0725 0.0718 0.0716 0.0710 0.0708 0.0707 \n",
            "\n",
            "[TRAIN] Epoch[1](790/1214); Loss: 0.080006; Backpropagation: 0.6220 sec; Batch: 4.4988 sec\n",
            "0.1700 0.1287 0.1021 0.0896 0.0777 0.0724 0.0686 0.0663 0.0651 0.0641 0.0630 0.0630 0.0625 0.0624 0.0623 0.0623 \n",
            "\n",
            "[TRAIN] Epoch[1](791/1214); Loss: 0.075486; Backpropagation: 0.6180 sec; Batch: 4.4954 sec\n",
            "0.1264 0.1221 0.0987 0.0873 0.0772 0.0723 0.0686 0.0654 0.0641 0.0628 0.0622 0.0612 0.0604 0.0600 0.0596 0.0595 \n",
            "\n",
            "[TRAIN] Epoch[1](792/1214); Loss: 0.096093; Backpropagation: 0.6240 sec; Batch: 4.4987 sec\n",
            "0.1664 0.1442 0.1211 0.1072 0.0989 0.0932 0.0894 0.0850 0.0836 0.0816 0.0808 0.0789 0.0779 0.0770 0.0765 0.0759 \n",
            "\n",
            "[TRAIN] Epoch[1](793/1214); Loss: 0.076455; Backpropagation: 0.6119 sec; Batch: 4.4862 sec\n",
            "0.1404 0.1150 0.0966 0.0842 0.0763 0.0713 0.0682 0.0663 0.0648 0.0641 0.0636 0.0633 0.0627 0.0624 0.0619 0.0620 \n",
            "\n",
            "[TRAIN] Epoch[1](794/1214); Loss: 0.080837; Backpropagation: 0.6192 sec; Batch: 4.5005 sec\n",
            "0.1619 0.1327 0.1039 0.0881 0.0797 0.0751 0.0712 0.0684 0.0665 0.0653 0.0643 0.0639 0.0637 0.0632 0.0629 0.0629 \n",
            "\n",
            "[TRAIN] Epoch[1](795/1214); Loss: 0.070603; Backpropagation: 0.6090 sec; Batch: 4.4829 sec\n",
            "0.1388 0.1148 0.0917 0.0794 0.0697 0.0670 0.0630 0.0602 0.0580 0.0567 0.0560 0.0556 0.0552 0.0547 0.0545 0.0545 \n",
            "\n",
            "[TRAIN] Epoch[1](796/1214); Loss: 0.082409; Backpropagation: 0.6139 sec; Batch: 4.4894 sec\n",
            "0.1527 0.1241 0.0960 0.0853 0.0811 0.0773 0.0756 0.0731 0.0716 0.0705 0.0694 0.0688 0.0684 0.0684 0.0682 0.0680 \n",
            "\n",
            "[TRAIN] Epoch[1](797/1214); Loss: 0.082042; Backpropagation: 0.6152 sec; Batch: 4.4945 sec\n",
            "0.1481 0.1162 0.0963 0.0865 0.0823 0.0782 0.0754 0.0738 0.0724 0.0709 0.0700 0.0693 0.0687 0.0685 0.0682 0.0677 \n",
            "\n",
            "[TRAIN] Epoch[1](798/1214); Loss: 0.075939; Backpropagation: 0.6128 sec; Batch: 4.4882 sec\n",
            "0.1366 0.1101 0.0898 0.0812 0.0766 0.0725 0.0689 0.0679 0.0666 0.0651 0.0640 0.0636 0.0634 0.0630 0.0628 0.0629 \n",
            "\n",
            "[TRAIN] Epoch[1](799/1214); Loss: 0.081070; Backpropagation: 0.6129 sec; Batch: 4.4852 sec\n",
            "0.1698 0.1213 0.0980 0.0903 0.0824 0.0766 0.0725 0.0706 0.0690 0.0666 0.0654 0.0643 0.0638 0.0626 0.0622 0.0617 \n",
            "\n",
            "[TRAIN] Epoch[1](800/1214); Loss: 0.085469; Backpropagation: 0.6076 sec; Batch: 4.4796 sec\n",
            "0.1499 0.1193 0.1000 0.0953 0.0872 0.0818 0.0796 0.0771 0.0747 0.0738 0.0729 0.0721 0.0716 0.0710 0.0707 0.0704 \n",
            "\n",
            "[TRAIN] Epoch[1](801/1214); Loss: 0.074935; Backpropagation: 0.6160 sec; Batch: 4.4908 sec\n",
            "0.1521 0.1173 0.0858 0.0786 0.0720 0.0700 0.0668 0.0656 0.0636 0.0628 0.0619 0.0611 0.0608 0.0602 0.0602 0.0600 \n",
            "\n",
            "[TRAIN] Epoch[1](802/1214); Loss: 0.072425; Backpropagation: 0.6120 sec; Batch: 4.4894 sec\n",
            "0.1659 0.1148 0.0825 0.0774 0.0694 0.0664 0.0637 0.0622 0.0602 0.0588 0.0577 0.0567 0.0562 0.0559 0.0557 0.0555 \n",
            "\n",
            "[TRAIN] Epoch[1](803/1214); Loss: 0.078565; Backpropagation: 0.6125 sec; Batch: 4.4865 sec\n",
            "0.1389 0.1134 0.0914 0.0830 0.0776 0.0744 0.0724 0.0711 0.0695 0.0684 0.0674 0.0667 0.0661 0.0657 0.0656 0.0654 \n",
            "\n",
            "[TRAIN] Epoch[1](804/1214); Loss: 0.070106; Backpropagation: 0.6174 sec; Batch: 4.4962 sec\n",
            "0.1377 0.1009 0.0834 0.0757 0.0694 0.0659 0.0631 0.0616 0.0602 0.0592 0.0584 0.0578 0.0573 0.0572 0.0571 0.0570 \n",
            "\n",
            "[TRAIN] Epoch[1](805/1214); Loss: 0.071219; Backpropagation: 0.6147 sec; Batch: 4.4934 sec\n",
            "0.1466 0.1144 0.0851 0.0763 0.0691 0.0656 0.0635 0.0617 0.0594 0.0584 0.0576 0.0570 0.0564 0.0564 0.0561 0.0559 \n",
            "\n",
            "[TRAIN] Epoch[1](806/1214); Loss: 0.086404; Backpropagation: 0.6177 sec; Batch: 4.4913 sec\n",
            "0.1414 0.1220 0.0996 0.0920 0.0871 0.0842 0.0814 0.0795 0.0776 0.0764 0.0752 0.0743 0.0736 0.0732 0.0727 0.0722 \n",
            "\n",
            "[TRAIN] Epoch[1](807/1214); Loss: 0.072635; Backpropagation: 0.6160 sec; Batch: 4.4911 sec\n",
            "0.1377 0.1033 0.0843 0.0768 0.0710 0.0681 0.0661 0.0647 0.0634 0.0624 0.0617 0.0611 0.0609 0.0606 0.0602 0.0600 \n",
            "\n",
            "[TRAIN] Epoch[1](808/1214); Loss: 0.075237; Backpropagation: 0.6124 sec; Batch: 4.4986 sec\n",
            "0.1384 0.1062 0.0860 0.0776 0.0740 0.0707 0.0688 0.0673 0.0662 0.0653 0.0650 0.0641 0.0638 0.0634 0.0635 0.0634 \n",
            "\n",
            "[TRAIN] Epoch[1](809/1214); Loss: 0.067355; Backpropagation: 0.6094 sec; Batch: 4.4889 sec\n",
            "0.1194 0.0999 0.0794 0.0719 0.0664 0.0639 0.0619 0.0597 0.0586 0.0579 0.0572 0.0566 0.0563 0.0560 0.0563 0.0561 \n",
            "\n",
            "[TRAIN] Epoch[1](810/1214); Loss: 0.084148; Backpropagation: 0.6093 sec; Batch: 4.4870 sec\n",
            "0.1624 0.1153 0.0944 0.0877 0.0824 0.0788 0.0762 0.0749 0.0736 0.0732 0.0723 0.0717 0.0714 0.0711 0.0706 0.0706 \n",
            "\n",
            "[TRAIN] Epoch[1](811/1214); Loss: 0.074456; Backpropagation: 0.6174 sec; Batch: 4.4888 sec\n",
            "0.1390 0.1091 0.0872 0.0780 0.0731 0.0707 0.0679 0.0660 0.0647 0.0636 0.0628 0.0623 0.0620 0.0617 0.0617 0.0614 \n",
            "\n",
            "[TRAIN] Epoch[1](812/1214); Loss: 0.074906; Backpropagation: 0.6148 sec; Batch: 4.4880 sec\n",
            "0.1589 0.1136 0.0857 0.0787 0.0724 0.0684 0.0662 0.0645 0.0630 0.0622 0.0617 0.0611 0.0609 0.0603 0.0604 0.0605 \n",
            "\n",
            "[TRAIN] Epoch[1](813/1214); Loss: 0.074401; Backpropagation: 0.6152 sec; Batch: 4.4920 sec\n",
            "0.1444 0.1021 0.0839 0.0774 0.0724 0.0695 0.0677 0.0661 0.0647 0.0639 0.0635 0.0632 0.0631 0.0629 0.0629 0.0628 \n",
            "\n",
            "[TRAIN] Epoch[1](814/1214); Loss: 0.086368; Backpropagation: 0.6179 sec; Batch: 4.4989 sec\n",
            "0.1605 0.1163 0.0994 0.0902 0.0848 0.0821 0.0795 0.0777 0.0762 0.0753 0.0745 0.0737 0.0732 0.0730 0.0728 0.0727 \n",
            "\n",
            "[TRAIN] Epoch[1](815/1214); Loss: 0.071902; Backpropagation: 0.6174 sec; Batch: 4.4949 sec\n",
            "0.1436 0.1100 0.0888 0.0783 0.0738 0.0682 0.0648 0.0619 0.0600 0.0589 0.0581 0.0573 0.0569 0.0567 0.0566 0.0565 \n",
            "\n",
            "[TRAIN] Epoch[1](816/1214); Loss: 0.076938; Backpropagation: 0.6091 sec; Batch: 4.4884 sec\n",
            "0.1536 0.1075 0.0876 0.0797 0.0750 0.0717 0.0691 0.0675 0.0668 0.0661 0.0655 0.0649 0.0646 0.0642 0.0637 0.0637 \n",
            "\n",
            "[TRAIN] Epoch[1](817/1214); Loss: 0.074034; Backpropagation: 0.6125 sec; Batch: 4.4858 sec\n",
            "0.1379 0.1062 0.0849 0.0761 0.0718 0.0688 0.0673 0.0659 0.0647 0.0642 0.0635 0.0629 0.0627 0.0627 0.0625 0.0624 \n",
            "\n",
            "[TRAIN] Epoch[1](818/1214); Loss: 0.067495; Backpropagation: 0.6168 sec; Batch: 4.4986 sec\n",
            "0.1302 0.0983 0.0786 0.0703 0.0660 0.0628 0.0610 0.0595 0.0583 0.0574 0.0570 0.0566 0.0562 0.0560 0.0558 0.0558 \n",
            "\n",
            "[TRAIN] Epoch[1](819/1214); Loss: 0.069407; Backpropagation: 0.6199 sec; Batch: 4.4927 sec\n",
            "0.1325 0.1003 0.0837 0.0749 0.0697 0.0650 0.0627 0.0606 0.0593 0.0586 0.0580 0.0576 0.0572 0.0570 0.0568 0.0567 \n",
            "\n",
            "[TRAIN] Epoch[1](820/1214); Loss: 0.070024; Backpropagation: 0.6110 sec; Batch: 4.4925 sec\n",
            "0.1272 0.0967 0.0804 0.0733 0.0679 0.0657 0.0644 0.0629 0.0619 0.0612 0.0605 0.0600 0.0598 0.0597 0.0595 0.0593 \n",
            "\n",
            "[TRAIN] Epoch[1](821/1214); Loss: 0.080936; Backpropagation: 0.6124 sec; Batch: 4.4872 sec\n",
            "0.1680 0.1168 0.0935 0.0837 0.0771 0.0750 0.0719 0.0702 0.0692 0.0682 0.0676 0.0673 0.0670 0.0668 0.0664 0.0662 \n",
            "\n",
            "[TRAIN] Epoch[1](822/1214); Loss: 0.068776; Backpropagation: 0.6123 sec; Batch: 4.4914 sec\n",
            "0.1226 0.0956 0.0826 0.0737 0.0696 0.0660 0.0635 0.0621 0.0610 0.0598 0.0589 0.0580 0.0574 0.0569 0.0566 0.0562 \n",
            "\n",
            "[TRAIN] Epoch[1](823/1214); Loss: 0.062162; Backpropagation: 0.6083 sec; Batch: 4.4809 sec\n",
            "0.1485 0.0964 0.0726 0.0635 0.0592 0.0555 0.0532 0.0518 0.0506 0.0498 0.0493 0.0490 0.0489 0.0488 0.0489 0.0487 \n",
            "\n",
            "[TRAIN] Epoch[1](824/1214); Loss: 0.067246; Backpropagation: 0.6173 sec; Batch: 4.4921 sec\n",
            "0.1474 0.0924 0.0758 0.0678 0.0637 0.0610 0.0594 0.0582 0.0574 0.0568 0.0563 0.0561 0.0559 0.0559 0.0558 0.0559 \n",
            "\n",
            "[TRAIN] Epoch[1](825/1214); Loss: 0.065432; Backpropagation: 0.6213 sec; Batch: 4.4936 sec\n",
            "0.1516 0.0988 0.0735 0.0672 0.0612 0.0588 0.0575 0.0556 0.0545 0.0536 0.0532 0.0528 0.0526 0.0523 0.0519 0.0517 \n",
            "\n",
            "[TRAIN] Epoch[1](826/1214); Loss: 0.065769; Backpropagation: 0.6144 sec; Batch: 4.4943 sec\n",
            "0.1395 0.0929 0.0734 0.0674 0.0626 0.0601 0.0584 0.0571 0.0562 0.0556 0.0552 0.0550 0.0549 0.0547 0.0547 0.0546 \n",
            "\n",
            "[TRAIN] Epoch[1](827/1214); Loss: 0.073081; Backpropagation: 0.6146 sec; Batch: 4.4890 sec\n",
            "0.1544 0.1055 0.0846 0.0759 0.0713 0.0676 0.0650 0.0636 0.0622 0.0615 0.0608 0.0602 0.0596 0.0593 0.0591 0.0589 \n",
            "\n",
            "[TRAIN] Epoch[1](828/1214); Loss: 0.075105; Backpropagation: 0.6169 sec; Batch: 4.4942 sec\n",
            "0.1471 0.1009 0.0873 0.0800 0.0735 0.0701 0.0682 0.0665 0.0652 0.0643 0.0638 0.0633 0.0632 0.0629 0.0627 0.0625 \n",
            "\n",
            "[TRAIN] Epoch[1](829/1214); Loss: 0.074981; Backpropagation: 0.6171 sec; Batch: 4.4927 sec\n",
            "0.1424 0.1038 0.0844 0.0762 0.0726 0.0699 0.0680 0.0668 0.0658 0.0652 0.0647 0.0644 0.0641 0.0640 0.0639 0.0637 \n",
            "\n",
            "[TRAIN] Epoch[1](830/1214); Loss: 0.075307; Backpropagation: 0.6222 sec; Batch: 4.4966 sec\n",
            "0.1486 0.1032 0.0848 0.0774 0.0735 0.0709 0.0688 0.0673 0.0659 0.0649 0.0642 0.0638 0.0634 0.0630 0.0627 0.0625 \n",
            "\n",
            "[TRAIN] Epoch[1](831/1214); Loss: 0.071981; Backpropagation: 0.6222 sec; Batch: 4.4952 sec\n",
            "0.1526 0.0964 0.0799 0.0728 0.0683 0.0658 0.0639 0.0629 0.0621 0.0615 0.0612 0.0609 0.0609 0.0609 0.0607 0.0608 \n",
            "\n",
            "[TRAIN] Epoch[1](832/1214); Loss: 0.069680; Backpropagation: 0.6072 sec; Batch: 4.4793 sec\n",
            "0.1383 0.0987 0.0789 0.0719 0.0681 0.0651 0.0629 0.0616 0.0605 0.0597 0.0590 0.0585 0.0583 0.0579 0.0578 0.0577 \n",
            "\n",
            "[TRAIN] Epoch[1](833/1214); Loss: 0.068886; Backpropagation: 0.6169 sec; Batch: 4.4905 sec\n",
            "0.1291 0.0990 0.0795 0.0731 0.0677 0.0646 0.0623 0.0605 0.0596 0.0590 0.0586 0.0583 0.0580 0.0577 0.0576 0.0575 \n",
            "\n",
            "[TRAIN] Epoch[1](834/1214); Loss: 0.072153; Backpropagation: 0.6107 sec; Batch: 4.4850 sec\n",
            "0.1356 0.0996 0.0855 0.0766 0.0713 0.0680 0.0655 0.0638 0.0628 0.0620 0.0612 0.0609 0.0606 0.0605 0.0604 0.0603 \n",
            "\n",
            "[TRAIN] Epoch[1](835/1214); Loss: 0.061243; Backpropagation: 0.6211 sec; Batch: 4.4983 sec\n",
            "0.1361 0.0918 0.0756 0.0659 0.0604 0.0566 0.0538 0.0518 0.0502 0.0494 0.0489 0.0484 0.0481 0.0478 0.0476 0.0475 \n",
            "\n",
            "[TRAIN] Epoch[1](836/1214); Loss: 0.060824; Backpropagation: 0.6114 sec; Batch: 4.4854 sec\n",
            "0.1290 0.0838 0.0731 0.0646 0.0586 0.0559 0.0540 0.0528 0.0516 0.0510 0.0505 0.0501 0.0497 0.0495 0.0495 0.0494 \n",
            "\n",
            "[TRAIN] Epoch[1](837/1214); Loss: 0.064012; Backpropagation: 0.6132 sec; Batch: 4.4881 sec\n",
            "0.1392 0.0879 0.0755 0.0657 0.0611 0.0588 0.0568 0.0554 0.0544 0.0537 0.0534 0.0529 0.0526 0.0523 0.0522 0.0521 \n",
            "\n",
            "[TRAIN] Epoch[1](838/1214); Loss: 0.062817; Backpropagation: 0.6117 sec; Batch: 4.4893 sec\n",
            "0.1263 0.0881 0.0738 0.0665 0.0623 0.0585 0.0564 0.0549 0.0538 0.0531 0.0526 0.0522 0.0519 0.0517 0.0516 0.0514 \n",
            "\n",
            "[TRAIN] Epoch[1](839/1214); Loss: 0.071273; Backpropagation: 0.6137 sec; Batch: 4.4829 sec\n",
            "0.1393 0.0995 0.0824 0.0741 0.0697 0.0665 0.0644 0.0628 0.0617 0.0608 0.0605 0.0601 0.0600 0.0597 0.0595 0.0594 \n",
            "\n",
            "[TRAIN] Epoch[1](840/1214); Loss: 0.068403; Backpropagation: 0.6135 sec; Batch: 4.4902 sec\n",
            "0.1272 0.0970 0.0783 0.0713 0.0666 0.0641 0.0622 0.0608 0.0599 0.0591 0.0585 0.0583 0.0581 0.0578 0.0576 0.0576 \n",
            "\n",
            "[TRAIN] Epoch[1](841/1214); Loss: 0.070601; Backpropagation: 0.6114 sec; Batch: 4.4815 sec\n",
            "0.1352 0.0990 0.0789 0.0729 0.0686 0.0657 0.0636 0.0623 0.0616 0.0611 0.0607 0.0603 0.0602 0.0599 0.0598 0.0598 \n",
            "\n",
            "[TRAIN] Epoch[1](842/1214); Loss: 0.069998; Backpropagation: 0.6211 sec; Batch: 4.4996 sec\n",
            "0.1438 0.1012 0.0783 0.0725 0.0673 0.0646 0.0623 0.0610 0.0599 0.0593 0.0588 0.0585 0.0582 0.0582 0.0581 0.0580 \n",
            "\n",
            "[TRAIN] Epoch[1](843/1214); Loss: 0.066401; Backpropagation: 0.6225 sec; Batch: 4.5048 sec\n",
            "0.1299 0.0980 0.0775 0.0696 0.0644 0.0614 0.0593 0.0580 0.0571 0.0564 0.0559 0.0555 0.0552 0.0549 0.0548 0.0546 \n",
            "\n",
            "[TRAIN] Epoch[1](844/1214); Loss: 0.073711; Backpropagation: 0.6091 sec; Batch: 4.4930 sec\n",
            "0.1460 0.1040 0.0841 0.0757 0.0710 0.0682 0.0662 0.0647 0.0640 0.0634 0.0628 0.0623 0.0620 0.0618 0.0617 0.0615 \n",
            "\n",
            "[TRAIN] Epoch[1](845/1214); Loss: 0.061448; Backpropagation: 0.6112 sec; Batch: 4.4832 sec\n",
            "0.1477 0.0971 0.0708 0.0621 0.0571 0.0544 0.0525 0.0510 0.0503 0.0496 0.0490 0.0486 0.0484 0.0483 0.0482 0.0482 \n",
            "\n",
            "[TRAIN] Epoch[1](846/1214); Loss: 0.063393; Backpropagation: 0.6153 sec; Batch: 4.4920 sec\n",
            "0.1347 0.0912 0.0726 0.0652 0.0613 0.0583 0.0568 0.0553 0.0541 0.0532 0.0526 0.0521 0.0520 0.0517 0.0517 0.0515 \n",
            "\n",
            "[TRAIN] Epoch[1](847/1214); Loss: 0.071252; Backpropagation: 0.6185 sec; Batch: 4.4966 sec\n",
            "0.1413 0.1011 0.0814 0.0735 0.0693 0.0659 0.0645 0.0629 0.0617 0.0606 0.0603 0.0599 0.0597 0.0594 0.0594 0.0591 \n",
            "\n",
            "[TRAIN] Epoch[1](848/1214); Loss: 0.068761; Backpropagation: 0.6127 sec; Batch: 4.4875 sec\n",
            "0.1355 0.0964 0.0836 0.0741 0.0687 0.0650 0.0625 0.0605 0.0590 0.0581 0.0572 0.0566 0.0561 0.0558 0.0556 0.0554 \n",
            "\n",
            "[TRAIN] Epoch[1](849/1214); Loss: 0.059570; Backpropagation: 0.6147 sec; Batch: 4.4836 sec\n",
            "0.1404 0.0843 0.0658 0.0615 0.0563 0.0535 0.0513 0.0503 0.0498 0.0495 0.0490 0.0487 0.0484 0.0483 0.0481 0.0481 \n",
            "\n",
            "[TRAIN] Epoch[1](850/1214); Loss: 0.065567; Backpropagation: 0.6148 sec; Batch: 4.4858 sec\n",
            "0.1263 0.0943 0.0753 0.0678 0.0628 0.0605 0.0590 0.0577 0.0569 0.0562 0.0558 0.0555 0.0553 0.0552 0.0551 0.0553 \n",
            "\n",
            "[TRAIN] Epoch[1](851/1214); Loss: 0.072655; Backpropagation: 0.6156 sec; Batch: 4.4965 sec\n",
            "0.1374 0.0992 0.0831 0.0764 0.0713 0.0684 0.0663 0.0647 0.0634 0.0627 0.0622 0.0618 0.0616 0.0614 0.0613 0.0613 \n",
            "\n",
            "[TRAIN] Epoch[1](852/1214); Loss: 0.075128; Backpropagation: 0.6121 sec; Batch: 4.4916 sec\n",
            "0.1450 0.1023 0.0853 0.0770 0.0730 0.0703 0.0687 0.0670 0.0658 0.0650 0.0646 0.0642 0.0638 0.0637 0.0633 0.0632 \n",
            "\n",
            "[TRAIN] Epoch[1](853/1214); Loss: 0.076938; Backpropagation: 0.6149 sec; Batch: 4.4922 sec\n",
            "0.1492 0.1095 0.0869 0.0795 0.0754 0.0721 0.0697 0.0682 0.0672 0.0661 0.0653 0.0649 0.0645 0.0643 0.0641 0.0639 \n",
            "\n",
            "[TRAIN] Epoch[1](854/1214); Loss: 0.071957; Backpropagation: 0.6204 sec; Batch: 4.4994 sec\n",
            "0.1517 0.1007 0.0819 0.0735 0.0692 0.0655 0.0635 0.0624 0.0614 0.0610 0.0605 0.0602 0.0601 0.0600 0.0599 0.0598 \n",
            "\n",
            "[TRAIN] Epoch[1](855/1214); Loss: 0.059175; Backpropagation: 0.6142 sec; Batch: 4.4900 sec\n",
            "0.1228 0.0859 0.0693 0.0627 0.0583 0.0549 0.0528 0.0511 0.0500 0.0493 0.0489 0.0484 0.0483 0.0481 0.0480 0.0481 \n",
            "\n",
            "[TRAIN] Epoch[1](856/1214); Loss: 0.075292; Backpropagation: 0.6084 sec; Batch: 4.4798 sec\n",
            "0.1429 0.1058 0.0898 0.0809 0.0754 0.0719 0.0692 0.0673 0.0654 0.0641 0.0631 0.0625 0.0621 0.0617 0.0615 0.0613 \n",
            "\n",
            "[TRAIN] Epoch[1](857/1214); Loss: 0.081937; Backpropagation: 0.6100 sec; Batch: 4.4827 sec\n",
            "0.1378 0.1088 0.0941 0.0873 0.0821 0.0789 0.0766 0.0747 0.0735 0.0724 0.0717 0.0712 0.0709 0.0706 0.0703 0.0702 \n",
            "\n",
            "[TRAIN] Epoch[1](858/1214); Loss: 0.077090; Backpropagation: 0.6109 sec; Batch: 4.4830 sec\n",
            "0.1405 0.1098 0.0922 0.0835 0.0770 0.0730 0.0701 0.0684 0.0668 0.0658 0.0651 0.0647 0.0645 0.0643 0.0639 0.0638 \n",
            "\n",
            "[TRAIN] Epoch[1](859/1214); Loss: 0.067218; Backpropagation: 0.6184 sec; Batch: 4.4900 sec\n",
            "0.1191 0.0924 0.0778 0.0700 0.0653 0.0628 0.0614 0.0604 0.0596 0.0589 0.0585 0.0582 0.0580 0.0578 0.0578 0.0576 \n",
            "\n",
            "[TRAIN] Epoch[1](860/1214); Loss: 0.080493; Backpropagation: 0.6143 sec; Batch: 4.4916 sec\n",
            "0.1530 0.1111 0.0927 0.0837 0.0786 0.0752 0.0731 0.0716 0.0704 0.0697 0.0690 0.0686 0.0682 0.0679 0.0677 0.0675 \n",
            "\n",
            "[TRAIN] Epoch[1](861/1214); Loss: 0.066783; Backpropagation: 0.6215 sec; Batch: 4.4899 sec\n",
            "0.1435 0.1029 0.0847 0.0740 0.0671 0.0626 0.0591 0.0564 0.0544 0.0532 0.0525 0.0521 0.0519 0.0516 0.0513 0.0512 \n",
            "\n",
            "[TRAIN] Epoch[1](862/1214); Loss: 0.069431; Backpropagation: 0.6129 sec; Batch: 4.4860 sec\n",
            "0.1381 0.1012 0.0846 0.0745 0.0687 0.0644 0.0614 0.0598 0.0587 0.0584 0.0577 0.0572 0.0568 0.0566 0.0564 0.0564 \n",
            "\n",
            "[TRAIN] Epoch[1](863/1214); Loss: 0.071976; Backpropagation: 0.6131 sec; Batch: 4.4972 sec\n",
            "0.1414 0.0970 0.0806 0.0728 0.0691 0.0668 0.0652 0.0639 0.0629 0.0623 0.0621 0.0619 0.0616 0.0615 0.0613 0.0613 \n",
            "\n",
            "[TRAIN] Epoch[1](864/1214); Loss: 0.063609; Backpropagation: 0.6093 sec; Batch: 4.4875 sec\n",
            "0.1400 0.0924 0.0750 0.0651 0.0605 0.0582 0.0559 0.0546 0.0536 0.0528 0.0522 0.0520 0.0516 0.0514 0.0513 0.0512 \n",
            "\n",
            "[TRAIN] Epoch[1](865/1214); Loss: 0.067244; Backpropagation: 0.6118 sec; Batch: 4.4874 sec\n",
            "0.1371 0.0889 0.0761 0.0702 0.0650 0.0621 0.0606 0.0591 0.0581 0.0579 0.0574 0.0570 0.0569 0.0566 0.0565 0.0564 \n",
            "\n",
            "[TRAIN] Epoch[1](866/1214); Loss: 0.073584; Backpropagation: 0.6191 sec; Batch: 4.4938 sec\n",
            "0.1364 0.0950 0.0839 0.0765 0.0724 0.0690 0.0673 0.0659 0.0652 0.0644 0.0641 0.0639 0.0637 0.0634 0.0631 0.0630 \n",
            "\n",
            "[TRAIN] Epoch[1](867/1214); Loss: 0.069877; Backpropagation: 0.6093 sec; Batch: 4.4868 sec\n",
            "0.1380 0.0910 0.0789 0.0713 0.0673 0.0648 0.0632 0.0621 0.0614 0.0608 0.0604 0.0600 0.0598 0.0597 0.0597 0.0597 \n",
            "\n",
            "[TRAIN] Epoch[1](868/1214); Loss: 0.073898; Backpropagation: 0.6207 sec; Batch: 4.4925 sec\n",
            "0.1459 0.0957 0.0851 0.0787 0.0736 0.0704 0.0680 0.0661 0.0649 0.0635 0.0627 0.0622 0.0618 0.0614 0.0612 0.0611 \n",
            "\n",
            "[TRAIN] Epoch[1](869/1214); Loss: 0.063984; Backpropagation: 0.6148 sec; Batch: 4.4830 sec\n",
            "0.1397 0.0887 0.0737 0.0661 0.0606 0.0581 0.0564 0.0555 0.0545 0.0540 0.0534 0.0530 0.0527 0.0526 0.0525 0.0524 \n",
            "\n",
            "[TRAIN] Epoch[1](870/1214); Loss: 0.058870; Backpropagation: 0.6174 sec; Batch: 4.4955 sec\n",
            "0.1254 0.0811 0.0673 0.0605 0.0562 0.0539 0.0525 0.0513 0.0506 0.0498 0.0493 0.0489 0.0488 0.0488 0.0487 0.0486 \n",
            "\n",
            "[TRAIN] Epoch[1](871/1214); Loss: 0.063600; Backpropagation: 0.6194 sec; Batch: 4.4945 sec\n",
            "0.1402 0.0927 0.0759 0.0685 0.0618 0.0582 0.0560 0.0543 0.0530 0.0521 0.0517 0.0512 0.0508 0.0506 0.0504 0.0502 \n",
            "\n",
            "[TRAIN] Epoch[1](872/1214); Loss: 0.070800; Backpropagation: 0.6153 sec; Batch: 4.4854 sec\n",
            "0.1328 0.0934 0.0798 0.0737 0.0695 0.0665 0.0646 0.0634 0.0625 0.0620 0.0615 0.0611 0.0607 0.0606 0.0604 0.0603 \n",
            "\n",
            "[TRAIN] Epoch[1](873/1214); Loss: 0.067184; Backpropagation: 0.6198 sec; Batch: 4.4959 sec\n",
            "0.1368 0.0931 0.0768 0.0693 0.0645 0.0627 0.0605 0.0593 0.0581 0.0573 0.0567 0.0564 0.0560 0.0560 0.0558 0.0557 \n",
            "\n",
            "[TRAIN] Epoch[1](874/1214); Loss: 0.069928; Backpropagation: 0.6133 sec; Batch: 4.4903 sec\n",
            "0.1345 0.0946 0.0777 0.0712 0.0673 0.0652 0.0637 0.0625 0.0617 0.0612 0.0606 0.0602 0.0600 0.0597 0.0595 0.0593 \n",
            "\n",
            "[TRAIN] Epoch[1](875/1214); Loss: 0.064149; Backpropagation: 0.6142 sec; Batch: 4.4886 sec\n",
            "0.1380 0.0905 0.0738 0.0668 0.0613 0.0583 0.0563 0.0550 0.0544 0.0538 0.0534 0.0532 0.0530 0.0529 0.0529 0.0529 \n",
            "\n",
            "[TRAIN] Epoch[1](876/1214); Loss: 0.070810; Backpropagation: 0.6186 sec; Batch: 4.4968 sec\n",
            "0.1322 0.0914 0.0793 0.0740 0.0693 0.0665 0.0647 0.0635 0.0627 0.0622 0.0619 0.0614 0.0612 0.0610 0.0609 0.0608 \n",
            "\n",
            "[TRAIN] Epoch[1](877/1214); Loss: 0.066387; Backpropagation: 0.6129 sec; Batch: 4.4875 sec\n",
            "0.1397 0.0930 0.0776 0.0693 0.0640 0.0607 0.0587 0.0573 0.0565 0.0560 0.0556 0.0553 0.0550 0.0546 0.0545 0.0544 \n",
            "\n",
            "[TRAIN] Epoch[1](878/1214); Loss: 0.059827; Backpropagation: 0.6160 sec; Batch: 4.4919 sec\n",
            "0.1256 0.0825 0.0697 0.0611 0.0572 0.0548 0.0531 0.0519 0.0512 0.0507 0.0503 0.0501 0.0499 0.0498 0.0496 0.0497 \n",
            "\n",
            "[TRAIN] Epoch[1](879/1214); Loss: 0.069790; Backpropagation: 0.6117 sec; Batch: 4.4885 sec\n",
            "0.1271 0.0955 0.0785 0.0713 0.0672 0.0652 0.0637 0.0627 0.0621 0.0613 0.0608 0.0605 0.0604 0.0602 0.0601 0.0600 \n",
            "\n",
            "[TRAIN] Epoch[1](880/1214); Loss: 0.064873; Backpropagation: 0.6159 sec; Batch: 4.4905 sec\n",
            "0.1178 0.0878 0.0758 0.0673 0.0631 0.0608 0.0592 0.0580 0.0573 0.0569 0.0563 0.0560 0.0557 0.0555 0.0553 0.0552 \n",
            "\n",
            "[TRAIN] Epoch[1](881/1214); Loss: 0.061622; Backpropagation: 0.6141 sec; Batch: 4.4865 sec\n",
            "0.1282 0.0833 0.0698 0.0637 0.0601 0.0571 0.0551 0.0539 0.0530 0.0525 0.0521 0.0518 0.0516 0.0514 0.0512 0.0511 \n",
            "\n",
            "[TRAIN] Epoch[1](882/1214); Loss: 0.067344; Backpropagation: 0.6105 sec; Batch: 4.4867 sec\n",
            "0.1229 0.0905 0.0763 0.0701 0.0657 0.0637 0.0615 0.0604 0.0596 0.0590 0.0585 0.0582 0.0579 0.0578 0.0577 0.0576 \n",
            "\n",
            "[TRAIN] Epoch[1](883/1214); Loss: 0.081765; Backpropagation: 0.6130 sec; Batch: 4.4895 sec\n",
            "0.1417 0.1045 0.0904 0.0839 0.0799 0.0774 0.0756 0.0747 0.0738 0.0734 0.0729 0.0725 0.0721 0.0720 0.0718 0.0717 \n",
            "\n",
            "[TRAIN] Epoch[1](884/1214); Loss: 0.059878; Backpropagation: 0.6146 sec; Batch: 4.4872 sec\n",
            "0.1192 0.0814 0.0675 0.0618 0.0579 0.0556 0.0537 0.0526 0.0521 0.0515 0.0512 0.0509 0.0508 0.0507 0.0506 0.0506 \n",
            "\n",
            "[TRAIN] Epoch[1](885/1214); Loss: 0.068449; Backpropagation: 0.6109 sec; Batch: 4.4889 sec\n",
            "0.1299 0.0871 0.0765 0.0703 0.0666 0.0645 0.0628 0.0617 0.0609 0.0601 0.0597 0.0593 0.0591 0.0589 0.0589 0.0587 \n",
            "\n",
            "[TRAIN] Epoch[1](886/1214); Loss: 0.061734; Backpropagation: 0.6107 sec; Batch: 4.4855 sec\n",
            "0.1325 0.0861 0.0749 0.0663 0.0615 0.0582 0.0555 0.0534 0.0521 0.0507 0.0502 0.0498 0.0495 0.0492 0.0490 0.0489 \n",
            "\n",
            "[TRAIN] Epoch[1](887/1214); Loss: 0.070563; Backpropagation: 0.6102 sec; Batch: 4.4850 sec\n",
            "0.1432 0.0966 0.0799 0.0716 0.0689 0.0653 0.0630 0.0618 0.0611 0.0604 0.0601 0.0598 0.0595 0.0593 0.0592 0.0591 \n",
            "\n",
            "[TRAIN] Epoch[1](888/1214); Loss: 0.074859; Backpropagation: 0.6117 sec; Batch: 4.4887 sec\n",
            "0.1497 0.0984 0.0843 0.0756 0.0715 0.0694 0.0678 0.0666 0.0658 0.0652 0.0646 0.0642 0.0638 0.0638 0.0636 0.0634 \n",
            "\n",
            "[TRAIN] Epoch[1](889/1214); Loss: 0.057549; Backpropagation: 0.6156 sec; Batch: 4.4941 sec\n",
            "0.1236 0.0742 0.0636 0.0584 0.0550 0.0528 0.0515 0.0504 0.0498 0.0494 0.0491 0.0490 0.0488 0.0485 0.0484 0.0484 \n",
            "\n",
            "[TRAIN] Epoch[1](890/1214); Loss: 0.068663; Backpropagation: 0.6166 sec; Batch: 4.4911 sec\n",
            "0.1229 0.0901 0.0782 0.0715 0.0674 0.0655 0.0634 0.0620 0.0611 0.0607 0.0600 0.0596 0.0594 0.0591 0.0589 0.0588 \n",
            "\n",
            "[TRAIN] Epoch[1](891/1214); Loss: 0.068370; Backpropagation: 0.6136 sec; Batch: 4.4858 sec\n",
            "0.1278 0.0884 0.0747 0.0691 0.0661 0.0639 0.0627 0.0618 0.0610 0.0606 0.0602 0.0599 0.0596 0.0595 0.0593 0.0593 \n",
            "\n",
            "[TRAIN] Epoch[1](892/1214); Loss: 0.079985; Backpropagation: 0.6157 sec; Batch: 4.4851 sec\n",
            "0.1317 0.1008 0.0900 0.0829 0.0789 0.0765 0.0745 0.0735 0.0728 0.0724 0.0719 0.0713 0.0709 0.0708 0.0705 0.0704 \n",
            "\n",
            "[TRAIN] Epoch[1](893/1214); Loss: 0.068260; Backpropagation: 0.6232 sec; Batch: 4.5026 sec\n",
            "0.1386 0.0913 0.0747 0.0685 0.0650 0.0627 0.0613 0.0602 0.0596 0.0592 0.0589 0.0586 0.0584 0.0585 0.0583 0.0583 \n",
            "\n",
            "[TRAIN] Epoch[1](894/1214); Loss: 0.063026; Backpropagation: 0.6092 sec; Batch: 4.4861 sec\n",
            "0.1365 0.0868 0.0695 0.0637 0.0600 0.0575 0.0560 0.0549 0.0542 0.0536 0.0531 0.0528 0.0526 0.0525 0.0524 0.0523 \n",
            "\n",
            "[TRAIN] Epoch[1](895/1214); Loss: 0.057962; Backpropagation: 0.6161 sec; Batch: 4.4938 sec\n",
            "0.1168 0.0806 0.0685 0.0613 0.0567 0.0534 0.0517 0.0507 0.0498 0.0492 0.0487 0.0484 0.0482 0.0480 0.0479 0.0478 \n",
            "\n",
            "[TRAIN] Epoch[1](896/1214); Loss: 0.060049; Backpropagation: 0.6097 sec; Batch: 4.4811 sec\n",
            "0.1100 0.0790 0.0681 0.0625 0.0587 0.0563 0.0548 0.0537 0.0531 0.0526 0.0523 0.0522 0.0520 0.0519 0.0518 0.0517 \n",
            "\n",
            "[TRAIN] Epoch[1](897/1214); Loss: 0.052482; Backpropagation: 0.6187 sec; Batch: 4.4899 sec\n",
            "0.1023 0.0744 0.0613 0.0544 0.0506 0.0484 0.0469 0.0458 0.0452 0.0449 0.0446 0.0444 0.0442 0.0441 0.0441 0.0442 \n",
            "\n",
            "[TRAIN] Epoch[1](898/1214); Loss: 0.059472; Backpropagation: 0.6119 sec; Batch: 4.4875 sec\n",
            "0.1169 0.0787 0.0668 0.0606 0.0573 0.0547 0.0535 0.0527 0.0520 0.0516 0.0514 0.0512 0.0511 0.0510 0.0510 0.0509 \n",
            "\n",
            "[TRAIN] Epoch[1](899/1214); Loss: 0.064878; Backpropagation: 0.6110 sec; Batch: 4.4870 sec\n",
            "0.1159 0.0849 0.0751 0.0686 0.0640 0.0611 0.0595 0.0583 0.0575 0.0571 0.0566 0.0562 0.0560 0.0558 0.0557 0.0557 \n",
            "\n",
            "[TRAIN] Epoch[1](900/1214); Loss: 0.066795; Backpropagation: 0.6132 sec; Batch: 4.4840 sec\n",
            "0.1382 0.0939 0.0767 0.0692 0.0642 0.0608 0.0590 0.0580 0.0572 0.0567 0.0563 0.0559 0.0557 0.0556 0.0556 0.0555 \n",
            "\n",
            "[TRAIN] Epoch[1](901/1214); Loss: 0.064638; Backpropagation: 0.6100 sec; Batch: 4.4850 sec\n",
            "0.1286 0.0847 0.0720 0.0659 0.0624 0.0598 0.0584 0.0574 0.0567 0.0563 0.0559 0.0555 0.0553 0.0551 0.0550 0.0550 \n",
            "\n",
            "[TRAIN] Epoch[1](902/1214); Loss: 0.066192; Backpropagation: 0.6205 sec; Batch: 4.5003 sec\n",
            "0.1300 0.0905 0.0754 0.0684 0.0640 0.0615 0.0602 0.0587 0.0577 0.0570 0.0566 0.0562 0.0560 0.0557 0.0556 0.0556 \n",
            "\n",
            "[TRAIN] Epoch[1](903/1214); Loss: 0.071961; Backpropagation: 0.6115 sec; Batch: 4.4849 sec\n",
            "0.1360 0.0968 0.0823 0.0745 0.0704 0.0672 0.0656 0.0643 0.0633 0.0626 0.0622 0.0618 0.0615 0.0612 0.0610 0.0607 \n",
            "\n",
            "[TRAIN] Epoch[1](904/1214); Loss: 0.060540; Backpropagation: 0.6135 sec; Batch: 4.4922 sec\n",
            "0.1258 0.0797 0.0678 0.0622 0.0580 0.0554 0.0540 0.0532 0.0525 0.0521 0.0518 0.0515 0.0514 0.0512 0.0511 0.0511 \n",
            "\n",
            "[TRAIN] Epoch[1](905/1214); Loss: 0.063116; Backpropagation: 0.6126 sec; Batch: 4.4870 sec\n",
            "0.1145 0.0852 0.0704 0.0647 0.0611 0.0587 0.0578 0.0569 0.0562 0.0558 0.0553 0.0550 0.0548 0.0547 0.0545 0.0544 \n",
            "\n",
            "[TRAIN] Epoch[1](906/1214); Loss: 0.064567; Backpropagation: 0.6072 sec; Batch: 4.4851 sec\n",
            "0.1243 0.0875 0.0751 0.0671 0.0624 0.0604 0.0585 0.0573 0.0564 0.0558 0.0553 0.0549 0.0547 0.0545 0.0545 0.0543 \n",
            "\n",
            "[TRAIN] Epoch[1](907/1214); Loss: 0.061560; Backpropagation: 0.6184 sec; Batch: 4.4971 sec\n",
            "0.1227 0.0870 0.0721 0.0637 0.0592 0.0572 0.0556 0.0544 0.0534 0.0524 0.0519 0.0515 0.0512 0.0511 0.0509 0.0507 \n",
            "\n",
            "[TRAIN] Epoch[1](908/1214); Loss: 0.068978; Backpropagation: 0.6084 sec; Batch: 4.4816 sec\n",
            "0.1316 0.0911 0.0768 0.0698 0.0667 0.0643 0.0628 0.0619 0.0612 0.0606 0.0601 0.0598 0.0596 0.0593 0.0592 0.0591 \n",
            "\n",
            "[TRAIN] Epoch[1](909/1214); Loss: 0.064811; Backpropagation: 0.6195 sec; Batch: 4.4951 sec\n",
            "0.1250 0.0917 0.0743 0.0664 0.0621 0.0596 0.0580 0.0571 0.0564 0.0559 0.0555 0.0552 0.0550 0.0549 0.0549 0.0549 \n",
            "\n",
            "[TRAIN] Epoch[1](910/1214); Loss: 0.067724; Backpropagation: 0.6161 sec; Batch: 4.4947 sec\n",
            "0.1312 0.0910 0.0760 0.0699 0.0657 0.0629 0.0614 0.0603 0.0595 0.0590 0.0585 0.0581 0.0578 0.0576 0.0575 0.0573 \n",
            "\n",
            "[TRAIN] Epoch[1](911/1214); Loss: 0.061893; Backpropagation: 0.6203 sec; Batch: 4.5017 sec\n",
            "0.1266 0.0863 0.0704 0.0622 0.0589 0.0564 0.0550 0.0543 0.0537 0.0531 0.0527 0.0525 0.0522 0.0521 0.0520 0.0520 \n",
            "\n",
            "[TRAIN] Epoch[1](912/1214); Loss: 0.066695; Backpropagation: 0.6112 sec; Batch: 4.4855 sec\n",
            "0.1297 0.0856 0.0724 0.0661 0.0635 0.0615 0.0605 0.0598 0.0592 0.0589 0.0586 0.0585 0.0584 0.0583 0.0582 0.0582 \n",
            "\n",
            "[TRAIN] Epoch[1](913/1214); Loss: 0.069503; Backpropagation: 0.6157 sec; Batch: 4.4917 sec\n",
            "0.1251 0.0917 0.0770 0.0708 0.0673 0.0649 0.0636 0.0627 0.0621 0.0616 0.0614 0.0611 0.0609 0.0607 0.0606 0.0605 \n",
            "\n",
            "[TRAIN] Epoch[1](914/1214); Loss: 0.063500; Backpropagation: 0.6193 sec; Batch: 4.4982 sec\n",
            "0.1338 0.0846 0.0713 0.0640 0.0607 0.0588 0.0569 0.0557 0.0549 0.0544 0.0540 0.0537 0.0534 0.0533 0.0533 0.0532 \n",
            "\n",
            "[TRAIN] Epoch[1](915/1214); Loss: 0.074731; Backpropagation: 0.6101 sec; Batch: 4.4854 sec\n",
            "0.1368 0.0998 0.0844 0.0769 0.0726 0.0701 0.0683 0.0671 0.0662 0.0657 0.0653 0.0650 0.0647 0.0645 0.0643 0.0641 \n",
            "\n",
            "[TRAIN] Epoch[1](916/1214); Loss: 0.057662; Backpropagation: 0.6167 sec; Batch: 4.4893 sec\n",
            "0.1208 0.0767 0.0631 0.0575 0.0548 0.0530 0.0515 0.0508 0.0502 0.0499 0.0495 0.0493 0.0490 0.0489 0.0488 0.0489 \n",
            "\n",
            "[TRAIN] Epoch[1](917/1214); Loss: 0.064243; Backpropagation: 0.6147 sec; Batch: 4.4916 sec\n",
            "0.1330 0.0865 0.0723 0.0655 0.0614 0.0586 0.0573 0.0565 0.0557 0.0553 0.0548 0.0545 0.0543 0.0542 0.0541 0.0541 \n",
            "\n",
            "[TRAIN] Epoch[1](918/1214); Loss: 0.060192; Backpropagation: 0.6128 sec; Batch: 4.4901 sec\n",
            "0.1231 0.0774 0.0672 0.0617 0.0582 0.0561 0.0546 0.0534 0.0527 0.0520 0.0516 0.0513 0.0511 0.0510 0.0509 0.0508 \n",
            "\n",
            "[TRAIN] Epoch[1](919/1214); Loss: 0.059723; Backpropagation: 0.6112 sec; Batch: 4.4876 sec\n",
            "0.1341 0.0877 0.0702 0.0625 0.0574 0.0540 0.0520 0.0507 0.0498 0.0491 0.0487 0.0482 0.0480 0.0478 0.0477 0.0476 \n",
            "\n",
            "[TRAIN] Epoch[1](920/1214); Loss: 0.064123; Backpropagation: 0.6180 sec; Batch: 4.4928 sec\n",
            "0.1327 0.0835 0.0696 0.0646 0.0610 0.0592 0.0576 0.0569 0.0562 0.0557 0.0554 0.0550 0.0548 0.0547 0.0546 0.0545 \n",
            "\n",
            "[TRAIN] Epoch[1](921/1214); Loss: 0.058185; Backpropagation: 0.6160 sec; Batch: 4.4910 sec\n",
            "0.1066 0.0783 0.0654 0.0606 0.0567 0.0546 0.0533 0.0525 0.0516 0.0510 0.0506 0.0504 0.0501 0.0499 0.0497 0.0497 \n",
            "\n",
            "[TRAIN] Epoch[1](922/1214); Loss: 0.066054; Backpropagation: 0.6156 sec; Batch: 4.4884 sec\n",
            "0.1306 0.0854 0.0739 0.0680 0.0647 0.0622 0.0606 0.0592 0.0583 0.0575 0.0569 0.0564 0.0561 0.0559 0.0557 0.0556 \n",
            "\n",
            "[TRAIN] Epoch[1](923/1214); Loss: 0.065049; Backpropagation: 0.6200 sec; Batch: 4.5013 sec\n",
            "0.1252 0.0813 0.0708 0.0658 0.0624 0.0605 0.0594 0.0587 0.0581 0.0577 0.0575 0.0571 0.0569 0.0566 0.0565 0.0564 \n",
            "\n",
            "[TRAIN] Epoch[1](924/1214); Loss: 0.071278; Backpropagation: 0.6143 sec; Batch: 4.4926 sec\n",
            "0.1277 0.0891 0.0782 0.0726 0.0696 0.0675 0.0665 0.0654 0.0644 0.0638 0.0631 0.0629 0.0626 0.0625 0.0623 0.0622 \n",
            "\n",
            "[TRAIN] Epoch[1](925/1214); Loss: 0.072276; Backpropagation: 0.6115 sec; Batch: 4.4888 sec\n",
            "0.1348 0.0982 0.0844 0.0756 0.0709 0.0676 0.0660 0.0642 0.0635 0.0628 0.0623 0.0618 0.0615 0.0611 0.0610 0.0607 \n",
            "\n",
            "[TRAIN] Epoch[1](926/1214); Loss: 0.079435; Backpropagation: 0.6105 sec; Batch: 4.5013 sec\n",
            "0.1328 0.1000 0.0891 0.0823 0.0783 0.0757 0.0742 0.0731 0.0721 0.0715 0.0710 0.0706 0.0703 0.0701 0.0699 0.0698 \n",
            "\n",
            "[TRAIN] Epoch[1](927/1214); Loss: 0.063452; Backpropagation: 0.6137 sec; Batch: 4.4847 sec\n",
            "0.1262 0.0823 0.0725 0.0652 0.0619 0.0590 0.0577 0.0564 0.0556 0.0549 0.0545 0.0542 0.0539 0.0537 0.0536 0.0535 \n",
            "\n",
            "[TRAIN] Epoch[1](928/1214); Loss: 0.063394; Backpropagation: 0.6206 sec; Batch: 4.5017 sec\n",
            "0.1277 0.0890 0.0758 0.0666 0.0628 0.0594 0.0575 0.0553 0.0546 0.0533 0.0529 0.0523 0.0521 0.0517 0.0517 0.0515 \n",
            "\n",
            "[TRAIN] Epoch[1](929/1214); Loss: 0.067676; Backpropagation: 0.6119 sec; Batch: 4.4908 sec\n",
            "0.1326 0.0946 0.0797 0.0703 0.0660 0.0629 0.0604 0.0591 0.0583 0.0578 0.0574 0.0570 0.0568 0.0567 0.0566 0.0565 \n",
            "\n",
            "[TRAIN] Epoch[1](930/1214); Loss: 0.067052; Backpropagation: 0.6220 sec; Batch: 4.4983 sec\n",
            "0.1356 0.0933 0.0786 0.0701 0.0650 0.0619 0.0597 0.0582 0.0573 0.0568 0.0565 0.0564 0.0561 0.0560 0.0558 0.0558 \n",
            "\n",
            "[TRAIN] Epoch[1](931/1214); Loss: 0.067633; Backpropagation: 0.6123 sec; Batch: 4.4902 sec\n",
            "0.1365 0.0902 0.0767 0.0693 0.0653 0.0627 0.0609 0.0598 0.0589 0.0583 0.0579 0.0575 0.0573 0.0571 0.0569 0.0569 \n",
            "\n",
            "[TRAIN] Epoch[1](932/1214); Loss: 0.068991; Backpropagation: 0.6163 sec; Batch: 4.4905 sec\n",
            "0.1286 0.0903 0.0786 0.0706 0.0665 0.0644 0.0628 0.0619 0.0612 0.0606 0.0602 0.0599 0.0597 0.0596 0.0594 0.0595 \n",
            "\n",
            "[TRAIN] Epoch[1](933/1214); Loss: 0.067100; Backpropagation: 0.6204 sec; Batch: 4.4926 sec\n",
            "0.1232 0.0904 0.0756 0.0691 0.0660 0.0634 0.0618 0.0605 0.0597 0.0589 0.0585 0.0579 0.0576 0.0573 0.0570 0.0568 \n",
            "\n",
            "[TRAIN] Epoch[1](934/1214); Loss: 0.060677; Backpropagation: 0.6142 sec; Batch: 4.4999 sec\n",
            "0.1240 0.0857 0.0710 0.0635 0.0587 0.0557 0.0538 0.0526 0.0520 0.0512 0.0508 0.0506 0.0504 0.0504 0.0502 0.0503 \n",
            "\n",
            "[TRAIN] Epoch[1](935/1214); Loss: 0.068325; Backpropagation: 0.6175 sec; Batch: 4.4927 sec\n",
            "0.1301 0.0913 0.0777 0.0713 0.0672 0.0642 0.0625 0.0612 0.0602 0.0593 0.0590 0.0584 0.0580 0.0577 0.0576 0.0575 \n",
            "\n",
            "[TRAIN] Epoch[1](936/1214); Loss: 0.060505; Backpropagation: 0.6144 sec; Batch: 4.4905 sec\n",
            "0.1377 0.0887 0.0744 0.0642 0.0586 0.0550 0.0530 0.0510 0.0497 0.0491 0.0485 0.0480 0.0477 0.0477 0.0475 0.0474 \n",
            "\n",
            "[TRAIN] Epoch[1](937/1214); Loss: 0.066712; Backpropagation: 0.6175 sec; Batch: 4.4897 sec\n",
            "0.1381 0.0927 0.0775 0.0690 0.0633 0.0610 0.0595 0.0583 0.0577 0.0568 0.0565 0.0558 0.0555 0.0553 0.0552 0.0550 \n",
            "\n",
            "[TRAIN] Epoch[1](938/1214); Loss: 0.059448; Backpropagation: 0.6131 sec; Batch: 4.4906 sec\n",
            "0.1212 0.0820 0.0703 0.0640 0.0581 0.0550 0.0531 0.0517 0.0508 0.0503 0.0496 0.0493 0.0490 0.0490 0.0489 0.0489 \n",
            "\n",
            "[TRAIN] Epoch[1](939/1214); Loss: 0.069434; Backpropagation: 0.6138 sec; Batch: 4.4868 sec\n",
            "0.1372 0.0940 0.0798 0.0710 0.0666 0.0642 0.0623 0.0612 0.0606 0.0601 0.0596 0.0593 0.0590 0.0589 0.0587 0.0585 \n",
            "\n",
            "[TRAIN] Epoch[1](940/1214); Loss: 0.068987; Backpropagation: 0.6154 sec; Batch: 4.4893 sec\n",
            "0.1224 0.0918 0.0793 0.0720 0.0679 0.0652 0.0634 0.0624 0.0614 0.0607 0.0602 0.0598 0.0596 0.0593 0.0592 0.0591 \n",
            "\n",
            "[TRAIN] Epoch[1](941/1214); Loss: 0.062715; Backpropagation: 0.6095 sec; Batch: 4.4856 sec\n",
            "0.1204 0.0850 0.0706 0.0633 0.0605 0.0581 0.0568 0.0561 0.0552 0.0547 0.0542 0.0541 0.0538 0.0536 0.0535 0.0536 \n",
            "\n",
            "[TRAIN] Epoch[1](942/1214); Loss: 0.069939; Backpropagation: 0.6190 sec; Batch: 4.5014 sec\n",
            "0.1279 0.0935 0.0817 0.0728 0.0694 0.0663 0.0641 0.0627 0.0619 0.0611 0.0603 0.0599 0.0596 0.0594 0.0593 0.0592 \n",
            "\n",
            "[TRAIN] Epoch[1](943/1214); Loss: 0.068099; Backpropagation: 0.6179 sec; Batch: 4.4948 sec\n",
            "0.1269 0.0949 0.0782 0.0714 0.0667 0.0636 0.0620 0.0609 0.0599 0.0591 0.0584 0.0579 0.0577 0.0575 0.0573 0.0570 \n",
            "\n",
            "[TRAIN] Epoch[1](944/1214); Loss: 0.058108; Backpropagation: 0.6127 sec; Batch: 4.4898 sec\n",
            "0.1095 0.0790 0.0676 0.0611 0.0567 0.0547 0.0530 0.0516 0.0506 0.0502 0.0499 0.0495 0.0493 0.0491 0.0489 0.0488 \n",
            "\n",
            "[TRAIN] Epoch[1](945/1214); Loss: 0.066523; Backpropagation: 0.6074 sec; Batch: 4.4832 sec\n",
            "0.1319 0.0919 0.0774 0.0691 0.0650 0.0622 0.0597 0.0583 0.0577 0.0569 0.0564 0.0559 0.0557 0.0554 0.0554 0.0553 \n",
            "\n",
            "[TRAIN] Epoch[1](946/1214); Loss: 0.071411; Backpropagation: 0.6114 sec; Batch: 4.4882 sec\n",
            "0.1355 0.0929 0.0799 0.0732 0.0694 0.0669 0.0652 0.0637 0.0631 0.0625 0.0621 0.0619 0.0618 0.0615 0.0615 0.0616 \n",
            "\n",
            "[TRAIN] Epoch[1](947/1214); Loss: 0.064674; Backpropagation: 0.6190 sec; Batch: 4.4922 sec\n",
            "0.1211 0.0865 0.0723 0.0675 0.0632 0.0606 0.0590 0.0577 0.0571 0.0564 0.0560 0.0557 0.0555 0.0554 0.0553 0.0553 \n",
            "\n",
            "[TRAIN] Epoch[1](948/1214); Loss: 0.072986; Backpropagation: 0.6158 sec; Batch: 4.4902 sec\n",
            "0.1391 0.0947 0.0828 0.0767 0.0727 0.0686 0.0669 0.0652 0.0642 0.0635 0.0630 0.0626 0.0622 0.0619 0.0619 0.0618 \n",
            "\n",
            "[TRAIN] Epoch[1](949/1214); Loss: 0.055110; Backpropagation: 0.6137 sec; Batch: 4.4903 sec\n",
            "0.1313 0.0759 0.0620 0.0555 0.0510 0.0486 0.0479 0.0470 0.0463 0.0458 0.0453 0.0452 0.0451 0.0450 0.0450 0.0450 \n",
            "\n",
            "[TRAIN] Epoch[1](950/1214); Loss: 0.063224; Backpropagation: 0.6157 sec; Batch: 4.4883 sec\n",
            "0.1248 0.0858 0.0733 0.0660 0.0616 0.0591 0.0569 0.0557 0.0550 0.0545 0.0539 0.0535 0.0532 0.0530 0.0528 0.0527 \n",
            "\n",
            "[TRAIN] Epoch[1](951/1214); Loss: 0.062434; Backpropagation: 0.6102 sec; Batch: 4.4902 sec\n",
            "0.1271 0.0809 0.0696 0.0636 0.0604 0.0581 0.0564 0.0554 0.0546 0.0542 0.0537 0.0533 0.0531 0.0530 0.0528 0.0528 \n",
            "\n",
            "[TRAIN] Epoch[1](952/1214); Loss: 0.065219; Backpropagation: 0.6187 sec; Batch: 4.5005 sec\n",
            "0.1427 0.0848 0.0724 0.0658 0.0617 0.0597 0.0580 0.0574 0.0563 0.0559 0.0553 0.0551 0.0548 0.0547 0.0545 0.0545 \n",
            "\n",
            "[TRAIN] Epoch[1](953/1214); Loss: 0.070826; Backpropagation: 0.6103 sec; Batch: 4.4880 sec\n",
            "0.1488 0.0961 0.0820 0.0741 0.0684 0.0661 0.0636 0.0622 0.0609 0.0602 0.0594 0.0590 0.0585 0.0582 0.0579 0.0578 \n",
            "\n",
            "[TRAIN] Epoch[1](954/1214); Loss: 0.070560; Backpropagation: 0.6244 sec; Batch: 4.5022 sec\n",
            "0.1363 0.0945 0.0819 0.0746 0.0700 0.0669 0.0650 0.0634 0.0620 0.0611 0.0601 0.0594 0.0590 0.0586 0.0583 0.0581 \n",
            "\n",
            "[TRAIN] Epoch[1](955/1214); Loss: 0.072027; Backpropagation: 0.6145 sec; Batch: 4.4900 sec\n",
            "0.1401 0.0975 0.0832 0.0756 0.0697 0.0670 0.0647 0.0639 0.0627 0.0623 0.0616 0.0614 0.0610 0.0608 0.0604 0.0604 \n",
            "\n",
            "[TRAIN] Epoch[1](956/1214); Loss: 0.075182; Backpropagation: 0.6133 sec; Batch: 4.4836 sec\n",
            "0.1374 0.1025 0.0877 0.0796 0.0750 0.0725 0.0697 0.0679 0.0664 0.0654 0.0643 0.0638 0.0632 0.0629 0.0625 0.0623 \n",
            "\n",
            "[TRAIN] Epoch[1](957/1214); Loss: 0.067061; Backpropagation: 0.6165 sec; Batch: 4.4881 sec\n",
            "0.1248 0.0887 0.0772 0.0700 0.0664 0.0633 0.0614 0.0602 0.0591 0.0584 0.0579 0.0576 0.0572 0.0571 0.0569 0.0567 \n",
            "\n",
            "[TRAIN] Epoch[1](958/1214); Loss: 0.061348; Backpropagation: 0.6148 sec; Batch: 4.4931 sec\n",
            "0.1262 0.0875 0.0749 0.0645 0.0594 0.0567 0.0542 0.0532 0.0519 0.0517 0.0509 0.0508 0.0502 0.0502 0.0497 0.0496 \n",
            "\n",
            "[TRAIN] Epoch[1](959/1214); Loss: 0.064003; Backpropagation: 0.6175 sec; Batch: 4.4928 sec\n",
            "0.1210 0.0861 0.0771 0.0683 0.0621 0.0592 0.0579 0.0568 0.0561 0.0553 0.0548 0.0543 0.0540 0.0538 0.0537 0.0536 \n",
            "\n",
            "[TRAIN] Epoch[1](960/1214); Loss: 0.069316; Backpropagation: 0.6134 sec; Batch: 4.4865 sec\n",
            "0.1306 0.0909 0.0790 0.0723 0.0672 0.0650 0.0636 0.0619 0.0612 0.0606 0.0601 0.0597 0.0594 0.0594 0.0591 0.0590 \n",
            "\n",
            "[TRAIN] Epoch[1](961/1214); Loss: 0.064505; Backpropagation: 0.6132 sec; Batch: 4.4806 sec\n",
            "0.1196 0.0849 0.0740 0.0662 0.0632 0.0606 0.0591 0.0583 0.0572 0.0564 0.0558 0.0556 0.0553 0.0554 0.0552 0.0552 \n",
            "\n",
            "[TRAIN] Epoch[1](962/1214); Loss: 0.060196; Backpropagation: 0.6174 sec; Batch: 4.4858 sec\n",
            "0.1377 0.0840 0.0690 0.0612 0.0579 0.0546 0.0528 0.0515 0.0504 0.0500 0.0497 0.0492 0.0489 0.0488 0.0487 0.0487 \n",
            "\n",
            "[TRAIN] Epoch[1](963/1214); Loss: 0.066372; Backpropagation: 0.6077 sec; Batch: 4.4793 sec\n",
            "0.1203 0.0907 0.0780 0.0704 0.0656 0.0631 0.0611 0.0595 0.0584 0.0577 0.0571 0.0565 0.0563 0.0558 0.0558 0.0556 \n",
            "\n",
            "[TRAIN] Epoch[1](964/1214); Loss: 0.058743; Backpropagation: 0.6183 sec; Batch: 4.4995 sec\n",
            "0.1285 0.0800 0.0711 0.0629 0.0570 0.0541 0.0516 0.0502 0.0494 0.0487 0.0483 0.0480 0.0478 0.0475 0.0476 0.0473 \n",
            "\n",
            "[TRAIN] Epoch[1](965/1214); Loss: 0.064415; Backpropagation: 0.6196 sec; Batch: 4.4986 sec\n",
            "0.1125 0.0859 0.0746 0.0682 0.0641 0.0612 0.0591 0.0578 0.0572 0.0567 0.0562 0.0559 0.0556 0.0554 0.0552 0.0551 \n",
            "\n",
            "[TRAIN] Epoch[1](966/1214); Loss: 0.064918; Backpropagation: 0.6261 sec; Batch: 4.5084 sec\n",
            "0.1265 0.0854 0.0740 0.0673 0.0637 0.0608 0.0590 0.0577 0.0569 0.0562 0.0558 0.0555 0.0552 0.0550 0.0549 0.0548 \n",
            "\n",
            "[TRAIN] Epoch[1](967/1214); Loss: 0.058853; Backpropagation: 0.6151 sec; Batch: 4.4868 sec\n",
            "0.1227 0.0802 0.0708 0.0626 0.0578 0.0545 0.0523 0.0508 0.0500 0.0495 0.0491 0.0486 0.0485 0.0482 0.0481 0.0480 \n",
            "\n",
            "[TRAIN] Epoch[1](968/1214); Loss: 0.067067; Backpropagation: 0.6189 sec; Batch: 4.4913 sec\n",
            "0.1273 0.0874 0.0741 0.0689 0.0654 0.0633 0.0615 0.0604 0.0593 0.0588 0.0583 0.0581 0.0578 0.0577 0.0575 0.0574 \n",
            "\n",
            "[TRAIN] Epoch[1](969/1214); Loss: 0.074752; Backpropagation: 0.6187 sec; Batch: 4.4949 sec\n",
            "0.1304 0.0982 0.0850 0.0773 0.0732 0.0707 0.0686 0.0675 0.0668 0.0665 0.0660 0.0657 0.0653 0.0650 0.0649 0.0648 \n",
            "\n",
            "[TRAIN] Epoch[1](970/1214); Loss: 0.064655; Backpropagation: 0.6167 sec; Batch: 4.4903 sec\n",
            "0.1274 0.0840 0.0717 0.0656 0.0623 0.0601 0.0588 0.0577 0.0568 0.0564 0.0560 0.0558 0.0557 0.0555 0.0554 0.0554 \n",
            "\n",
            "[TRAIN] Epoch[1](971/1214); Loss: 0.072228; Backpropagation: 0.6200 sec; Batch: 4.4982 sec\n",
            "0.1418 0.0993 0.0842 0.0758 0.0700 0.0666 0.0645 0.0632 0.0626 0.0621 0.0617 0.0612 0.0609 0.0608 0.0605 0.0604 \n",
            "\n",
            "[TRAIN] Epoch[1](972/1214); Loss: 0.073111; Backpropagation: 0.6133 sec; Batch: 4.4869 sec\n",
            "0.1381 0.0933 0.0822 0.0752 0.0704 0.0681 0.0668 0.0661 0.0653 0.0645 0.0640 0.0636 0.0635 0.0631 0.0629 0.0626 \n",
            "\n",
            "[TRAIN] Epoch[1](973/1214); Loss: 0.061184; Backpropagation: 0.6109 sec; Batch: 4.4852 sec\n",
            "0.1245 0.0838 0.0699 0.0636 0.0599 0.0567 0.0547 0.0535 0.0529 0.0522 0.0518 0.0515 0.0512 0.0511 0.0508 0.0508 \n",
            "\n",
            "[TRAIN] Epoch[1](974/1214); Loss: 0.084237; Backpropagation: 0.6165 sec; Batch: 4.4897 sec\n",
            "0.1325 0.1070 0.0948 0.0879 0.0832 0.0809 0.0792 0.0781 0.0772 0.0765 0.0758 0.0755 0.0750 0.0749 0.0746 0.0746 \n",
            "\n",
            "[TRAIN] Epoch[1](975/1214); Loss: 0.053286; Backpropagation: 0.6124 sec; Batch: 4.4869 sec\n",
            "0.1223 0.0724 0.0595 0.0539 0.0506 0.0482 0.0469 0.0458 0.0452 0.0448 0.0445 0.0440 0.0439 0.0436 0.0435 0.0435 \n",
            "\n",
            "[TRAIN] Epoch[1](976/1214); Loss: 0.070849; Backpropagation: 0.6173 sec; Batch: 4.4906 sec\n",
            "0.1279 0.0917 0.0789 0.0737 0.0693 0.0664 0.0653 0.0641 0.0634 0.0627 0.0622 0.0619 0.0616 0.0615 0.0615 0.0614 \n",
            "\n",
            "[TRAIN] Epoch[1](977/1214); Loss: 0.064601; Backpropagation: 0.6129 sec; Batch: 4.4969 sec\n",
            "0.1223 0.0872 0.0731 0.0676 0.0629 0.0602 0.0585 0.0575 0.0568 0.0562 0.0557 0.0554 0.0553 0.0550 0.0549 0.0548 \n",
            "\n",
            "[TRAIN] Epoch[1](978/1214); Loss: 0.064797; Backpropagation: 0.6151 sec; Batch: 4.4897 sec\n",
            "0.1252 0.0922 0.0765 0.0680 0.0632 0.0594 0.0579 0.0570 0.0561 0.0552 0.0549 0.0547 0.0544 0.0542 0.0540 0.0540 \n",
            "\n",
            "[TRAIN] Epoch[1](979/1214); Loss: 0.059377; Backpropagation: 0.6211 sec; Batch: 4.4999 sec\n",
            "0.1329 0.0914 0.0712 0.0626 0.0569 0.0535 0.0511 0.0501 0.0492 0.0485 0.0479 0.0474 0.0471 0.0469 0.0468 0.0467 \n",
            "\n",
            "[TRAIN] Epoch[1](980/1214); Loss: 0.072372; Backpropagation: 0.6100 sec; Batch: 4.4870 sec\n",
            "0.1335 0.0932 0.0789 0.0737 0.0698 0.0677 0.0663 0.0653 0.0647 0.0641 0.0638 0.0635 0.0634 0.0633 0.0632 0.0633 \n",
            "\n",
            "[TRAIN] Epoch[1](981/1214); Loss: 0.070897; Backpropagation: 0.6134 sec; Batch: 4.4933 sec\n",
            "0.1251 0.0945 0.0813 0.0739 0.0702 0.0670 0.0651 0.0639 0.0631 0.0625 0.0619 0.0616 0.0613 0.0611 0.0610 0.0609 \n",
            "\n",
            "[TRAIN] Epoch[1](982/1214); Loss: 0.062600; Backpropagation: 0.6083 sec; Batch: 4.4791 sec\n",
            "0.1318 0.0841 0.0714 0.0647 0.0604 0.0575 0.0556 0.0546 0.0538 0.0533 0.0529 0.0527 0.0524 0.0523 0.0521 0.0520 \n",
            "\n",
            "[TRAIN] Epoch[1](983/1214); Loss: 0.068795; Backpropagation: 0.6193 sec; Batch: 4.4931 sec\n",
            "0.1316 0.0948 0.0794 0.0720 0.0673 0.0646 0.0622 0.0608 0.0597 0.0592 0.0587 0.0585 0.0582 0.0581 0.0580 0.0578 \n",
            "\n",
            "[TRAIN] Epoch[1](984/1214); Loss: 0.074203; Backpropagation: 0.6182 sec; Batch: 4.4985 sec\n",
            "0.1406 0.0983 0.0827 0.0778 0.0728 0.0702 0.0680 0.0668 0.0655 0.0649 0.0641 0.0637 0.0634 0.0631 0.0628 0.0626 \n",
            "\n",
            "[TRAIN] Epoch[1](985/1214); Loss: 0.058722; Backpropagation: 0.6114 sec; Batch: 4.4861 sec\n",
            "0.1202 0.0797 0.0656 0.0597 0.0561 0.0541 0.0527 0.0516 0.0509 0.0506 0.0502 0.0500 0.0498 0.0495 0.0495 0.0494 \n",
            "\n",
            "[TRAIN] Epoch[1](986/1214); Loss: 0.076843; Backpropagation: 0.6135 sec; Batch: 4.4875 sec\n",
            "0.1363 0.0988 0.0856 0.0790 0.0750 0.0727 0.0711 0.0699 0.0690 0.0683 0.0678 0.0675 0.0673 0.0671 0.0670 0.0669 \n",
            "\n",
            "[TRAIN] Epoch[1](987/1214); Loss: 0.066893; Backpropagation: 0.6107 sec; Batch: 4.4895 sec\n",
            "0.1248 0.0854 0.0736 0.0681 0.0645 0.0627 0.0614 0.0605 0.0598 0.0592 0.0588 0.0586 0.0584 0.0583 0.0582 0.0581 \n",
            "\n",
            "[TRAIN] Epoch[1](988/1214); Loss: 0.065220; Backpropagation: 0.6205 sec; Batch: 4.4960 sec\n",
            "0.1182 0.0838 0.0716 0.0656 0.0629 0.0611 0.0598 0.0591 0.0586 0.0581 0.0578 0.0576 0.0575 0.0573 0.0573 0.0572 \n",
            "\n",
            "[TRAIN] Epoch[1](989/1214); Loss: 0.069737; Backpropagation: 0.6140 sec; Batch: 4.4889 sec\n",
            "0.1266 0.0899 0.0755 0.0709 0.0675 0.0658 0.0642 0.0634 0.0625 0.0622 0.0618 0.0616 0.0613 0.0610 0.0609 0.0608 \n",
            "\n",
            "[TRAIN] Epoch[1](990/1214); Loss: 0.064883; Backpropagation: 0.6158 sec; Batch: 4.4877 sec\n",
            "0.1304 0.0886 0.0731 0.0668 0.0626 0.0599 0.0580 0.0569 0.0564 0.0560 0.0555 0.0551 0.0549 0.0548 0.0546 0.0545 \n",
            "\n",
            "[TRAIN] Epoch[1](991/1214); Loss: 0.059141; Backpropagation: 0.6119 sec; Batch: 4.4827 sec\n",
            "0.1271 0.0760 0.0647 0.0595 0.0562 0.0542 0.0526 0.0517 0.0512 0.0509 0.0506 0.0504 0.0503 0.0503 0.0503 0.0503 \n",
            "\n",
            "[TRAIN] Epoch[1](992/1214); Loss: 0.060365; Backpropagation: 0.6214 sec; Batch: 4.5032 sec\n",
            "0.1278 0.0837 0.0707 0.0632 0.0588 0.0556 0.0537 0.0525 0.0516 0.0508 0.0503 0.0498 0.0496 0.0493 0.0493 0.0491 \n",
            "\n",
            "[TRAIN] Epoch[1](993/1214); Loss: 0.061129; Backpropagation: 0.6163 sec; Batch: 4.4909 sec\n",
            "0.1172 0.0860 0.0710 0.0638 0.0595 0.0568 0.0552 0.0540 0.0533 0.0525 0.0521 0.0518 0.0515 0.0513 0.0512 0.0511 \n",
            "\n",
            "[TRAIN] Epoch[1](994/1214); Loss: 0.064211; Backpropagation: 0.6180 sec; Batch: 4.4899 sec\n",
            "0.1245 0.0847 0.0735 0.0658 0.0614 0.0593 0.0581 0.0571 0.0565 0.0560 0.0556 0.0552 0.0551 0.0550 0.0548 0.0547 \n",
            "\n",
            "[TRAIN] Epoch[1](995/1214); Loss: 0.062176; Backpropagation: 0.6157 sec; Batch: 4.4962 sec\n",
            "0.1253 0.0811 0.0677 0.0624 0.0596 0.0576 0.0561 0.0552 0.0545 0.0540 0.0538 0.0536 0.0535 0.0535 0.0535 0.0534 \n",
            "\n",
            "[TRAIN] Epoch[1](996/1214); Loss: 0.058732; Backpropagation: 0.6176 sec; Batch: 4.4878 sec\n",
            "0.1121 0.0784 0.0667 0.0610 0.0573 0.0550 0.0535 0.0522 0.0515 0.0509 0.0506 0.0504 0.0502 0.0501 0.0499 0.0500 \n",
            "\n",
            "[TRAIN] Epoch[1](997/1214); Loss: 0.061901; Backpropagation: 0.6245 sec; Batch: 4.4997 sec\n",
            "0.1172 0.0880 0.0727 0.0647 0.0601 0.0574 0.0558 0.0546 0.0537 0.0532 0.0528 0.0525 0.0522 0.0520 0.0518 0.0517 \n",
            "\n",
            "[TRAIN] Epoch[1](998/1214); Loss: 0.063719; Backpropagation: 0.6118 sec; Batch: 4.4885 sec\n",
            "0.1264 0.0832 0.0696 0.0646 0.0612 0.0591 0.0577 0.0567 0.0562 0.0555 0.0552 0.0550 0.0549 0.0548 0.0547 0.0547 \n",
            "\n",
            "[TRAIN] Epoch[1](999/1214); Loss: 0.072609; Backpropagation: 0.6124 sec; Batch: 4.4880 sec\n",
            "0.1419 0.0969 0.0823 0.0742 0.0698 0.0668 0.0656 0.0643 0.0635 0.0630 0.0626 0.0623 0.0622 0.0621 0.0620 0.0620 \n",
            "\n",
            "[TRAIN] Epoch[1](1000/1214); Loss: 0.058190; Backpropagation: 0.6182 sec; Batch: 4.5007 sec\n",
            "0.1083 0.0779 0.0657 0.0607 0.0570 0.0547 0.0528 0.0520 0.0514 0.0508 0.0504 0.0501 0.0499 0.0499 0.0497 0.0497 \n",
            "\n",
            "[TRAIN] Epoch[1](1001/1214); Loss: 0.055897; Backpropagation: 0.6087 sec; Batch: 4.4858 sec\n",
            "0.1100 0.0730 0.0610 0.0562 0.0533 0.0518 0.0506 0.0497 0.0493 0.0490 0.0487 0.0485 0.0484 0.0483 0.0483 0.0483 \n",
            "\n",
            "[TRAIN] Epoch[1](1002/1214); Loss: 0.055081; Backpropagation: 0.6137 sec; Batch: 4.4898 sec\n",
            "0.1085 0.0723 0.0614 0.0569 0.0529 0.0509 0.0495 0.0489 0.0482 0.0478 0.0476 0.0474 0.0473 0.0472 0.0472 0.0471 \n",
            "\n",
            "[TRAIN] Epoch[1](1003/1214); Loss: 0.062460; Backpropagation: 0.6173 sec; Batch: 4.5027 sec\n",
            "0.1202 0.0788 0.0676 0.0623 0.0598 0.0579 0.0568 0.0562 0.0558 0.0554 0.0552 0.0549 0.0547 0.0547 0.0546 0.0545 \n",
            "\n",
            "[TRAIN] Epoch[1](1004/1214); Loss: 0.064840; Backpropagation: 0.6203 sec; Batch: 4.4895 sec\n",
            "0.1283 0.0850 0.0729 0.0663 0.0627 0.0602 0.0587 0.0575 0.0568 0.0562 0.0560 0.0557 0.0555 0.0553 0.0552 0.0551 \n",
            "\n",
            "[TRAIN] Epoch[1](1005/1214); Loss: 0.057326; Backpropagation: 0.6231 sec; Batch: 4.4979 sec\n",
            "0.1158 0.0756 0.0633 0.0573 0.0541 0.0525 0.0515 0.0508 0.0503 0.0500 0.0497 0.0494 0.0493 0.0493 0.0493 0.0492 \n",
            "\n",
            "[TRAIN] Epoch[1](1006/1214); Loss: 0.055445; Backpropagation: 0.6116 sec; Batch: 4.4945 sec\n",
            "0.1264 0.0747 0.0633 0.0556 0.0519 0.0496 0.0483 0.0476 0.0472 0.0466 0.0463 0.0461 0.0460 0.0459 0.0459 0.0458 \n",
            "\n",
            "[TRAIN] Epoch[1](1007/1214); Loss: 0.064755; Backpropagation: 0.6198 sec; Batch: 4.4914 sec\n",
            "0.1282 0.0849 0.0718 0.0658 0.0618 0.0597 0.0582 0.0574 0.0567 0.0564 0.0561 0.0560 0.0558 0.0558 0.0558 0.0556 \n",
            "\n",
            "[TRAIN] Epoch[1](1008/1214); Loss: 0.069489; Backpropagation: 0.6184 sec; Batch: 4.4931 sec\n",
            "0.1173 0.0855 0.0757 0.0704 0.0677 0.0662 0.0649 0.0638 0.0633 0.0630 0.0627 0.0625 0.0623 0.0622 0.0621 0.0622 \n",
            "\n",
            "[TRAIN] Epoch[1](1009/1214); Loss: 0.066308; Backpropagation: 0.6153 sec; Batch: 4.4934 sec\n",
            "0.1187 0.0845 0.0727 0.0665 0.0635 0.0621 0.0612 0.0604 0.0598 0.0593 0.0590 0.0589 0.0587 0.0586 0.0586 0.0586 \n",
            "\n",
            "[TRAIN] Epoch[1](1010/1214); Loss: 0.058643; Backpropagation: 0.6197 sec; Batch: 4.4941 sec\n",
            "0.1148 0.0746 0.0656 0.0598 0.0564 0.0545 0.0532 0.0524 0.0518 0.0513 0.0510 0.0508 0.0507 0.0506 0.0504 0.0504 \n",
            "\n",
            "[TRAIN] Epoch[1](1011/1214); Loss: 0.056942; Backpropagation: 0.6159 sec; Batch: 4.4969 sec\n",
            "0.1148 0.0715 0.0629 0.0568 0.0540 0.0525 0.0516 0.0509 0.0502 0.0498 0.0496 0.0494 0.0493 0.0493 0.0492 0.0492 \n",
            "\n",
            "[TRAIN] Epoch[1](1012/1214); Loss: 0.068731; Backpropagation: 0.6230 sec; Batch: 4.4956 sec\n",
            "0.1211 0.0882 0.0774 0.0713 0.0676 0.0652 0.0636 0.0625 0.0616 0.0610 0.0605 0.0602 0.0601 0.0599 0.0597 0.0597 \n",
            "\n",
            "[TRAIN] Epoch[1](1013/1214); Loss: 0.062449; Backpropagation: 0.6159 sec; Batch: 4.4927 sec\n",
            "0.1255 0.0837 0.0721 0.0642 0.0603 0.0574 0.0558 0.0549 0.0543 0.0538 0.0534 0.0531 0.0529 0.0527 0.0526 0.0525 \n",
            "\n",
            "[TRAIN] Epoch[1](1014/1214); Loss: 0.061118; Backpropagation: 0.6187 sec; Batch: 4.4911 sec\n",
            "0.1137 0.0772 0.0676 0.0622 0.0590 0.0571 0.0557 0.0551 0.0545 0.0541 0.0539 0.0537 0.0536 0.0535 0.0536 0.0535 \n",
            "\n",
            "[TRAIN] Epoch[1](1015/1214); Loss: 0.055716; Backpropagation: 0.6188 sec; Batch: 4.4970 sec\n",
            "0.1144 0.0755 0.0625 0.0566 0.0531 0.0510 0.0498 0.0491 0.0485 0.0480 0.0476 0.0473 0.0471 0.0470 0.0468 0.0468 \n",
            "\n",
            "[TRAIN] Epoch[1](1016/1214); Loss: 0.085502; Backpropagation: 0.6082 sec; Batch: 4.4837 sec\n",
            "0.1361 0.1038 0.0935 0.0874 0.0840 0.0819 0.0807 0.0796 0.0788 0.0782 0.0779 0.0776 0.0774 0.0772 0.0770 0.0768 \n",
            "\n",
            "[TRAIN] Epoch[1](1017/1214); Loss: 0.060714; Backpropagation: 0.6108 sec; Batch: 4.4839 sec\n",
            "0.1332 0.0819 0.0697 0.0625 0.0581 0.0550 0.0536 0.0526 0.0520 0.0513 0.0508 0.0504 0.0502 0.0501 0.0500 0.0500 \n",
            "\n",
            "[TRAIN] Epoch[1](1018/1214); Loss: 0.062700; Backpropagation: 0.6124 sec; Batch: 4.4817 sec\n",
            "0.1269 0.0838 0.0707 0.0635 0.0601 0.0580 0.0566 0.0555 0.0548 0.0542 0.0539 0.0536 0.0532 0.0530 0.0528 0.0527 \n",
            "\n",
            "[TRAIN] Epoch[1](1019/1214); Loss: 0.064680; Backpropagation: 0.6166 sec; Batch: 4.4932 sec\n",
            "0.1235 0.0827 0.0720 0.0656 0.0624 0.0604 0.0589 0.0583 0.0577 0.0570 0.0565 0.0563 0.0561 0.0559 0.0558 0.0557 \n",
            "\n",
            "[TRAIN] Epoch[1](1020/1214); Loss: 0.062913; Backpropagation: 0.6123 sec; Batch: 4.4897 sec\n",
            "0.1226 0.0827 0.0701 0.0638 0.0609 0.0590 0.0576 0.0563 0.0555 0.0549 0.0545 0.0542 0.0538 0.0538 0.0535 0.0534 \n",
            "\n",
            "[TRAIN] Epoch[1](1021/1214); Loss: 0.066768; Backpropagation: 0.6106 sec; Batch: 4.4843 sec\n",
            "0.1190 0.0866 0.0746 0.0679 0.0649 0.0627 0.0614 0.0606 0.0599 0.0594 0.0590 0.0588 0.0586 0.0584 0.0584 0.0583 \n",
            "\n",
            "[TRAIN] Epoch[1](1022/1214); Loss: 0.061903; Backpropagation: 0.6272 sec; Batch: 4.5079 sec\n",
            "0.1149 0.0751 0.0672 0.0625 0.0597 0.0580 0.0570 0.0561 0.0557 0.0555 0.0552 0.0549 0.0548 0.0548 0.0547 0.0546 \n",
            "\n",
            "[TRAIN] Epoch[1](1023/1214); Loss: 0.065402; Backpropagation: 0.6078 sec; Batch: 4.4920 sec\n",
            "0.1244 0.0894 0.0757 0.0676 0.0633 0.0610 0.0593 0.0581 0.0574 0.0567 0.0562 0.0558 0.0557 0.0555 0.0553 0.0551 \n",
            "\n",
            "[TRAIN] Epoch[1](1024/1214); Loss: 0.067338; Backpropagation: 0.6154 sec; Batch: 4.4895 sec\n",
            "0.1298 0.0872 0.0749 0.0682 0.0647 0.0626 0.0613 0.0604 0.0599 0.0592 0.0588 0.0584 0.0582 0.0581 0.0580 0.0579 \n",
            "\n",
            "[TRAIN] Epoch[1](1025/1214); Loss: 0.070536; Backpropagation: 0.6207 sec; Batch: 4.4969 sec\n",
            "0.1207 0.0874 0.0766 0.0717 0.0685 0.0668 0.0655 0.0649 0.0643 0.0639 0.0636 0.0633 0.0631 0.0629 0.0627 0.0627 \n",
            "\n",
            "[TRAIN] Epoch[1](1026/1214); Loss: 0.066645; Backpropagation: 0.6110 sec; Batch: 4.4858 sec\n",
            "0.1183 0.0862 0.0754 0.0689 0.0652 0.0624 0.0611 0.0603 0.0594 0.0590 0.0588 0.0586 0.0584 0.0582 0.0581 0.0580 \n",
            "\n",
            "[TRAIN] Epoch[1](1027/1214); Loss: 0.061985; Backpropagation: 0.6153 sec; Batch: 4.4859 sec\n",
            "0.1131 0.0806 0.0716 0.0654 0.0612 0.0585 0.0567 0.0554 0.0548 0.0542 0.0538 0.0535 0.0534 0.0533 0.0532 0.0531 \n",
            "\n",
            "[TRAIN] Epoch[1](1028/1214); Loss: 0.060583; Backpropagation: 0.6200 sec; Batch: 4.4841 sec\n",
            "0.1154 0.0764 0.0659 0.0613 0.0584 0.0567 0.0554 0.0547 0.0540 0.0536 0.0533 0.0531 0.0529 0.0528 0.0527 0.0526 \n",
            "\n",
            "[TRAIN] Epoch[1](1029/1214); Loss: 0.063650; Backpropagation: 0.6086 sec; Batch: 4.4763 sec\n",
            "0.1226 0.0856 0.0711 0.0649 0.0609 0.0589 0.0575 0.0567 0.0560 0.0555 0.0551 0.0549 0.0548 0.0548 0.0546 0.0546 \n",
            "\n",
            "[TRAIN] Epoch[1](1030/1214); Loss: 0.068606; Backpropagation: 0.6123 sec; Batch: 4.4891 sec\n",
            "0.1256 0.0886 0.0768 0.0703 0.0667 0.0645 0.0629 0.0617 0.0612 0.0607 0.0602 0.0600 0.0598 0.0597 0.0596 0.0596 \n",
            "\n",
            "[TRAIN] Epoch[1](1031/1214); Loss: 0.056760; Backpropagation: 0.6155 sec; Batch: 4.4939 sec\n",
            "0.1073 0.0735 0.0639 0.0588 0.0549 0.0533 0.0516 0.0507 0.0504 0.0498 0.0494 0.0492 0.0490 0.0489 0.0489 0.0487 \n",
            "\n",
            "[TRAIN] Epoch[1](1032/1214); Loss: 0.071798; Backpropagation: 0.6112 sec; Batch: 4.4880 sec\n",
            "0.1264 0.0990 0.0829 0.0754 0.0715 0.0680 0.0658 0.0647 0.0636 0.0630 0.0624 0.0618 0.0616 0.0613 0.0608 0.0606 \n",
            "\n",
            "[TRAIN] Epoch[1](1033/1214); Loss: 0.065657; Backpropagation: 0.6098 sec; Batch: 4.4831 sec\n",
            "0.1233 0.0891 0.0773 0.0718 0.0666 0.0616 0.0597 0.0588 0.0575 0.0564 0.0556 0.0553 0.0551 0.0545 0.0541 0.0539 \n",
            "\n",
            "[TRAIN] Epoch[1](1034/1214); Loss: 0.069620; Backpropagation: 0.6246 sec; Batch: 4.4944 sec\n",
            "0.1413 0.1003 0.0850 0.0768 0.0701 0.0650 0.0625 0.0607 0.0593 0.0581 0.0572 0.0564 0.0557 0.0555 0.0551 0.0548 \n",
            "\n",
            "[TRAIN] Epoch[1](1035/1214); Loss: 0.065806; Backpropagation: 0.6063 sec; Batch: 4.4806 sec\n",
            "0.1455 0.0979 0.0825 0.0735 0.0662 0.0606 0.0569 0.0549 0.0540 0.0530 0.0524 0.0517 0.0512 0.0510 0.0509 0.0508 \n",
            "\n",
            "[TRAIN] Epoch[1](1036/1214); Loss: 0.073949; Backpropagation: 0.6251 sec; Batch: 4.5008 sec\n",
            "0.1387 0.1034 0.0905 0.0824 0.0742 0.0691 0.0665 0.0650 0.0640 0.0630 0.0622 0.0616 0.0612 0.0608 0.0605 0.0603 \n",
            "\n",
            "[TRAIN] Epoch[1](1037/1214); Loss: 0.069415; Backpropagation: 0.6117 sec; Batch: 4.4824 sec\n",
            "0.1403 0.0974 0.0805 0.0749 0.0675 0.0636 0.0621 0.0604 0.0593 0.0587 0.0582 0.0578 0.0576 0.0575 0.0574 0.0574 \n",
            "\n",
            "[TRAIN] Epoch[1](1038/1214); Loss: 0.075243; Backpropagation: 0.6153 sec; Batch: 4.4916 sec\n",
            "0.1464 0.1035 0.0897 0.0811 0.0739 0.0698 0.0672 0.0657 0.0646 0.0639 0.0636 0.0632 0.0630 0.0628 0.0627 0.0627 \n",
            "\n",
            "[TRAIN] Epoch[1](1039/1214); Loss: 0.064787; Backpropagation: 0.6091 sec; Batch: 4.4858 sec\n",
            "0.1188 0.0910 0.0793 0.0715 0.0642 0.0607 0.0583 0.0567 0.0558 0.0551 0.0547 0.0543 0.0542 0.0541 0.0540 0.0540 \n",
            "\n",
            "[TRAIN] Epoch[1](1040/1214); Loss: 0.073343; Backpropagation: 0.6138 sec; Batch: 4.4882 sec\n",
            "0.1298 0.0996 0.0889 0.0788 0.0725 0.0689 0.0666 0.0651 0.0643 0.0637 0.0632 0.0628 0.0626 0.0624 0.0622 0.0621 \n",
            "\n",
            "[TRAIN] Epoch[1](1041/1214); Loss: 0.078892; Backpropagation: 0.6170 sec; Batch: 4.4916 sec\n",
            "0.1304 0.1097 0.0906 0.0844 0.0776 0.0745 0.0725 0.0713 0.0705 0.0697 0.0692 0.0688 0.0685 0.0685 0.0681 0.0680 \n",
            "\n",
            "[TRAIN] Epoch[1](1042/1214); Loss: 0.072776; Backpropagation: 0.6215 sec; Batch: 4.4993 sec\n",
            "0.1357 0.1021 0.0900 0.0772 0.0711 0.0674 0.0656 0.0641 0.0629 0.0623 0.0618 0.0614 0.0610 0.0608 0.0605 0.0604 \n",
            "\n",
            "[TRAIN] Epoch[1](1043/1214); Loss: 0.070223; Backpropagation: 0.6217 sec; Batch: 4.4965 sec\n",
            "0.1270 0.0951 0.0833 0.0739 0.0689 0.0659 0.0643 0.0629 0.0621 0.0612 0.0606 0.0603 0.0598 0.0594 0.0594 0.0592 \n",
            "\n",
            "[TRAIN] Epoch[1](1044/1214); Loss: 0.062924; Backpropagation: 0.6179 sec; Batch: 4.4953 sec\n",
            "0.1244 0.0902 0.0752 0.0657 0.0609 0.0576 0.0560 0.0549 0.0542 0.0535 0.0528 0.0525 0.0525 0.0523 0.0520 0.0522 \n",
            "\n",
            "[TRAIN] Epoch[1](1045/1214); Loss: 0.069712; Backpropagation: 0.6081 sec; Batch: 4.4851 sec\n",
            "0.1380 0.0918 0.0784 0.0704 0.0674 0.0650 0.0634 0.0622 0.0612 0.0605 0.0600 0.0596 0.0593 0.0594 0.0592 0.0593 \n",
            "\n",
            "[TRAIN] Epoch[1](1046/1214); Loss: 0.076447; Backpropagation: 0.6193 sec; Batch: 4.4930 sec\n",
            "0.1336 0.1023 0.0881 0.0800 0.0755 0.0717 0.0701 0.0689 0.0680 0.0674 0.0669 0.0666 0.0664 0.0660 0.0659 0.0657 \n",
            "\n",
            "[TRAIN] Epoch[1](1047/1214); Loss: 0.078169; Backpropagation: 0.6144 sec; Batch: 4.4866 sec\n",
            "0.1344 0.1025 0.0900 0.0828 0.0780 0.0751 0.0727 0.0713 0.0699 0.0691 0.0684 0.0679 0.0674 0.0672 0.0670 0.0669 \n",
            "\n",
            "[TRAIN] Epoch[1](1048/1214); Loss: 0.062419; Backpropagation: 0.6128 sec; Batch: 4.4877 sec\n",
            "0.1232 0.0897 0.0728 0.0651 0.0600 0.0573 0.0552 0.0544 0.0537 0.0532 0.0530 0.0523 0.0524 0.0522 0.0520 0.0521 \n",
            "\n",
            "[TRAIN] Epoch[1](1049/1214); Loss: 0.067799; Backpropagation: 0.6164 sec; Batch: 4.4878 sec\n",
            "0.1259 0.0934 0.0788 0.0717 0.0669 0.0631 0.0616 0.0604 0.0591 0.0588 0.0584 0.0578 0.0577 0.0572 0.0573 0.0568 \n",
            "\n",
            "[TRAIN] Epoch[1](1050/1214); Loss: 0.079095; Backpropagation: 0.6095 sec; Batch: 4.4868 sec\n",
            "0.1397 0.1051 0.0917 0.0823 0.0777 0.0747 0.0726 0.0711 0.0703 0.0700 0.0693 0.0689 0.0684 0.0683 0.0679 0.0675 \n",
            "\n",
            "[TRAIN] Epoch[1](1051/1214); Loss: 0.073993; Backpropagation: 0.6129 sec; Batch: 4.4865 sec\n",
            "0.1301 0.1013 0.0859 0.0793 0.0734 0.0702 0.0679 0.0666 0.0653 0.0647 0.0640 0.0637 0.0632 0.0631 0.0628 0.0625 \n",
            "\n",
            "[TRAIN] Epoch[1](1052/1214); Loss: 0.062063; Backpropagation: 0.6159 sec; Batch: 4.4917 sec\n",
            "0.1267 0.0842 0.0704 0.0650 0.0600 0.0570 0.0552 0.0546 0.0535 0.0530 0.0526 0.0527 0.0519 0.0521 0.0522 0.0519 \n",
            "\n",
            "[TRAIN] Epoch[1](1053/1214); Loss: 0.069379; Backpropagation: 0.6195 sec; Batch: 4.4954 sec\n",
            "0.1351 0.0992 0.0818 0.0728 0.0673 0.0642 0.0624 0.0608 0.0602 0.0592 0.0586 0.0582 0.0577 0.0577 0.0576 0.0572 \n",
            "\n",
            "[TRAIN] Epoch[1](1054/1214); Loss: 0.059247; Backpropagation: 0.6142 sec; Batch: 4.4879 sec\n",
            "0.1235 0.0883 0.0691 0.0612 0.0561 0.0537 0.0524 0.0512 0.0502 0.0497 0.0492 0.0490 0.0488 0.0488 0.0484 0.0485 \n",
            "\n",
            "[TRAIN] Epoch[1](1055/1214); Loss: 0.062416; Backpropagation: 0.6224 sec; Batch: 4.5058 sec\n",
            "0.1131 0.0870 0.0707 0.0641 0.0601 0.0580 0.0565 0.0559 0.0550 0.0548 0.0545 0.0541 0.0539 0.0538 0.0535 0.0535 \n",
            "\n",
            "[TRAIN] Epoch[1](1056/1214); Loss: 0.073255; Backpropagation: 0.6113 sec; Batch: 4.4894 sec\n",
            "0.1479 0.1013 0.0821 0.0756 0.0701 0.0673 0.0658 0.0646 0.0634 0.0628 0.0623 0.0621 0.0617 0.0617 0.0616 0.0617 \n",
            "\n",
            "[TRAIN] Epoch[1](1057/1214); Loss: 0.067350; Backpropagation: 0.6092 sec; Batch: 4.4870 sec\n",
            "0.1230 0.0917 0.0786 0.0717 0.0659 0.0633 0.0612 0.0601 0.0590 0.0584 0.0580 0.0578 0.0575 0.0572 0.0572 0.0570 \n",
            "\n",
            "[TRAIN] Epoch[1](1058/1214); Loss: 0.063494; Backpropagation: 0.6159 sec; Batch: 4.4955 sec\n",
            "0.1229 0.0888 0.0740 0.0669 0.0621 0.0589 0.0572 0.0561 0.0551 0.0544 0.0539 0.0535 0.0533 0.0532 0.0529 0.0527 \n",
            "\n",
            "[TRAIN] Epoch[1](1059/1214); Loss: 0.074816; Backpropagation: 0.6170 sec; Batch: 4.4894 sec\n",
            "0.1332 0.1018 0.0887 0.0800 0.0742 0.0710 0.0687 0.0671 0.0662 0.0652 0.0646 0.0639 0.0635 0.0632 0.0630 0.0630 \n",
            "\n",
            "[TRAIN] Epoch[1](1060/1214); Loss: 0.066997; Backpropagation: 0.6175 sec; Batch: 4.4944 sec\n",
            "0.1178 0.0941 0.0806 0.0729 0.0671 0.0635 0.0612 0.0597 0.0586 0.0578 0.0571 0.0568 0.0566 0.0563 0.0561 0.0559 \n",
            "\n",
            "[TRAIN] Epoch[1](1061/1214); Loss: 0.071264; Backpropagation: 0.6171 sec; Batch: 4.4893 sec\n",
            "0.1316 0.0933 0.0796 0.0734 0.0696 0.0670 0.0651 0.0641 0.0633 0.0626 0.0623 0.0619 0.0618 0.0616 0.0616 0.0615 \n",
            "\n",
            "[TRAIN] Epoch[1](1062/1214); Loss: 0.064251; Backpropagation: 0.6152 sec; Batch: 4.4850 sec\n",
            "0.1152 0.0814 0.0716 0.0669 0.0638 0.0613 0.0592 0.0581 0.0575 0.0571 0.0565 0.0563 0.0561 0.0559 0.0556 0.0557 \n",
            "\n",
            "[TRAIN] Epoch[1](1063/1214); Loss: 0.065530; Backpropagation: 0.6138 sec; Batch: 4.4895 sec\n",
            "0.1279 0.0892 0.0759 0.0675 0.0636 0.0607 0.0591 0.0581 0.0572 0.0564 0.0561 0.0558 0.0554 0.0552 0.0552 0.0551 \n",
            "\n",
            "[TRAIN] Epoch[1](1064/1214); Loss: 0.083012; Backpropagation: 0.6130 sec; Batch: 4.4899 sec\n",
            "0.1404 0.1028 0.0931 0.0858 0.0814 0.0790 0.0774 0.0763 0.0753 0.0749 0.0743 0.0741 0.0737 0.0734 0.0733 0.0730 \n",
            "\n",
            "[TRAIN] Epoch[1](1065/1214); Loss: 0.060585; Backpropagation: 0.6088 sec; Batch: 4.4884 sec\n",
            "0.1205 0.0809 0.0681 0.0629 0.0589 0.0567 0.0549 0.0538 0.0529 0.0522 0.0518 0.0515 0.0514 0.0511 0.0508 0.0508 \n",
            "\n",
            "[TRAIN] Epoch[1](1066/1214); Loss: 0.059639; Backpropagation: 0.6084 sec; Batch: 4.4784 sec\n",
            "0.1223 0.0794 0.0670 0.0614 0.0583 0.0554 0.0539 0.0527 0.0519 0.0514 0.0508 0.0504 0.0500 0.0500 0.0498 0.0496 \n",
            "\n",
            "[TRAIN] Epoch[1](1067/1214); Loss: 0.058018; Backpropagation: 0.6239 sec; Batch: 4.4973 sec\n",
            "0.1317 0.0828 0.0659 0.0589 0.0545 0.0520 0.0504 0.0496 0.0487 0.0485 0.0479 0.0477 0.0476 0.0475 0.0474 0.0473 \n",
            "\n",
            "[TRAIN] Epoch[1](1068/1214); Loss: 0.059209; Backpropagation: 0.6194 sec; Batch: 4.4982 sec\n",
            "0.1204 0.0779 0.0670 0.0606 0.0565 0.0543 0.0530 0.0520 0.0518 0.0512 0.0508 0.0506 0.0505 0.0505 0.0502 0.0502 \n",
            "\n",
            "[TRAIN] Epoch[1](1069/1214); Loss: 0.071685; Backpropagation: 0.6110 sec; Batch: 4.4835 sec\n",
            "0.1236 0.0920 0.0809 0.0742 0.0701 0.0679 0.0664 0.0653 0.0645 0.0641 0.0636 0.0632 0.0631 0.0628 0.0627 0.0626 \n",
            "\n",
            "[TRAIN] Epoch[1](1070/1214); Loss: 0.064739; Backpropagation: 0.6139 sec; Batch: 4.4863 sec\n",
            "0.1311 0.0905 0.0750 0.0671 0.0626 0.0597 0.0579 0.0566 0.0556 0.0552 0.0547 0.0544 0.0542 0.0540 0.0537 0.0536 \n",
            "\n",
            "[TRAIN] Epoch[1](1071/1214); Loss: 0.071454; Backpropagation: 0.6217 sec; Batch: 4.4971 sec\n",
            "0.1256 0.0961 0.0849 0.0763 0.0713 0.0682 0.0661 0.0642 0.0632 0.0623 0.0617 0.0611 0.0609 0.0607 0.0605 0.0604 \n",
            "\n",
            "[TRAIN] Epoch[1](1072/1214); Loss: 0.071127; Backpropagation: 0.6207 sec; Batch: 4.4942 sec\n",
            "0.1208 0.0902 0.0802 0.0731 0.0697 0.0675 0.0660 0.0649 0.0642 0.0638 0.0634 0.0632 0.0630 0.0629 0.0628 0.0626 \n",
            "\n",
            "[TRAIN] Epoch[1](1073/1214); Loss: 0.067200; Backpropagation: 0.6060 sec; Batch: 4.4772 sec\n",
            "0.1203 0.0901 0.0761 0.0694 0.0652 0.0629 0.0615 0.0606 0.0600 0.0593 0.0591 0.0586 0.0584 0.0581 0.0580 0.0578 \n",
            "\n",
            "[TRAIN] Epoch[1](1074/1214); Loss: 0.069705; Backpropagation: 0.6147 sec; Batch: 4.4948 sec\n",
            "0.1269 0.0898 0.0778 0.0706 0.0678 0.0655 0.0640 0.0630 0.0622 0.0618 0.0614 0.0612 0.0610 0.0609 0.0608 0.0608 \n",
            "\n",
            "[TRAIN] Epoch[1](1075/1214); Loss: 0.063512; Backpropagation: 0.6151 sec; Batch: 4.4913 sec\n",
            "0.1197 0.0875 0.0728 0.0656 0.0620 0.0594 0.0576 0.0565 0.0558 0.0554 0.0548 0.0544 0.0541 0.0537 0.0535 0.0533 \n",
            "\n",
            "[TRAIN] Epoch[1](1076/1214); Loss: 0.060205; Backpropagation: 0.6171 sec; Batch: 4.4961 sec\n",
            "0.1167 0.0848 0.0696 0.0626 0.0586 0.0563 0.0542 0.0532 0.0522 0.0518 0.0512 0.0509 0.0506 0.0504 0.0502 0.0501 \n",
            "\n",
            "[TRAIN] Epoch[1](1077/1214); Loss: 0.060455; Backpropagation: 0.6268 sec; Batch: 4.5007 sec\n",
            "0.1121 0.0834 0.0703 0.0637 0.0594 0.0570 0.0550 0.0538 0.0528 0.0523 0.0517 0.0514 0.0513 0.0512 0.0510 0.0510 \n",
            "\n",
            "[TRAIN] Epoch[1](1078/1214); Loss: 0.066678; Backpropagation: 0.6138 sec; Batch: 4.4947 sec\n",
            "0.1192 0.0912 0.0781 0.0704 0.0659 0.0625 0.0610 0.0596 0.0587 0.0582 0.0578 0.0575 0.0570 0.0568 0.0565 0.0564 \n",
            "\n",
            "[TRAIN] Epoch[1](1079/1214); Loss: 0.067411; Backpropagation: 0.6088 sec; Batch: 4.4822 sec\n",
            "0.1193 0.0889 0.0752 0.0692 0.0657 0.0635 0.0620 0.0611 0.0606 0.0599 0.0594 0.0591 0.0588 0.0587 0.0586 0.0585 \n",
            "\n",
            "[TRAIN] Epoch[1](1080/1214); Loss: 0.060105; Backpropagation: 0.6110 sec; Batch: 4.4852 sec\n",
            "0.1218 0.0791 0.0660 0.0611 0.0575 0.0553 0.0541 0.0534 0.0528 0.0524 0.0520 0.0517 0.0514 0.0512 0.0510 0.0510 \n",
            "\n",
            "[TRAIN] Epoch[1](1081/1214); Loss: 0.060305; Backpropagation: 0.6139 sec; Batch: 4.4882 sec\n",
            "0.1251 0.0822 0.0670 0.0602 0.0569 0.0552 0.0539 0.0529 0.0524 0.0519 0.0516 0.0514 0.0512 0.0511 0.0509 0.0509 \n",
            "\n",
            "[TRAIN] Epoch[1](1082/1214); Loss: 0.060417; Backpropagation: 0.6138 sec; Batch: 4.4844 sec\n",
            "0.1183 0.0819 0.0669 0.0606 0.0574 0.0552 0.0544 0.0534 0.0530 0.0527 0.0524 0.0523 0.0522 0.0520 0.0519 0.0518 \n",
            "\n",
            "[TRAIN] Epoch[1](1083/1214); Loss: 0.065108; Backpropagation: 0.6102 sec; Batch: 4.4854 sec\n",
            "0.1169 0.0863 0.0719 0.0661 0.0632 0.0613 0.0597 0.0588 0.0582 0.0576 0.0573 0.0572 0.0569 0.0568 0.0568 0.0567 \n",
            "\n",
            "[TRAIN] Epoch[1](1084/1214); Loss: 0.067272; Backpropagation: 0.6164 sec; Batch: 4.4865 sec\n",
            "0.1210 0.0910 0.0774 0.0696 0.0656 0.0629 0.0615 0.0605 0.0597 0.0591 0.0586 0.0582 0.0580 0.0579 0.0577 0.0576 \n",
            "\n",
            "[TRAIN] Epoch[1](1085/1214); Loss: 0.056717; Backpropagation: 0.6128 sec; Batch: 4.4873 sec\n",
            "0.1025 0.0726 0.0608 0.0565 0.0542 0.0531 0.0524 0.0518 0.0512 0.0508 0.0506 0.0505 0.0502 0.0502 0.0501 0.0501 \n",
            "\n",
            "[TRAIN] Epoch[1](1086/1214); Loss: 0.068457; Backpropagation: 0.6167 sec; Batch: 4.4938 sec\n",
            "0.1168 0.0905 0.0759 0.0711 0.0674 0.0652 0.0635 0.0623 0.0616 0.0609 0.0605 0.0603 0.0600 0.0600 0.0597 0.0596 \n",
            "\n",
            "[TRAIN] Epoch[1](1087/1214); Loss: 0.065965; Backpropagation: 0.6143 sec; Batch: 4.4893 sec\n",
            "0.1283 0.0893 0.0743 0.0676 0.0638 0.0609 0.0595 0.0585 0.0579 0.0572 0.0568 0.0565 0.0564 0.0563 0.0562 0.0561 \n",
            "\n",
            "[TRAIN] Epoch[1](1088/1214); Loss: 0.064945; Backpropagation: 0.6146 sec; Batch: 4.4912 sec\n",
            "0.1314 0.0896 0.0769 0.0689 0.0636 0.0604 0.0582 0.0568 0.0557 0.0550 0.0546 0.0542 0.0538 0.0536 0.0533 0.0531 \n",
            "\n",
            "[TRAIN] Epoch[1](1089/1214); Loss: 0.060881; Backpropagation: 0.6193 sec; Batch: 4.4932 sec\n",
            "0.1226 0.0859 0.0707 0.0636 0.0594 0.0560 0.0543 0.0530 0.0521 0.0516 0.0513 0.0509 0.0508 0.0507 0.0506 0.0505 \n",
            "\n",
            "[TRAIN] Epoch[1](1090/1214); Loss: 0.056856; Backpropagation: 0.6087 sec; Batch: 4.4812 sec\n",
            "0.1117 0.0766 0.0639 0.0579 0.0544 0.0525 0.0514 0.0504 0.0498 0.0493 0.0490 0.0488 0.0486 0.0485 0.0484 0.0484 \n",
            "\n",
            "[TRAIN] Epoch[1](1091/1214); Loss: 0.065876; Backpropagation: 0.6096 sec; Batch: 4.4833 sec\n",
            "0.1137 0.0843 0.0730 0.0671 0.0644 0.0624 0.0611 0.0602 0.0595 0.0591 0.0587 0.0585 0.0583 0.0581 0.0579 0.0578 \n",
            "\n",
            "[TRAIN] Epoch[1](1092/1214); Loss: 0.070461; Backpropagation: 0.6141 sec; Batch: 4.4952 sec\n",
            "0.1263 0.0894 0.0767 0.0714 0.0679 0.0662 0.0650 0.0641 0.0634 0.0630 0.0628 0.0625 0.0623 0.0622 0.0621 0.0619 \n",
            "\n",
            "[TRAIN] Epoch[1](1093/1214); Loss: 0.061271; Backpropagation: 0.6109 sec; Batch: 4.4850 sec\n",
            "0.1002 0.0788 0.0687 0.0635 0.0612 0.0591 0.0577 0.0568 0.0560 0.0552 0.0546 0.0541 0.0539 0.0537 0.0535 0.0535 \n",
            "\n",
            "[TRAIN] Epoch[1](1094/1214); Loss: 0.061615; Backpropagation: 0.6161 sec; Batch: 4.4842 sec\n",
            "0.1159 0.0819 0.0692 0.0629 0.0594 0.0572 0.0561 0.0552 0.0544 0.0540 0.0537 0.0534 0.0533 0.0532 0.0531 0.0531 \n",
            "\n",
            "[TRAIN] Epoch[1](1095/1214); Loss: 0.081166; Backpropagation: 0.6132 sec; Batch: 4.4906 sec\n",
            "0.1431 0.1049 0.0920 0.0848 0.0796 0.0766 0.0747 0.0735 0.0725 0.0720 0.0715 0.0712 0.0709 0.0706 0.0705 0.0703 \n",
            "\n",
            "[TRAIN] Epoch[1](1096/1214); Loss: 0.053669; Backpropagation: 0.6192 sec; Batch: 4.4957 sec\n",
            "0.1139 0.0792 0.0656 0.0572 0.0521 0.0490 0.0471 0.0459 0.0450 0.0443 0.0438 0.0435 0.0432 0.0431 0.0430 0.0429 \n",
            "\n",
            "[TRAIN] Epoch[1](1097/1214); Loss: 0.068903; Backpropagation: 0.6147 sec; Batch: 4.4932 sec\n",
            "0.1274 0.0954 0.0802 0.0724 0.0675 0.0646 0.0628 0.0615 0.0606 0.0599 0.0593 0.0589 0.0584 0.0582 0.0579 0.0577 \n",
            "\n",
            "[TRAIN] Epoch[1](1098/1214); Loss: 0.063751; Backpropagation: 0.6226 sec; Batch: 4.4956 sec\n",
            "0.1264 0.0863 0.0726 0.0659 0.0616 0.0591 0.0577 0.0565 0.0558 0.0550 0.0545 0.0542 0.0539 0.0537 0.0535 0.0534 \n",
            "\n",
            "[TRAIN] Epoch[1](1099/1214); Loss: 0.067862; Backpropagation: 0.6113 sec; Batch: 4.4837 sec\n",
            "0.1347 0.0920 0.0796 0.0722 0.0670 0.0635 0.0615 0.0599 0.0589 0.0581 0.0574 0.0569 0.0565 0.0562 0.0559 0.0557 \n",
            "\n",
            "[TRAIN] Epoch[1](1100/1214); Loss: 0.062006; Backpropagation: 0.6089 sec; Batch: 4.4851 sec\n",
            "0.1215 0.0818 0.0718 0.0642 0.0601 0.0574 0.0559 0.0548 0.0541 0.0536 0.0533 0.0530 0.0528 0.0526 0.0526 0.0525 \n",
            "\n",
            "[TRAIN] Epoch[1](1101/1214); Loss: 0.064240; Backpropagation: 0.6112 sec; Batch: 4.4888 sec\n",
            "0.1303 0.0909 0.0764 0.0686 0.0636 0.0598 0.0575 0.0559 0.0548 0.0540 0.0534 0.0530 0.0527 0.0525 0.0523 0.0522 \n",
            "\n",
            "[TRAIN] Epoch[1](1102/1214); Loss: 0.069833; Backpropagation: 0.6128 sec; Batch: 4.4870 sec\n",
            "0.1227 0.0924 0.0804 0.0736 0.0695 0.0666 0.0646 0.0631 0.0620 0.0614 0.0608 0.0605 0.0602 0.0600 0.0599 0.0598 \n",
            "\n",
            "[TRAIN] Epoch[1](1103/1214); Loss: 0.066274; Backpropagation: 0.6165 sec; Batch: 4.4976 sec\n",
            "0.1165 0.0847 0.0750 0.0686 0.0648 0.0625 0.0610 0.0599 0.0596 0.0591 0.0587 0.0584 0.0581 0.0579 0.0579 0.0578 \n",
            "\n",
            "[TRAIN] Epoch[1](1104/1214); Loss: 0.066791; Backpropagation: 0.6121 sec; Batch: 4.4895 sec\n",
            "0.1162 0.0876 0.0773 0.0697 0.0654 0.0630 0.0614 0.0602 0.0595 0.0591 0.0586 0.0585 0.0581 0.0582 0.0578 0.0578 \n",
            "\n",
            "[TRAIN] Epoch[1](1105/1214); Loss: 0.074421; Backpropagation: 0.6104 sec; Batch: 4.4855 sec\n",
            "0.1285 0.0983 0.0854 0.0775 0.0730 0.0703 0.0685 0.0677 0.0666 0.0660 0.0655 0.0652 0.0648 0.0644 0.0644 0.0644 \n",
            "\n",
            "[TRAIN] Epoch[1](1106/1214); Loss: 0.076127; Backpropagation: 0.6153 sec; Batch: 4.4890 sec\n",
            "0.1316 0.0993 0.0884 0.0804 0.0764 0.0735 0.0708 0.0692 0.0681 0.0673 0.0666 0.0661 0.0656 0.0652 0.0648 0.0647 \n",
            "\n",
            "[TRAIN] Epoch[1](1107/1214); Loss: 0.058175; Backpropagation: 0.6128 sec; Batch: 4.4871 sec\n",
            "0.1095 0.0783 0.0659 0.0595 0.0564 0.0543 0.0527 0.0520 0.0512 0.0508 0.0505 0.0503 0.0500 0.0499 0.0497 0.0497 \n",
            "\n",
            "[TRAIN] Epoch[1](1108/1214); Loss: 0.059348; Backpropagation: 0.6176 sec; Batch: 4.4979 sec\n",
            "0.1150 0.0877 0.0709 0.0625 0.0578 0.0547 0.0529 0.0519 0.0511 0.0503 0.0498 0.0494 0.0490 0.0489 0.0488 0.0488 \n",
            "\n",
            "[TRAIN] Epoch[1](1109/1214); Loss: 0.061542; Backpropagation: 0.6118 sec; Batch: 4.4870 sec\n",
            "0.1165 0.0876 0.0731 0.0649 0.0600 0.0570 0.0553 0.0541 0.0532 0.0526 0.0522 0.0519 0.0518 0.0516 0.0514 0.0514 \n",
            "\n",
            "[TRAIN] Epoch[1](1110/1214); Loss: 0.065669; Backpropagation: 0.6164 sec; Batch: 4.4891 sec\n",
            "0.1203 0.0914 0.0748 0.0682 0.0641 0.0618 0.0602 0.0590 0.0579 0.0573 0.0567 0.0564 0.0560 0.0558 0.0555 0.0555 \n",
            "\n",
            "[TRAIN] Epoch[1](1111/1214); Loss: 0.058427; Backpropagation: 0.6183 sec; Batch: 4.4946 sec\n",
            "0.1115 0.0841 0.0657 0.0596 0.0565 0.0542 0.0525 0.0517 0.0509 0.0505 0.0500 0.0498 0.0496 0.0495 0.0493 0.0493 \n",
            "\n",
            "[TRAIN] Epoch[1](1112/1214); Loss: 0.060570; Backpropagation: 0.6129 sec; Batch: 4.4982 sec\n",
            "0.1116 0.0813 0.0703 0.0634 0.0592 0.0568 0.0551 0.0543 0.0535 0.0528 0.0524 0.0522 0.0518 0.0516 0.0514 0.0514 \n",
            "\n",
            "[TRAIN] Epoch[1](1113/1214); Loss: 0.061302; Backpropagation: 0.6111 sec; Batch: 4.4863 sec\n",
            "0.1180 0.0837 0.0696 0.0630 0.0593 0.0571 0.0555 0.0545 0.0537 0.0532 0.0528 0.0526 0.0522 0.0520 0.0519 0.0519 \n",
            "\n",
            "[TRAIN] Epoch[1](1114/1214); Loss: 0.064855; Backpropagation: 0.6100 sec; Batch: 4.4861 sec\n",
            "0.1138 0.0868 0.0711 0.0660 0.0630 0.0611 0.0597 0.0588 0.0581 0.0577 0.0573 0.0571 0.0569 0.0568 0.0568 0.0566 \n",
            "\n",
            "[TRAIN] Epoch[1](1115/1214); Loss: 0.073871; Backpropagation: 0.6251 sec; Batch: 4.4991 sec\n",
            "0.1290 0.1009 0.0849 0.0785 0.0739 0.0711 0.0688 0.0672 0.0658 0.0650 0.0640 0.0634 0.0629 0.0625 0.0622 0.0619 \n",
            "\n",
            "[TRAIN] Epoch[1](1116/1214); Loss: 0.070006; Backpropagation: 0.6113 sec; Batch: 4.4795 sec\n",
            "0.1211 0.0930 0.0796 0.0728 0.0687 0.0664 0.0651 0.0637 0.0630 0.0621 0.0617 0.0611 0.0609 0.0606 0.0604 0.0600 \n",
            "\n",
            "[TRAIN] Epoch[1](1117/1214); Loss: 0.066016; Backpropagation: 0.6161 sec; Batch: 4.4949 sec\n",
            "0.1156 0.0895 0.0750 0.0683 0.0648 0.0625 0.0609 0.0597 0.0588 0.0582 0.0579 0.0575 0.0573 0.0570 0.0568 0.0567 \n",
            "\n",
            "[TRAIN] Epoch[1](1118/1214); Loss: 0.067531; Backpropagation: 0.6145 sec; Batch: 4.4891 sec\n",
            "0.1191 0.0896 0.0766 0.0713 0.0675 0.0649 0.0630 0.0614 0.0602 0.0592 0.0586 0.0582 0.0581 0.0577 0.0576 0.0574 \n",
            "\n",
            "[TRAIN] Epoch[1](1119/1214); Loss: 0.061728; Backpropagation: 0.6126 sec; Batch: 4.4905 sec\n",
            "0.1111 0.0807 0.0691 0.0632 0.0599 0.0579 0.0568 0.0560 0.0551 0.0547 0.0542 0.0540 0.0539 0.0538 0.0536 0.0536 \n",
            "\n",
            "[TRAIN] Epoch[1](1120/1214); Loss: 0.065412; Backpropagation: 0.6130 sec; Batch: 4.4860 sec\n",
            "0.1196 0.0872 0.0721 0.0668 0.0630 0.0611 0.0599 0.0591 0.0581 0.0578 0.0575 0.0573 0.0569 0.0568 0.0566 0.0567 \n",
            "\n",
            "[TRAIN] Epoch[1](1121/1214); Loss: 0.055079; Backpropagation: 0.6176 sec; Batch: 4.4976 sec\n",
            "0.1178 0.0806 0.0637 0.0562 0.0521 0.0498 0.0483 0.0475 0.0469 0.0464 0.0459 0.0455 0.0454 0.0452 0.0449 0.0449 \n",
            "\n",
            "[TRAIN] Epoch[1](1122/1214); Loss: 0.057477; Backpropagation: 0.6198 sec; Batch: 4.4953 sec\n",
            "0.1177 0.0807 0.0631 0.0578 0.0546 0.0528 0.0517 0.0504 0.0498 0.0494 0.0491 0.0488 0.0486 0.0485 0.0484 0.0483 \n",
            "\n",
            "[TRAIN] Epoch[1](1123/1214); Loss: 0.068894; Backpropagation: 0.6116 sec; Batch: 4.4837 sec\n",
            "0.1186 0.0929 0.0794 0.0731 0.0686 0.0657 0.0638 0.0624 0.0613 0.0606 0.0601 0.0596 0.0593 0.0591 0.0589 0.0588 \n",
            "\n",
            "[TRAIN] Epoch[1](1124/1214); Loss: 0.065592; Backpropagation: 0.6082 sec; Batch: 4.4793 sec\n",
            "0.1217 0.0944 0.0755 0.0680 0.0633 0.0612 0.0593 0.0582 0.0572 0.0567 0.0562 0.0560 0.0556 0.0556 0.0553 0.0553 \n",
            "\n",
            "[TRAIN] Epoch[1](1125/1214); Loss: 0.064631; Backpropagation: 0.6108 sec; Batch: 4.4868 sec\n",
            "0.1200 0.0858 0.0731 0.0660 0.0626 0.0606 0.0590 0.0579 0.0571 0.0568 0.0563 0.0560 0.0559 0.0557 0.0557 0.0557 \n",
            "\n",
            "[TRAIN] Epoch[1](1126/1214); Loss: 0.077877; Backpropagation: 0.6176 sec; Batch: 4.4945 sec\n",
            "0.1360 0.1059 0.0898 0.0815 0.0771 0.0740 0.0718 0.0703 0.0692 0.0686 0.0680 0.0674 0.0670 0.0667 0.0665 0.0663 \n",
            "\n",
            "[TRAIN] Epoch[1](1127/1214); Loss: 0.061196; Backpropagation: 0.6100 sec; Batch: 4.4802 sec\n",
            "0.1082 0.0812 0.0704 0.0636 0.0599 0.0578 0.0565 0.0554 0.0545 0.0540 0.0535 0.0530 0.0530 0.0529 0.0527 0.0525 \n",
            "\n",
            "[TRAIN] Epoch[1](1128/1214); Loss: 0.063341; Backpropagation: 0.6204 sec; Batch: 4.4967 sec\n",
            "0.1193 0.0882 0.0744 0.0664 0.0621 0.0594 0.0575 0.0564 0.0554 0.0545 0.0541 0.0537 0.0534 0.0531 0.0530 0.0528 \n",
            "\n",
            "[TRAIN] Epoch[1](1129/1214); Loss: 0.056409; Backpropagation: 0.6174 sec; Batch: 4.4960 sec\n",
            "0.1157 0.0784 0.0660 0.0584 0.0541 0.0516 0.0501 0.0490 0.0482 0.0478 0.0475 0.0473 0.0471 0.0472 0.0470 0.0471 \n",
            "\n",
            "[TRAIN] Epoch[1](1130/1214); Loss: 0.062093; Backpropagation: 0.6178 sec; Batch: 4.4900 sec\n",
            "0.1199 0.0828 0.0702 0.0637 0.0599 0.0580 0.0565 0.0555 0.0548 0.0542 0.0537 0.0533 0.0530 0.0528 0.0526 0.0525 \n",
            "\n",
            "[TRAIN] Epoch[1](1131/1214); Loss: 0.051520; Backpropagation: 0.6100 sec; Batch: 4.4845 sec\n",
            "0.1161 0.0723 0.0598 0.0542 0.0495 0.0468 0.0452 0.0440 0.0433 0.0427 0.0422 0.0420 0.0418 0.0417 0.0415 0.0414 \n",
            "\n",
            "[TRAIN] Epoch[1](1132/1214); Loss: 0.054505; Backpropagation: 0.6169 sec; Batch: 4.4995 sec\n",
            "0.1076 0.0730 0.0621 0.0555 0.0515 0.0503 0.0488 0.0480 0.0476 0.0471 0.0470 0.0469 0.0467 0.0466 0.0466 0.0467 \n",
            "\n",
            "[TRAIN] Epoch[1](1133/1214); Loss: 0.059750; Backpropagation: 0.6090 sec; Batch: 4.4839 sec\n",
            "0.1206 0.0873 0.0724 0.0635 0.0576 0.0547 0.0531 0.0515 0.0505 0.0502 0.0497 0.0494 0.0491 0.0489 0.0488 0.0487 \n",
            "\n",
            "[TRAIN] Epoch[1](1134/1214); Loss: 0.060020; Backpropagation: 0.6148 sec; Batch: 4.4945 sec\n",
            "0.1060 0.0791 0.0691 0.0614 0.0582 0.0564 0.0549 0.0538 0.0534 0.0531 0.0528 0.0526 0.0525 0.0524 0.0523 0.0523 \n",
            "\n",
            "[TRAIN] Epoch[1](1135/1214); Loss: 0.082768; Backpropagation: 0.6125 sec; Batch: 4.4862 sec\n",
            "0.1398 0.1081 0.0938 0.0859 0.0816 0.0791 0.0772 0.0756 0.0746 0.0739 0.0732 0.0728 0.0725 0.0722 0.0721 0.0720 \n",
            "\n",
            "[TRAIN] Epoch[1](1136/1214); Loss: 0.070679; Backpropagation: 0.6090 sec; Batch: 4.4859 sec\n",
            "0.1283 0.0940 0.0816 0.0746 0.0695 0.0667 0.0645 0.0633 0.0625 0.0620 0.0614 0.0610 0.0607 0.0604 0.0603 0.0601 \n",
            "\n",
            "[TRAIN] Epoch[1](1137/1214); Loss: 0.071302; Backpropagation: 0.6119 sec; Batch: 4.4870 sec\n",
            "0.1187 0.0959 0.0823 0.0749 0.0709 0.0680 0.0659 0.0649 0.0641 0.0633 0.0626 0.0624 0.0621 0.0618 0.0616 0.0615 \n",
            "\n",
            "[TRAIN] Epoch[1](1138/1214); Loss: 0.066257; Backpropagation: 0.6102 sec; Batch: 4.4833 sec\n",
            "0.1272 0.0900 0.0767 0.0694 0.0647 0.0617 0.0602 0.0587 0.0579 0.0573 0.0567 0.0564 0.0561 0.0559 0.0557 0.0556 \n",
            "\n",
            "[TRAIN] Epoch[1](1139/1214); Loss: 0.066906; Backpropagation: 0.6221 sec; Batch: 4.4953 sec\n",
            "0.1233 0.0901 0.0777 0.0697 0.0660 0.0630 0.0611 0.0598 0.0587 0.0581 0.0578 0.0574 0.0570 0.0569 0.0569 0.0568 \n",
            "\n",
            "[TRAIN] Epoch[1](1140/1214); Loss: 0.065457; Backpropagation: 0.6186 sec; Batch: 4.4973 sec\n",
            "0.1218 0.0853 0.0747 0.0683 0.0637 0.0614 0.0597 0.0586 0.0580 0.0575 0.0568 0.0566 0.0563 0.0563 0.0561 0.0560 \n",
            "\n",
            "[TRAIN] Epoch[1](1141/1214); Loss: 0.058732; Backpropagation: 0.6165 sec; Batch: 4.4914 sec\n",
            "0.1272 0.0835 0.0675 0.0616 0.0571 0.0539 0.0520 0.0507 0.0496 0.0490 0.0485 0.0482 0.0479 0.0478 0.0476 0.0476 \n",
            "\n",
            "[TRAIN] Epoch[1](1142/1214); Loss: 0.062326; Backpropagation: 0.6130 sec; Batch: 4.4921 sec\n",
            "0.1156 0.0826 0.0712 0.0645 0.0608 0.0586 0.0570 0.0559 0.0552 0.0545 0.0542 0.0538 0.0536 0.0534 0.0533 0.0531 \n",
            "\n",
            "[TRAIN] Epoch[1](1143/1214); Loss: 0.053175; Backpropagation: 0.6097 sec; Batch: 4.4893 sec\n",
            "0.1061 0.0732 0.0604 0.0546 0.0512 0.0489 0.0477 0.0467 0.0461 0.0456 0.0455 0.0452 0.0451 0.0450 0.0449 0.0448 \n",
            "\n",
            "[TRAIN] Epoch[1](1144/1214); Loss: 0.065049; Backpropagation: 0.6103 sec; Batch: 4.4904 sec\n",
            "0.1188 0.0918 0.0756 0.0684 0.0641 0.0610 0.0594 0.0579 0.0570 0.0563 0.0557 0.0553 0.0551 0.0549 0.0548 0.0547 \n",
            "\n",
            "[TRAIN] Epoch[1](1145/1214); Loss: 0.062452; Backpropagation: 0.6141 sec; Batch: 4.4868 sec\n",
            "0.1187 0.0829 0.0706 0.0641 0.0603 0.0582 0.0566 0.0557 0.0552 0.0546 0.0542 0.0540 0.0537 0.0536 0.0534 0.0534 \n",
            "\n",
            "[TRAIN] Epoch[1](1146/1214); Loss: 0.062932; Backpropagation: 0.6144 sec; Batch: 4.4859 sec\n",
            "0.1183 0.0819 0.0699 0.0642 0.0608 0.0589 0.0577 0.0566 0.0559 0.0555 0.0550 0.0548 0.0546 0.0544 0.0543 0.0542 \n",
            "\n",
            "[TRAIN] Epoch[1](1147/1214); Loss: 0.056987; Backpropagation: 0.6143 sec; Batch: 4.4905 sec\n",
            "0.1074 0.0811 0.0670 0.0592 0.0547 0.0528 0.0514 0.0503 0.0495 0.0490 0.0486 0.0484 0.0483 0.0481 0.0480 0.0480 \n",
            "\n",
            "[TRAIN] Epoch[1](1148/1214); Loss: 0.070760; Backpropagation: 0.6136 sec; Batch: 4.4873 sec\n",
            "0.1271 0.0930 0.0790 0.0731 0.0691 0.0665 0.0651 0.0641 0.0632 0.0626 0.0622 0.0619 0.0616 0.0614 0.0613 0.0611 \n",
            "\n",
            "[TRAIN] Epoch[1](1149/1214); Loss: 0.059796; Backpropagation: 0.6107 sec; Batch: 4.4885 sec\n",
            "0.1175 0.0798 0.0668 0.0614 0.0575 0.0553 0.0539 0.0529 0.0522 0.0519 0.0517 0.0514 0.0513 0.0512 0.0510 0.0510 \n",
            "\n",
            "[TRAIN] Epoch[1](1150/1214); Loss: 0.063259; Backpropagation: 0.6118 sec; Batch: 4.4883 sec\n",
            "0.1266 0.0916 0.0756 0.0667 0.0606 0.0575 0.0557 0.0547 0.0541 0.0535 0.0531 0.0528 0.0525 0.0524 0.0523 0.0523 \n",
            "\n",
            "[TRAIN] Epoch[1](1151/1214); Loss: 0.054492; Backpropagation: 0.6201 sec; Batch: 4.4990 sec\n",
            "0.1040 0.0749 0.0634 0.0568 0.0530 0.0505 0.0491 0.0482 0.0475 0.0470 0.0467 0.0464 0.0462 0.0461 0.0460 0.0459 \n",
            "\n",
            "[TRAIN] Epoch[1](1152/1214); Loss: 0.069338; Backpropagation: 0.6110 sec; Batch: 4.4867 sec\n",
            "0.1139 0.0894 0.0779 0.0716 0.0680 0.0658 0.0648 0.0637 0.0630 0.0626 0.0620 0.0617 0.0615 0.0613 0.0612 0.0611 \n",
            "\n",
            "[TRAIN] Epoch[1](1153/1214); Loss: 0.066879; Backpropagation: 0.6125 sec; Batch: 4.4851 sec\n",
            "0.1212 0.0886 0.0756 0.0684 0.0644 0.0626 0.0613 0.0603 0.0595 0.0590 0.0587 0.0584 0.0582 0.0581 0.0579 0.0579 \n",
            "\n",
            "[TRAIN] Epoch[1](1154/1214); Loss: 0.058598; Backpropagation: 0.6210 sec; Batch: 4.5047 sec\n",
            "0.1244 0.0866 0.0693 0.0606 0.0559 0.0532 0.0512 0.0500 0.0494 0.0488 0.0485 0.0482 0.0480 0.0478 0.0478 0.0478 \n",
            "\n",
            "[TRAIN] Epoch[1](1155/1214); Loss: 0.056624; Backpropagation: 0.6132 sec; Batch: 4.4964 sec\n",
            "0.1120 0.0784 0.0654 0.0583 0.0545 0.0523 0.0508 0.0499 0.0491 0.0485 0.0482 0.0480 0.0479 0.0477 0.0475 0.0474 \n",
            "\n",
            "[TRAIN] Epoch[1](1156/1214); Loss: 0.064656; Backpropagation: 0.6181 sec; Batch: 4.4998 sec\n",
            "0.1138 0.0855 0.0749 0.0681 0.0635 0.0614 0.0594 0.0582 0.0574 0.0569 0.0565 0.0561 0.0559 0.0558 0.0557 0.0556 \n",
            "\n",
            "[TRAIN] Epoch[1](1157/1214); Loss: 0.059641; Backpropagation: 0.6086 sec; Batch: 4.4849 sec\n",
            "0.1242 0.0827 0.0681 0.0611 0.0572 0.0550 0.0533 0.0520 0.0515 0.0507 0.0504 0.0500 0.0497 0.0496 0.0494 0.0493 \n",
            "\n",
            "[TRAIN] Epoch[1](1158/1214); Loss: 0.059027; Backpropagation: 0.6167 sec; Batch: 4.4910 sec\n",
            "0.1055 0.0801 0.0692 0.0613 0.0580 0.0555 0.0539 0.0529 0.0522 0.0516 0.0512 0.0509 0.0507 0.0506 0.0504 0.0504 \n",
            "\n",
            "[TRAIN] Epoch[1](1159/1214); Loss: 0.066299; Backpropagation: 0.6092 sec; Batch: 4.4749 sec\n",
            "0.1241 0.0888 0.0783 0.0701 0.0661 0.0622 0.0605 0.0591 0.0581 0.0573 0.0568 0.0564 0.0561 0.0559 0.0557 0.0554 \n",
            "\n",
            "[TRAIN] Epoch[1](1160/1214); Loss: 0.054502; Backpropagation: 0.6179 sec; Batch: 4.4960 sec\n",
            "0.1175 0.0808 0.0663 0.0572 0.0528 0.0494 0.0479 0.0463 0.0454 0.0450 0.0446 0.0441 0.0439 0.0437 0.0436 0.0435 \n",
            "\n",
            "[TRAIN] Epoch[1](1161/1214); Loss: 0.063394; Backpropagation: 0.6121 sec; Batch: 4.4874 sec\n",
            "0.1244 0.0900 0.0763 0.0673 0.0628 0.0600 0.0573 0.0551 0.0542 0.0533 0.0530 0.0527 0.0523 0.0520 0.0519 0.0517 \n",
            "\n",
            "[TRAIN] Epoch[1](1162/1214); Loss: 0.072850; Backpropagation: 0.6113 sec; Batch: 4.4837 sec\n",
            "0.1263 0.0982 0.0849 0.0769 0.0722 0.0692 0.0671 0.0658 0.0647 0.0638 0.0634 0.0631 0.0628 0.0626 0.0623 0.0622 \n",
            "\n",
            "[TRAIN] Epoch[1](1163/1214); Loss: 0.062423; Backpropagation: 0.6138 sec; Batch: 4.4865 sec\n",
            "0.1269 0.0880 0.0762 0.0672 0.0619 0.0582 0.0555 0.0540 0.0531 0.0523 0.0517 0.0514 0.0510 0.0507 0.0505 0.0503 \n",
            "\n",
            "[TRAIN] Epoch[1](1164/1214); Loss: 0.065191; Backpropagation: 0.6047 sec; Batch: 4.4784 sec\n",
            "0.1355 0.0940 0.0762 0.0698 0.0642 0.0610 0.0586 0.0568 0.0557 0.0546 0.0539 0.0534 0.0529 0.0524 0.0521 0.0519 \n",
            "\n",
            "[TRAIN] Epoch[1](1165/1214); Loss: 0.063278; Backpropagation: 0.6102 sec; Batch: 4.4881 sec\n",
            "0.1259 0.0876 0.0748 0.0674 0.0626 0.0592 0.0571 0.0556 0.0547 0.0538 0.0532 0.0527 0.0524 0.0520 0.0517 0.0515 \n",
            "\n",
            "[TRAIN] Epoch[1](1166/1214); Loss: 0.062043; Backpropagation: 0.6123 sec; Batch: 4.4892 sec\n",
            "0.1128 0.0863 0.0744 0.0664 0.0625 0.0590 0.0573 0.0556 0.0546 0.0537 0.0528 0.0522 0.0517 0.0514 0.0511 0.0509 \n",
            "\n",
            "[TRAIN] Epoch[1](1167/1214); Loss: 0.072733; Backpropagation: 0.6207 sec; Batch: 4.5013 sec\n",
            "0.1371 0.1023 0.0857 0.0778 0.0730 0.0694 0.0668 0.0647 0.0633 0.0623 0.0616 0.0609 0.0603 0.0599 0.0595 0.0593 \n",
            "\n",
            "[TRAIN] Epoch[1](1168/1214); Loss: 0.068228; Backpropagation: 0.6104 sec; Batch: 4.4906 sec\n",
            "0.1216 0.0938 0.0815 0.0736 0.0688 0.0655 0.0633 0.0612 0.0597 0.0586 0.0581 0.0576 0.0574 0.0571 0.0570 0.0568 \n",
            "\n",
            "[TRAIN] Epoch[1](1169/1214); Loss: 0.069740; Backpropagation: 0.6106 sec; Batch: 4.4878 sec\n",
            "0.1195 0.0953 0.0827 0.0750 0.0700 0.0669 0.0644 0.0629 0.0618 0.0609 0.0602 0.0598 0.0594 0.0592 0.0590 0.0589 \n",
            "\n",
            "[TRAIN] Epoch[1](1170/1214); Loss: 0.066467; Backpropagation: 0.6127 sec; Batch: 4.4874 sec\n",
            "0.1330 0.0949 0.0790 0.0716 0.0665 0.0628 0.0599 0.0581 0.0566 0.0558 0.0551 0.0546 0.0543 0.0539 0.0537 0.0535 \n",
            "\n",
            "[TRAIN] Epoch[1](1171/1214); Loss: 0.067301; Backpropagation: 0.6087 sec; Batch: 4.4835 sec\n",
            "0.1245 0.0885 0.0783 0.0713 0.0662 0.0636 0.0618 0.0604 0.0596 0.0588 0.0582 0.0577 0.0574 0.0570 0.0567 0.0566 \n",
            "\n",
            "[TRAIN] Epoch[1](1172/1214); Loss: 0.070873; Backpropagation: 0.6132 sec; Batch: 4.4863 sec\n",
            "0.1266 0.0923 0.0804 0.0739 0.0699 0.0673 0.0657 0.0642 0.0633 0.0627 0.0620 0.0617 0.0612 0.0611 0.0608 0.0608 \n",
            "\n",
            "[TRAIN] Epoch[1](1173/1214); Loss: 0.062473; Backpropagation: 0.6146 sec; Batch: 4.4876 sec\n",
            "0.1274 0.0886 0.0741 0.0658 0.0611 0.0575 0.0554 0.0541 0.0533 0.0527 0.0522 0.0519 0.0517 0.0515 0.0512 0.0512 \n",
            "\n",
            "[TRAIN] Epoch[1](1174/1214); Loss: 0.067133; Backpropagation: 0.6115 sec; Batch: 4.4885 sec\n",
            "0.1211 0.0891 0.0779 0.0712 0.0663 0.0632 0.0617 0.0604 0.0594 0.0589 0.0584 0.0579 0.0575 0.0573 0.0571 0.0568 \n",
            "\n",
            "[TRAIN] Epoch[1](1175/1214); Loss: 0.056986; Backpropagation: 0.6105 sec; Batch: 4.4857 sec\n",
            "0.1171 0.0797 0.0670 0.0594 0.0554 0.0525 0.0506 0.0496 0.0489 0.0482 0.0477 0.0474 0.0473 0.0472 0.0470 0.0468 \n",
            "\n",
            "[TRAIN] Epoch[1](1176/1214); Loss: 0.059208; Backpropagation: 0.6080 sec; Batch: 4.4893 sec\n",
            "0.1180 0.0804 0.0683 0.0621 0.0573 0.0549 0.0533 0.0523 0.0515 0.0510 0.0504 0.0500 0.0497 0.0496 0.0493 0.0493 \n",
            "\n",
            "[TRAIN] Epoch[1](1177/1214); Loss: 0.065462; Backpropagation: 0.6163 sec; Batch: 4.4906 sec\n",
            "0.1214 0.0927 0.0775 0.0704 0.0650 0.0617 0.0594 0.0580 0.0570 0.0562 0.0554 0.0551 0.0546 0.0544 0.0543 0.0543 \n",
            "\n",
            "[TRAIN] Epoch[1](1178/1214); Loss: 0.071346; Backpropagation: 0.6119 sec; Batch: 4.4911 sec\n",
            "0.1320 0.0969 0.0828 0.0758 0.0705 0.0673 0.0657 0.0639 0.0626 0.0618 0.0612 0.0608 0.0605 0.0601 0.0600 0.0598 \n",
            "\n",
            "[TRAIN] Epoch[1](1179/1214); Loss: 0.057155; Backpropagation: 0.6150 sec; Batch: 4.4967 sec\n",
            "0.1206 0.0821 0.0668 0.0599 0.0558 0.0524 0.0502 0.0494 0.0486 0.0479 0.0474 0.0471 0.0467 0.0467 0.0465 0.0464 \n",
            "\n",
            "[TRAIN] Epoch[1](1180/1214); Loss: 0.066789; Backpropagation: 0.6201 sec; Batch: 4.5018 sec\n",
            "0.1203 0.0883 0.0758 0.0702 0.0654 0.0626 0.0611 0.0599 0.0593 0.0589 0.0584 0.0580 0.0578 0.0577 0.0574 0.0575 \n",
            "\n",
            "[TRAIN] Epoch[1](1181/1214); Loss: 0.065163; Backpropagation: 0.6096 sec; Batch: 4.4843 sec\n",
            "0.1335 0.0867 0.0737 0.0679 0.0635 0.0605 0.0588 0.0577 0.0564 0.0560 0.0554 0.0550 0.0546 0.0544 0.0542 0.0540 \n",
            "\n",
            "[TRAIN] Epoch[1](1182/1214); Loss: 0.059173; Backpropagation: 0.6168 sec; Batch: 4.4904 sec\n",
            "0.1148 0.0787 0.0671 0.0612 0.0571 0.0550 0.0537 0.0527 0.0520 0.0515 0.0509 0.0507 0.0506 0.0503 0.0503 0.0501 \n",
            "\n",
            "[TRAIN] Epoch[1](1183/1214); Loss: 0.069042; Backpropagation: 0.6068 sec; Batch: 4.4769 sec\n",
            "0.1231 0.0953 0.0805 0.0736 0.0686 0.0657 0.0636 0.0619 0.0608 0.0601 0.0595 0.0589 0.0586 0.0584 0.0582 0.0580 \n",
            "\n",
            "[TRAIN] Epoch[1](1184/1214); Loss: 0.067513; Backpropagation: 0.6177 sec; Batch: 4.4959 sec\n",
            "0.1368 0.0951 0.0811 0.0730 0.0664 0.0630 0.0606 0.0589 0.0576 0.0567 0.0561 0.0557 0.0553 0.0549 0.0546 0.0544 \n",
            "\n",
            "[TRAIN] Epoch[1](1185/1214); Loss: 0.072760; Backpropagation: 0.6114 sec; Batch: 4.4851 sec\n",
            "0.1235 0.0978 0.0841 0.0772 0.0725 0.0697 0.0675 0.0661 0.0652 0.0643 0.0636 0.0632 0.0628 0.0625 0.0622 0.0621 \n",
            "\n",
            "[TRAIN] Epoch[1](1186/1214); Loss: 0.067061; Backpropagation: 0.6095 sec; Batch: 4.4886 sec\n",
            "0.1252 0.0892 0.0753 0.0692 0.0650 0.0628 0.0616 0.0602 0.0593 0.0589 0.0583 0.0580 0.0577 0.0575 0.0575 0.0573 \n",
            "\n",
            "[TRAIN] Epoch[1](1187/1214); Loss: 0.055990; Backpropagation: 0.6101 sec; Batch: 4.4847 sec\n",
            "0.1130 0.0794 0.0663 0.0588 0.0543 0.0515 0.0499 0.0487 0.0479 0.0474 0.0470 0.0467 0.0465 0.0463 0.0461 0.0460 \n",
            "\n",
            "[TRAIN] Epoch[1](1188/1214); Loss: 0.058179; Backpropagation: 0.6060 sec; Batch: 4.4840 sec\n",
            "0.1064 0.0766 0.0664 0.0607 0.0566 0.0546 0.0532 0.0522 0.0515 0.0511 0.0507 0.0505 0.0503 0.0500 0.0500 0.0500 \n",
            "\n",
            "[TRAIN] Epoch[1](1189/1214); Loss: 0.063385; Backpropagation: 0.6116 sec; Batch: 4.4847 sec\n",
            "0.1144 0.0865 0.0727 0.0668 0.0616 0.0588 0.0579 0.0569 0.0561 0.0556 0.0551 0.0548 0.0546 0.0542 0.0541 0.0540 \n",
            "\n",
            "[TRAIN] Epoch[1](1190/1214); Loss: 0.063450; Backpropagation: 0.6103 sec; Batch: 4.4876 sec\n",
            "0.1180 0.0852 0.0731 0.0662 0.0625 0.0594 0.0576 0.0565 0.0559 0.0553 0.0549 0.0546 0.0543 0.0541 0.0539 0.0538 \n",
            "\n",
            "[TRAIN] Epoch[1](1191/1214); Loss: 0.060638; Backpropagation: 0.6113 sec; Batch: 4.4872 sec\n",
            "0.1183 0.0821 0.0709 0.0633 0.0590 0.0561 0.0544 0.0531 0.0525 0.0521 0.0518 0.0515 0.0514 0.0513 0.0512 0.0511 \n",
            "\n",
            "[TRAIN] Epoch[1](1192/1214); Loss: 0.066543; Backpropagation: 0.6089 sec; Batch: 4.4802 sec\n",
            "0.1288 0.0965 0.0814 0.0726 0.0665 0.0625 0.0595 0.0578 0.0567 0.0558 0.0552 0.0548 0.0544 0.0542 0.0539 0.0538 \n",
            "\n",
            "[TRAIN] Epoch[1](1193/1214); Loss: 0.061123; Backpropagation: 0.6081 sec; Batch: 4.4793 sec\n",
            "0.1135 0.0843 0.0710 0.0630 0.0591 0.0571 0.0554 0.0543 0.0536 0.0531 0.0527 0.0525 0.0523 0.0522 0.0520 0.0519 \n",
            "\n",
            "[TRAIN] Epoch[1](1194/1214); Loss: 0.060629; Backpropagation: 0.6145 sec; Batch: 4.4949 sec\n",
            "0.1105 0.0810 0.0695 0.0628 0.0589 0.0568 0.0554 0.0543 0.0536 0.0531 0.0528 0.0526 0.0524 0.0522 0.0521 0.0521 \n",
            "\n",
            "[TRAIN] Epoch[1](1195/1214); Loss: 0.060098; Backpropagation: 0.6111 sec; Batch: 4.4882 sec\n",
            "0.1149 0.0848 0.0694 0.0622 0.0584 0.0559 0.0543 0.0531 0.0523 0.0517 0.0512 0.0509 0.0508 0.0506 0.0505 0.0505 \n",
            "\n",
            "[TRAIN] Epoch[1](1196/1214); Loss: 0.066714; Backpropagation: 0.6156 sec; Batch: 4.4907 sec\n",
            "0.1172 0.0894 0.0789 0.0711 0.0659 0.0631 0.0616 0.0602 0.0592 0.0584 0.0578 0.0574 0.0571 0.0568 0.0568 0.0566 \n",
            "\n",
            "[TRAIN] Epoch[1](1197/1214); Loss: 0.067943; Backpropagation: 0.6156 sec; Batch: 4.4964 sec\n",
            "0.1267 0.0900 0.0765 0.0697 0.0658 0.0637 0.0622 0.0610 0.0602 0.0596 0.0593 0.0589 0.0586 0.0585 0.0583 0.0582 \n",
            "\n",
            "[TRAIN] Epoch[1](1198/1214); Loss: 0.072937; Backpropagation: 0.6097 sec; Batch: 4.4867 sec\n",
            "0.1275 0.0919 0.0806 0.0741 0.0712 0.0692 0.0676 0.0667 0.0659 0.0656 0.0650 0.0648 0.0645 0.0643 0.0641 0.0640 \n",
            "\n",
            "[TRAIN] Epoch[1](1199/1214); Loss: 0.074424; Backpropagation: 0.6227 sec; Batch: 4.5065 sec\n",
            "0.1325 0.1003 0.0849 0.0782 0.0731 0.0702 0.0684 0.0671 0.0661 0.0653 0.0649 0.0645 0.0641 0.0638 0.0637 0.0636 \n",
            "\n",
            "[TRAIN] Epoch[1](1200/1214); Loss: 0.058867; Backpropagation: 0.6145 sec; Batch: 4.4948 sec\n",
            "0.1065 0.0772 0.0648 0.0600 0.0569 0.0550 0.0540 0.0531 0.0525 0.0523 0.0519 0.0517 0.0516 0.0515 0.0514 0.0514 \n",
            "\n",
            "[TRAIN] Epoch[1](1201/1214); Loss: 0.057303; Backpropagation: 0.6192 sec; Batch: 4.4937 sec\n",
            "0.1147 0.0772 0.0654 0.0591 0.0552 0.0530 0.0514 0.0506 0.0499 0.0494 0.0490 0.0488 0.0485 0.0484 0.0481 0.0481 \n",
            "\n",
            "[TRAIN] Epoch[1](1202/1214); Loss: 0.061733; Backpropagation: 0.6110 sec; Batch: 4.4890 sec\n",
            "0.1108 0.0789 0.0687 0.0633 0.0599 0.0580 0.0568 0.0559 0.0552 0.0549 0.0545 0.0543 0.0543 0.0542 0.0541 0.0540 \n",
            "\n",
            "[TRAIN] Epoch[1](1203/1214); Loss: 0.065651; Backpropagation: 0.6103 sec; Batch: 4.4855 sec\n",
            "0.1226 0.0851 0.0725 0.0664 0.0632 0.0616 0.0601 0.0590 0.0583 0.0580 0.0577 0.0575 0.0573 0.0571 0.0571 0.0570 \n",
            "\n",
            "[TRAIN] Epoch[1](1204/1214); Loss: 0.060646; Backpropagation: 0.6090 sec; Batch: 4.4796 sec\n",
            "0.1186 0.0855 0.0692 0.0622 0.0584 0.0560 0.0547 0.0536 0.0529 0.0524 0.0517 0.0515 0.0511 0.0510 0.0509 0.0508 \n",
            "\n",
            "[TRAIN] Epoch[1](1205/1214); Loss: 0.064711; Backpropagation: 0.6096 sec; Batch: 4.4864 sec\n",
            "0.1225 0.0893 0.0740 0.0669 0.0631 0.0603 0.0586 0.0575 0.0567 0.0560 0.0556 0.0554 0.0551 0.0549 0.0548 0.0547 \n",
            "\n",
            "[TRAIN] Epoch[1](1206/1214); Loss: 0.063613; Backpropagation: 0.6119 sec; Batch: 4.4881 sec\n",
            "0.1200 0.0895 0.0756 0.0670 0.0619 0.0592 0.0574 0.0560 0.0552 0.0545 0.0541 0.0539 0.0537 0.0534 0.0533 0.0531 \n",
            "\n",
            "[TRAIN] Epoch[1](1207/1214); Loss: 0.061184; Backpropagation: 0.6110 sec; Batch: 4.4839 sec\n",
            "0.1188 0.0812 0.0691 0.0627 0.0590 0.0572 0.0557 0.0547 0.0539 0.0532 0.0527 0.0525 0.0523 0.0521 0.0520 0.0518 \n",
            "\n",
            "[TRAIN] Epoch[1](1208/1214); Loss: 0.055825; Backpropagation: 0.6096 sec; Batch: 4.4859 sec\n",
            "0.1207 0.0765 0.0620 0.0562 0.0530 0.0511 0.0495 0.0486 0.0480 0.0475 0.0472 0.0469 0.0467 0.0465 0.0464 0.0464 \n",
            "\n",
            "[TRAIN] Epoch[1](1209/1214); Loss: 0.059532; Backpropagation: 0.6138 sec; Batch: 4.4927 sec\n",
            "0.1109 0.0818 0.0684 0.0617 0.0579 0.0556 0.0544 0.0530 0.0523 0.0518 0.0514 0.0510 0.0507 0.0506 0.0505 0.0503 \n",
            "\n",
            "[TRAIN] Epoch[1](1210/1214); Loss: 0.072758; Backpropagation: 0.6133 sec; Batch: 4.4895 sec\n",
            "0.1372 0.0992 0.0837 0.0752 0.0709 0.0680 0.0661 0.0648 0.0639 0.0632 0.0628 0.0623 0.0620 0.0618 0.0616 0.0615 \n",
            "\n",
            "[TRAIN] Epoch[1](1211/1214); Loss: 0.058913; Backpropagation: 0.6198 sec; Batch: 4.5017 sec\n",
            "0.1244 0.0814 0.0675 0.0604 0.0566 0.0541 0.0524 0.0510 0.0504 0.0499 0.0496 0.0493 0.0491 0.0490 0.0489 0.0488 \n",
            "\n",
            "[TRAIN] Epoch[1](1212/1214); Loss: 0.062217; Backpropagation: 0.6072 sec; Batch: 4.4844 sec\n",
            "0.1229 0.0887 0.0720 0.0647 0.0606 0.0576 0.0558 0.0547 0.0538 0.0530 0.0526 0.0522 0.0519 0.0517 0.0517 0.0515 \n",
            "\n",
            "[TRAIN] Epoch[1](1213/1214); Loss: 0.075437; Backpropagation: 0.6037 sec; Batch: 4.4778 sec\n",
            "0.1208 0.0939 0.0828 0.0772 0.0743 0.0725 0.0712 0.0701 0.0694 0.0687 0.0683 0.0680 0.0678 0.0675 0.0673 0.0671 \n",
            "\n",
            "[TRAIN] Epoch[1](1214/1214); Loss: 0.060567; Backpropagation: 0.4787 sec; Batch: 3.3650 sec\n",
            "0.1119 0.0800 0.0691 0.0628 0.0593 0.0574 0.0560 0.0547 0.0537 0.0531 0.0526 0.0523 0.0518 0.0516 0.0514 0.0514 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K5cq7iCaGgFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4913
        },
        "outputId": "0bb497a1-5328-4d01-d4aa-692467f7511c"
      },
      "cell_type": "code",
      "source": [
        "!bash 'gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/test/get_kodak.sh'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01\n",
            "--2018-12-03 00:52:55--  http://r0k.us/graphics/kodak/kodak/kodim01.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 736501 (719K) [image/png]\n",
            "Saving to: test/images/kodim01.png\n",
            "\n",
            "test/images/kodim01 100%[===================>] 719.24K  3.06MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:56 (3.06 MB/s) - test/images/kodim01.png saved [736501/736501]\n",
            "\n",
            "02\n",
            "--2018-12-03 00:52:56--  http://r0k.us/graphics/kodak/kodak/kodim02.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 617995 (604K) [image/png]\n",
            "Saving to: test/images/kodim02.png\n",
            "\n",
            "test/images/kodim02 100%[===================>] 603.51K  2.70MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:56 (2.70 MB/s) - test/images/kodim02.png saved [617995/617995]\n",
            "\n",
            "03\n",
            "--2018-12-03 00:52:56--  http://r0k.us/graphics/kodak/kodak/kodim03.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 502888 (491K) [image/png]\n",
            "Saving to: test/images/kodim03.png\n",
            "\n",
            "test/images/kodim03 100%[===================>] 491.10K  2.31MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:56 (2.31 MB/s) - test/images/kodim03.png saved [502888/502888]\n",
            "\n",
            "04\n",
            "--2018-12-03 00:52:56--  http://r0k.us/graphics/kodak/kodak/kodim04.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 637432 (622K) [image/png]\n",
            "Saving to: test/images/kodim04.png\n",
            "\n",
            "test/images/kodim04 100%[===================>] 622.49K  2.73MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:57 (2.73 MB/s) - test/images/kodim04.png saved [637432/637432]\n",
            "\n",
            "05\n",
            "--2018-12-03 00:52:57--  http://r0k.us/graphics/kodak/kodak/kodim05.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 785610 (767K) [image/png]\n",
            "Saving to: test/images/kodim05.png\n",
            "\n",
            "test/images/kodim05 100%[===================>] 767.20K  3.22MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:57 (3.22 MB/s) - test/images/kodim05.png saved [785610/785610]\n",
            "\n",
            "06\n",
            "--2018-12-03 00:52:57--  http://r0k.us/graphics/kodak/kodak/kodim06.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 618959 (604K) [image/png]\n",
            "Saving to: test/images/kodim06.png\n",
            "\n",
            "test/images/kodim06 100%[===================>] 604.45K  2.68MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:57 (2.68 MB/s) - test/images/kodim06.png saved [618959/618959]\n",
            "\n",
            "07\n",
            "--2018-12-03 00:52:57--  http://r0k.us/graphics/kodak/kodak/kodim07.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 566322 (553K) [image/png]\n",
            "Saving to: test/images/kodim07.png\n",
            "\n",
            "test/images/kodim07 100%[===================>] 553.05K  1.34MB/s    in 0.4s    \n",
            "\n",
            "2018-12-03 00:52:58 (1.34 MB/s) - test/images/kodim07.png saved [566322/566322]\n",
            "\n",
            "08\n",
            "--2018-12-03 00:52:58--  http://r0k.us/graphics/kodak/kodak/kodim08.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 788470 (770K) [image/png]\n",
            "Saving to: test/images/kodim08.png\n",
            "\n",
            "test/images/kodim08 100%[===================>] 769.99K  3.22MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:58 (3.22 MB/s) - test/images/kodim08.png saved [788470/788470]\n",
            "\n",
            "09\n",
            "--2018-12-03 00:52:58--  http://r0k.us/graphics/kodak/kodak/kodim09.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 582899 (569K) [image/png]\n",
            "Saving to: test/images/kodim09.png\n",
            "\n",
            "test/images/kodim09 100%[===================>] 569.24K  2.57MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:58 (2.57 MB/s) - test/images/kodim09.png saved [582899/582899]\n",
            "\n",
            "10\n",
            "--2018-12-03 00:52:58--  http://r0k.us/graphics/kodak/kodak/kodim10.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593463 (580K) [image/png]\n",
            "Saving to: test/images/kodim10.png\n",
            "\n",
            "test/images/kodim10 100%[===================>] 579.55K  2.60MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:59 (2.60 MB/s) - test/images/kodim10.png saved [593463/593463]\n",
            "\n",
            "11\n",
            "--2018-12-03 00:52:59--  http://r0k.us/graphics/kodak/kodak/kodim11.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 621023 (606K) [image/png]\n",
            "Saving to: test/images/kodim11.png\n",
            "\n",
            "test/images/kodim11 100%[===================>] 606.47K  2.69MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:59 (2.69 MB/s) - test/images/kodim11.png saved [621023/621023]\n",
            "\n",
            "12\n",
            "--2018-12-03 00:52:59--  http://r0k.us/graphics/kodak/kodak/kodim12.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 531024 (519K) [image/png]\n",
            "Saving to: test/images/kodim12.png\n",
            "\n",
            "test/images/kodim12 100%[===================>] 518.58K  2.40MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:52:59 (2.40 MB/s) - test/images/kodim12.png saved [531024/531024]\n",
            "\n",
            "13\n",
            "--2018-12-03 00:52:59--  http://r0k.us/graphics/kodak/kodak/kodim13.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 822712 (803K) [image/png]\n",
            "Saving to: test/images/kodim13.png\n",
            "\n",
            "test/images/kodim13 100%[===================>] 803.43K  3.30MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:00 (3.30 MB/s) - test/images/kodim13.png saved [822712/822712]\n",
            "\n",
            "14\n",
            "--2018-12-03 00:53:00--  http://r0k.us/graphics/kodak/kodak/kodim14.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 692201 (676K) [image/png]\n",
            "Saving to: test/images/kodim14.png\n",
            "\n",
            "test/images/kodim14 100%[===================>] 675.98K  2.92MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:00 (2.92 MB/s) - test/images/kodim14.png saved [692201/692201]\n",
            "\n",
            "15\n",
            "--2018-12-03 00:53:00--  http://r0k.us/graphics/kodak/kodak/kodim15.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 612582 (598K) [image/png]\n",
            "Saving to: test/images/kodim15.png\n",
            "\n",
            "test/images/kodim15 100%[===================>] 598.22K  2.64MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:00 (2.64 MB/s) - test/images/kodim15.png saved [612582/612582]\n",
            "\n",
            "16\n",
            "--2018-12-03 00:53:00--  http://r0k.us/graphics/kodak/kodak/kodim16.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 534247 (522K) [image/png]\n",
            "Saving to: test/images/kodim16.png\n",
            "\n",
            "test/images/kodim16 100%[===================>] 521.73K  2.42MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:01 (2.42 MB/s) - test/images/kodim16.png saved [534247/534247]\n",
            "\n",
            "17\n",
            "--2018-12-03 00:53:01--  http://r0k.us/graphics/kodak/kodak/kodim17.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 602078 (588K) [image/png]\n",
            "Saving to: test/images/kodim17.png\n",
            "\n",
            "test/images/kodim17 100%[===================>] 587.97K  2.63MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:01 (2.63 MB/s) - test/images/kodim17.png saved [602078/602078]\n",
            "\n",
            "18\n",
            "--2018-12-03 00:53:01--  http://r0k.us/graphics/kodak/kodak/kodim18.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 780947 (763K) [image/png]\n",
            "Saving to: test/images/kodim18.png\n",
            "\n",
            "test/images/kodim18 100%[===================>] 762.64K  3.19MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:01 (3.19 MB/s) - test/images/kodim18.png saved [780947/780947]\n",
            "\n",
            "19\n",
            "--2018-12-03 00:53:01--  http://r0k.us/graphics/kodak/kodak/kodim19.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 671476 (656K) [image/png]\n",
            "Saving to: test/images/kodim19.png\n",
            "\n",
            "test/images/kodim19 100%[===================>] 655.74K  2.86MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:02 (2.86 MB/s) - test/images/kodim19.png saved [671476/671476]\n",
            "\n",
            "20\n",
            "--2018-12-03 00:53:02--  http://r0k.us/graphics/kodak/kodak/kodim20.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 492462 (481K) [image/png]\n",
            "Saving to: test/images/kodim20.png\n",
            "\n",
            "test/images/kodim20 100%[===================>] 480.92K  2.26MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:02 (2.26 MB/s) - test/images/kodim20.png saved [492462/492462]\n",
            "\n",
            "21\n",
            "--2018-12-03 00:53:02--  http://r0k.us/graphics/kodak/kodak/kodim21.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 637051 (622K) [image/png]\n",
            "Saving to: test/images/kodim21.png\n",
            "\n",
            "test/images/kodim21 100%[===================>] 622.12K  2.76MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:02 (2.76 MB/s) - test/images/kodim21.png saved [637051/637051]\n",
            "\n",
            "22\n",
            "--2018-12-03 00:53:02--  http://r0k.us/graphics/kodak/kodak/kodim22.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 701970 (686K) [image/png]\n",
            "Saving to: test/images/kodim22.png\n",
            "\n",
            "test/images/kodim22 100%[===================>] 685.52K  2.97MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:03 (2.97 MB/s) - test/images/kodim22.png saved [701970/701970]\n",
            "\n",
            "23\n",
            "--2018-12-03 00:53:03--  http://r0k.us/graphics/kodak/kodak/kodim23.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 557596 (545K) [image/png]\n",
            "Saving to: test/images/kodim23.png\n",
            "\n",
            "test/images/kodim23 100%[===================>] 544.53K  2.49MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:03 (2.49 MB/s) - test/images/kodim23.png saved [557596/557596]\n",
            "\n",
            "24\n",
            "--2018-12-03 00:53:03--  http://r0k.us/graphics/kodak/kodak/kodim24.png\n",
            "Resolving r0k.us (r0k.us)... 174.127.119.148\n",
            "Connecting to r0k.us (r0k.us)|174.127.119.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 706397 (690K) [image/png]\n",
            "Saving to: test/images/kodim24.png\n",
            "\n",
            "test/images/kodim24 100%[===================>] 689.84K  2.94MB/s    in 0.2s    \n",
            "\n",
            "2018-12-03 00:53:03 (2.94 MB/s) - test/images/kodim24.png saved [706397/706397]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9G87DTDdjcE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a8e2d4fb-66bd-4f5a-8e00-45efef90f911"
      },
      "cell_type": "code",
      "source": [
        "!ls 'checkpoint/'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "binarizer_epoch_00000001.pth  decoder_iter_00000000.pth\n",
            "binarizer_epoch_00000002.pth  encoder_epoch_00000001.pth\n",
            "binarizer_iter_00000000.pth   encoder_epoch_00000002.pth\n",
            "decoder_epoch_00000001.pth    encoder_iter_00000000.pth\n",
            "decoder_epoch_00000002.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jpLzQQQ6jkKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "9ff9e361-6918-4b29-9c04-ec925faed9b9"
      },
      "cell_type": "code",
      "source": [
        "!python 'gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py' --model checkpoint/encoder_epoch_00000002.pth --input test/images/kodim04.png --cuda --output ex --iterations 4"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  image = Variable(image, volatile=True)\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:46: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 256, height // 4, width // 4), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:49: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:51: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 512, height // 8, width // 8), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:54: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:56: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 512, height // 16, width // 16), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:59: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:62: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 512, height // 16, width // 16), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:65: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 512, height // 8, width // 8), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:72: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 256, height // 4, width // 4), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:75: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:77: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 128, height // 2, width // 2), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:80: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Iter: 00; Loss: 0.049724\n",
            "Iter: 01; Loss: 0.031621\n",
            "Iter: 02; Loss: 0.026040\n",
            "Iter: 03; Loss: 0.023439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qw1lchVxnKrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "64810b7d-d6f4-4ae6-896b-d24032149a84"
      },
      "cell_type": "code",
      "source": [
        "!python 'gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py' --model checkpoint/encoder_epoch_00000002.pth --input test/images/kodim04.png --cuda --output ex --iterations 4"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  image = Variable(image, volatile=True)\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:46: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 256, height // 4, width // 4), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:49: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:51: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 512, height // 8, width // 8), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:54: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:56: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 512, height // 16, width // 16), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:59: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:62: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 512, height // 16, width // 16), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:65: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 512, height // 8, width // 8), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:72: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 256, height // 4, width // 4), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:75: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:77: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  torch.zeros(batch_size, 128, height // 2, width // 2), volatile=True),\n",
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/encoder.py:80: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  volatile=True))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Iter: 00; Loss: 0.049724\n",
            "Iter: 01; Loss: 0.031621\n",
            "Iter: 02; Loss: 0.026040\n",
            "Iter: 03; Loss: 0.023439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VzSd3tw2pwnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "c3ac1524-29da-4b97-b6a6-aa2a35de0f5b"
      },
      "cell_type": "code",
      "source": [
        "!python 'gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/decoder.py' --model checkpoint/encoder_epoch_00000001.pth --input ex.npz --cuda --output ."
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/decoder.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  codes = Variable(codes, volatile=True)\n",
            "Traceback (most recent call last):\n",
            "  File \"gdrive/My Drive/Fall 18/297/Deliverable_4/pytorch-image-comp-rnn/decoder.py\", line 35, in <module>\n",
            "    decoder.load_state_dict(torch.load(args.model))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 719, in load_state_dict\n",
            "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
            "RuntimeError: Error(s) in loading state_dict for DecoderCell:\n",
            "\tMissing key(s) in state_dict: \"conv1.weight\", \"rnn4.conv_ih.weight\", \"rnn4.conv_hh.weight\", \"conv2.weight\". \n",
            "\tUnexpected key(s) in state_dict: \"conv.weight\". \n",
            "\tsize mismatch for rnn1.conv_ih.weight: copying a param of torch.Size([2048, 512, 3, 3]) from checkpoint, where the shape is torch.Size([1024, 64, 3, 3]) in current model.\n",
            "\tsize mismatch for rnn1.conv_hh.weight: copying a param of torch.Size([2048, 512, 1, 1]) from checkpoint, where the shape is torch.Size([1024, 256, 1, 1]) in current model.\n",
            "\tsize mismatch for rnn2.conv_ih.weight: copying a param of torch.Size([2048, 128, 3, 3]) from checkpoint, where the shape is torch.Size([2048, 256, 3, 3]) in current model.\n",
            "\tsize mismatch for rnn3.conv_ih.weight: copying a param of torch.Size([1024, 128, 3, 3]) from checkpoint, where the shape is torch.Size([2048, 512, 3, 3]) in current model.\n",
            "\tsize mismatch for rnn3.conv_hh.weight: copying a param of torch.Size([1024, 256, 3, 3]) from checkpoint, where the shape is torch.Size([2048, 512, 1, 1]) in current model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GExerfXWriA7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}